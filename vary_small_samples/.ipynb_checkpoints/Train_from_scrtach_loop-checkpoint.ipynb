{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "(160, 224, 224, 8)\n",
      "(160, 224, 224, 1)\n",
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "model_train_from_scratch_No_NAIP_200_samples_r1_\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 29s 183ms/step - loss: -0.1335 - dice_coef: 0.1335 - accuracy: 0.7146 - val_loss: -0.0662 - val_dice_coef: 0.0662 - val_accuracy: 0.6509\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 12s 77ms/step - loss: -0.1970 - dice_coef: 0.1970 - accuracy: 0.9041 - val_loss: -0.1204 - val_dice_coef: 0.1204 - val_accuracy: 0.9114\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.2364 - dice_coef: 0.2364 - accuracy: 0.9391 - val_loss: -0.1706 - val_dice_coef: 0.1706 - val_accuracy: 0.9239\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.2629 - dice_coef: 0.2629 - accuracy: 0.9520 - val_loss: -0.1597 - val_dice_coef: 0.1597 - val_accuracy: 0.9649\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.2815 - dice_coef: 0.2815 - accuracy: 0.9593 - val_loss: -0.1776 - val_dice_coef: 0.1776 - val_accuracy: 0.9750\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.3083 - dice_coef: 0.3083 - accuracy: 0.9651 - val_loss: -0.1890 - val_dice_coef: 0.1890 - val_accuracy: 0.9294\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.3266 - dice_coef: 0.3266 - accuracy: 0.9661 - val_loss: -0.2012 - val_dice_coef: 0.2012 - val_accuracy: 0.9643\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.3592 - dice_coef: 0.3592 - accuracy: 0.9698 - val_loss: -0.2035 - val_dice_coef: 0.2035 - val_accuracy: 0.9189\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.3816 - dice_coef: 0.3816 - accuracy: 0.9728 - val_loss: -0.2175 - val_dice_coef: 0.2175 - val_accuracy: 0.9415\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 12s 76ms/step - loss: -0.4099 - dice_coef: 0.4099 - accuracy: 0.9742 - val_loss: -0.2370 - val_dice_coef: 0.2370 - val_accuracy: 0.9396\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 12s 76ms/step - loss: -0.4356 - dice_coef: 0.4356 - accuracy: 0.9782 - val_loss: -0.2607 - val_dice_coef: 0.2607 - val_accuracy: 0.9671\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 12s 76ms/step - loss: -0.4581 - dice_coef: 0.4581 - accuracy: 0.9771 - val_loss: -0.2569 - val_dice_coef: 0.2569 - val_accuracy: 0.9788\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 12s 76ms/step - loss: -0.4885 - dice_coef: 0.4885 - accuracy: 0.9804 - val_loss: -0.2932 - val_dice_coef: 0.2932 - val_accuracy: 0.9773\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.5157 - dice_coef: 0.5157 - accuracy: 0.9829 - val_loss: -0.2803 - val_dice_coef: 0.2803 - val_accuracy: 0.9766\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5345 - dice_coef: 0.5345 - accuracy: 0.9826 - val_loss: -0.2974 - val_dice_coef: 0.2974 - val_accuracy: 0.9646\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5564 - dice_coef: 0.5564 - accuracy: 0.9834 - val_loss: -0.3348 - val_dice_coef: 0.3348 - val_accuracy: 0.9567\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5789 - dice_coef: 0.5789 - accuracy: 0.9840 - val_loss: -0.3528 - val_dice_coef: 0.3528 - val_accuracy: 0.9817\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6019 - dice_coef: 0.6019 - accuracy: 0.9845 - val_loss: -0.3250 - val_dice_coef: 0.3250 - val_accuracy: 0.9691\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6206 - dice_coef: 0.6206 - accuracy: 0.9856 - val_loss: -0.3574 - val_dice_coef: 0.3574 - val_accuracy: 0.9723\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.6208 - dice_coef: 0.6208 - accuracy: 0.9852 - val_loss: -0.3110 - val_dice_coef: 0.3110 - val_accuracy: 0.9832\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6343 - dice_coef: 0.6343 - accuracy: 0.9851 - val_loss: -0.3191 - val_dice_coef: 0.3191 - val_accuracy: 0.9836\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6539 - dice_coef: 0.6539 - accuracy: 0.9887 - val_loss: -0.3537 - val_dice_coef: 0.3537 - val_accuracy: 0.9786\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6987 - dice_coef: 0.6987 - accuracy: 0.9887 - val_loss: -0.3792 - val_dice_coef: 0.3792 - val_accuracy: 0.9795\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6861 - dice_coef: 0.6861 - accuracy: 0.9875 - val_loss: -0.3537 - val_dice_coef: 0.3537 - val_accuracy: 0.9710\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7138 - dice_coef: 0.7138 - accuracy: 0.9896 - val_loss: -0.3571 - val_dice_coef: 0.3571 - val_accuracy: 0.9837\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.6955 - dice_coef: 0.6955 - accuracy: 0.9889 - val_loss: -0.3743 - val_dice_coef: 0.3743 - val_accuracy: 0.9826\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7414 - dice_coef: 0.7414 - accuracy: 0.9915 - val_loss: -0.3937 - val_dice_coef: 0.3937 - val_accuracy: 0.9830\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7103 - dice_coef: 0.7103 - accuracy: 0.9908 - val_loss: -0.3691 - val_dice_coef: 0.3691 - val_accuracy: 0.9835\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7383 - dice_coef: 0.7383 - accuracy: 0.9909 - val_loss: -0.3804 - val_dice_coef: 0.3804 - val_accuracy: 0.9835\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 12s 75ms/step - loss: -0.7437 - dice_coef: 0.7437 - accuracy: 0.9919 - val_loss: -0.4018 - val_dice_coef: 0.4018 - val_accuracy: 0.9831\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.7494 - dice_coef: 0.7494 - accuracy: 0.9928 - val_loss: -0.4079 - val_dice_coef: 0.4079 - val_accuracy: 0.9811\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7993 - dice_coef: 0.7993 - accuracy: 0.9931 - val_loss: -0.3851 - val_dice_coef: 0.3851 - val_accuracy: 0.9832\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7338 - dice_coef: 0.7338 - accuracy: 0.9917 - val_loss: -0.3653 - val_dice_coef: 0.3653 - val_accuracy: 0.9834\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8007 - dice_coef: 0.8007 - accuracy: 0.9925 - val_loss: -0.4017 - val_dice_coef: 0.4017 - val_accuracy: 0.9814\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7798 - dice_coef: 0.7798 - accuracy: 0.9928 - val_loss: -0.4286 - val_dice_coef: 0.4286 - val_accuracy: 0.9664\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.7732 - dice_coef: 0.7732 - accuracy: 0.9928 - val_loss: -0.4010 - val_dice_coef: 0.4010 - val_accuracy: 0.9832\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8244 - dice_coef: 0.8244 - accuracy: 0.9946 - val_loss: -0.4022 - val_dice_coef: 0.4022 - val_accuracy: 0.9834\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8285 - dice_coef: 0.8285 - accuracy: 0.9943 - val_loss: -0.4244 - val_dice_coef: 0.4244 - val_accuracy: 0.9811\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8371 - dice_coef: 0.8371 - accuracy: 0.9943 - val_loss: -0.3894 - val_dice_coef: 0.3894 - val_accuracy: 0.9840\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7997 - dice_coef: 0.7997 - accuracy: 0.9947 - val_loss: -0.3969 - val_dice_coef: 0.3969 - val_accuracy: 0.9825\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7951 - dice_coef: 0.7951 - accuracy: 0.9938 - val_loss: -0.4409 - val_dice_coef: 0.4409 - val_accuracy: 0.9812\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8360 - dice_coef: 0.8360 - accuracy: 0.9948 - val_loss: -0.3597 - val_dice_coef: 0.3597 - val_accuracy: 0.9822\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7628 - dice_coef: 0.7628 - accuracy: 0.9947 - val_loss: -0.4389 - val_dice_coef: 0.4389 - val_accuracy: 0.9743\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7845 - dice_coef: 0.7845 - accuracy: 0.9944 - val_loss: -0.4460 - val_dice_coef: 0.4460 - val_accuracy: 0.9807\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7598 - dice_coef: 0.7598 - accuracy: 0.9907 - val_loss: -0.4414 - val_dice_coef: 0.4414 - val_accuracy: 0.9828\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8090 - dice_coef: 0.8090 - accuracy: 0.9939 - val_loss: -0.4171 - val_dice_coef: 0.4171 - val_accuracy: 0.9831\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7984 - dice_coef: 0.7984 - accuracy: 0.9950 - val_loss: -0.4181 - val_dice_coef: 0.4181 - val_accuracy: 0.9822\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.8401 - dice_coef: 0.8401 - accuracy: 0.9943 - val_loss: -0.4279 - val_dice_coef: 0.4279 - val_accuracy: 0.9823\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7663 - dice_coef: 0.7663 - accuracy: 0.9932 - val_loss: -0.3804 - val_dice_coef: 0.3804 - val_accuracy: 0.9824\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8209 - dice_coef: 0.8209 - accuracy: 0.9938 - val_loss: -0.4432 - val_dice_coef: 0.4432 - val_accuracy: 0.9798\n",
      "(160, 224, 224, 8)\n",
      "(160, 224, 224, 1)\n",
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "model_train_from_scratch_No_NAIP_200_samples_r1_No_NAIP_200_samples_r2_\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 20s 125ms/step - loss: -0.1524 - dice_coef: 0.1524 - accuracy: 0.7491 - val_loss: -0.0592 - val_dice_coef: 0.0592 - val_accuracy: 0.0304\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2019 - dice_coef: 0.2019 - accuracy: 0.8766 - val_loss: -0.1146 - val_dice_coef: 0.1146 - val_accuracy: 0.8103\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2346 - dice_coef: 0.2346 - accuracy: 0.9237 - val_loss: -0.1654 - val_dice_coef: 0.1654 - val_accuracy: 0.9700\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2636 - dice_coef: 0.2636 - accuracy: 0.9458 - val_loss: -0.1608 - val_dice_coef: 0.1608 - val_accuracy: 0.9571\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2754 - dice_coef: 0.2754 - accuracy: 0.9493 - val_loss: -0.1919 - val_dice_coef: 0.1919 - val_accuracy: 0.9716\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2926 - dice_coef: 0.2926 - accuracy: 0.9567 - val_loss: -0.1934 - val_dice_coef: 0.1934 - val_accuracy: 0.9745\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3099 - dice_coef: 0.3099 - accuracy: 0.9584 - val_loss: -0.1870 - val_dice_coef: 0.1870 - val_accuracy: 0.9736\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3291 - dice_coef: 0.3291 - accuracy: 0.9636 - val_loss: -0.2346 - val_dice_coef: 0.2346 - val_accuracy: 0.9577\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3513 - dice_coef: 0.3513 - accuracy: 0.9673 - val_loss: -0.2026 - val_dice_coef: 0.2026 - val_accuracy: 0.9759\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3808 - dice_coef: 0.3808 - accuracy: 0.9710 - val_loss: -0.2243 - val_dice_coef: 0.2243 - val_accuracy: 0.9750\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4022 - dice_coef: 0.4022 - accuracy: 0.9752 - val_loss: -0.2138 - val_dice_coef: 0.2138 - val_accuracy: 0.9765\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4115 - dice_coef: 0.4115 - accuracy: 0.9748 - val_loss: -0.2594 - val_dice_coef: 0.2594 - val_accuracy: 0.9633\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.4467 - dice_coef: 0.4467 - accuracy: 0.9773 - val_loss: -0.2392 - val_dice_coef: 0.2392 - val_accuracy: 0.9770\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.4453 - dice_coef: 0.4453 - accuracy: 0.9773 - val_loss: -0.2867 - val_dice_coef: 0.2867 - val_accuracy: 0.9808\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.4867 - dice_coef: 0.4867 - accuracy: 0.9806 - val_loss: -0.2355 - val_dice_coef: 0.2355 - val_accuracy: 0.9799\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5105 - dice_coef: 0.5105 - accuracy: 0.9825 - val_loss: -0.2923 - val_dice_coef: 0.2923 - val_accuracy: 0.9780\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.5508 - dice_coef: 0.5508 - accuracy: 0.9847 - val_loss: -0.2794 - val_dice_coef: 0.2794 - val_accuracy: 0.9797\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.5481 - dice_coef: 0.5481 - accuracy: 0.9831 - val_loss: -0.2748 - val_dice_coef: 0.2748 - val_accuracy: 0.9786\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5758 - dice_coef: 0.5758 - accuracy: 0.9837 - val_loss: -0.3590 - val_dice_coef: 0.3590 - val_accuracy: 0.9670\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.5937 - dice_coef: 0.5937 - accuracy: 0.9840 - val_loss: -0.4042 - val_dice_coef: 0.4042 - val_accuracy: 0.9798\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6513 - dice_coef: 0.6513 - accuracy: 0.9871 - val_loss: -0.2913 - val_dice_coef: 0.2913 - val_accuracy: 0.9815\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6403 - dice_coef: 0.6403 - accuracy: 0.9846 - val_loss: -0.3942 - val_dice_coef: 0.3942 - val_accuracy: 0.9661\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.6589 - dice_coef: 0.6589 - accuracy: 0.9868 - val_loss: -0.3800 - val_dice_coef: 0.3800 - val_accuracy: 0.9819\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6764 - dice_coef: 0.6764 - accuracy: 0.9887 - val_loss: -0.3535 - val_dice_coef: 0.3535 - val_accuracy: 0.9803\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7088 - dice_coef: 0.7088 - accuracy: 0.9890 - val_loss: -0.4722 - val_dice_coef: 0.4722 - val_accuracy: 0.9771\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.7359 - dice_coef: 0.7359 - accuracy: 0.9903 - val_loss: -0.2952 - val_dice_coef: 0.2952 - val_accuracy: 0.9795\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7432 - dice_coef: 0.7432 - accuracy: 0.9906 - val_loss: -0.4921 - val_dice_coef: 0.4921 - val_accuracy: 0.9817\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7680 - dice_coef: 0.7680 - accuracy: 0.9915 - val_loss: -0.3862 - val_dice_coef: 0.3862 - val_accuracy: 0.9816\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7488 - dice_coef: 0.7488 - accuracy: 0.9918 - val_loss: -0.5007 - val_dice_coef: 0.5007 - val_accuracy: 0.9798\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7944 - dice_coef: 0.7944 - accuracy: 0.9931 - val_loss: -0.3277 - val_dice_coef: 0.3277 - val_accuracy: 0.9805\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7993 - dice_coef: 0.7993 - accuracy: 0.9925 - val_loss: -0.4612 - val_dice_coef: 0.4612 - val_accuracy: 0.9803\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7852 - dice_coef: 0.7852 - accuracy: 0.9926 - val_loss: -0.5172 - val_dice_coef: 0.5172 - val_accuracy: 0.9747\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7814 - dice_coef: 0.7814 - accuracy: 0.9926 - val_loss: -0.4759 - val_dice_coef: 0.4759 - val_accuracy: 0.9815\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7559 - dice_coef: 0.7559 - accuracy: 0.9913 - val_loss: -0.4422 - val_dice_coef: 0.4422 - val_accuracy: 0.9749\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.7902 - dice_coef: 0.7902 - accuracy: 0.9920 - val_loss: -0.3908 - val_dice_coef: 0.3908 - val_accuracy: 0.9819\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8410 - dice_coef: 0.8410 - accuracy: 0.9942 - val_loss: -0.3376 - val_dice_coef: 0.3376 - val_accuracy: 0.9791\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.8166 - dice_coef: 0.8166 - accuracy: 0.9933 - val_loss: -0.4700 - val_dice_coef: 0.4700 - val_accuracy: 0.9806\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7928 - dice_coef: 0.7928 - accuracy: 0.9909 - val_loss: -0.5016 - val_dice_coef: 0.5016 - val_accuracy: 0.9776\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8475 - dice_coef: 0.8475 - accuracy: 0.9939 - val_loss: -0.3464 - val_dice_coef: 0.3464 - val_accuracy: 0.9798\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8605 - dice_coef: 0.8605 - accuracy: 0.9949 - val_loss: -0.4931 - val_dice_coef: 0.4931 - val_accuracy: 0.9808\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8196 - dice_coef: 0.8196 - accuracy: 0.9945 - val_loss: -0.4022 - val_dice_coef: 0.4022 - val_accuracy: 0.9813\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8503 - dice_coef: 0.8503 - accuracy: 0.9933 - val_loss: -0.4253 - val_dice_coef: 0.4253 - val_accuracy: 0.9779\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.8439 - dice_coef: 0.8439 - accuracy: 0.9933 - val_loss: -0.5230 - val_dice_coef: 0.5230 - val_accuracy: 0.9811\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8473 - dice_coef: 0.8473 - accuracy: 0.9930 - val_loss: -0.5551 - val_dice_coef: 0.5551 - val_accuracy: 0.9827\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.8266 - dice_coef: 0.8266 - accuracy: 0.9933 - val_loss: -0.4871 - val_dice_coef: 0.4871 - val_accuracy: 0.9783\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8841 - dice_coef: 0.8841 - accuracy: 0.9954 - val_loss: -0.5203 - val_dice_coef: 0.5203 - val_accuracy: 0.9798\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8493 - dice_coef: 0.8493 - accuracy: 0.9945 - val_loss: -0.4088 - val_dice_coef: 0.4088 - val_accuracy: 0.9816\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8896 - dice_coef: 0.8896 - accuracy: 0.9957 - val_loss: -0.3859 - val_dice_coef: 0.3859 - val_accuracy: 0.9804\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8128 - dice_coef: 0.8128 - accuracy: 0.9925 - val_loss: -0.5617 - val_dice_coef: 0.5617 - val_accuracy: 0.9821\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8495 - dice_coef: 0.8495 - accuracy: 0.9942 - val_loss: -0.4398 - val_dice_coef: 0.4398 - val_accuracy: 0.9791\n",
      "(160, 224, 224, 8)\n",
      "(160, 224, 224, 1)\n",
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "model_train_from_scratch_No_NAIP_200_samples_r1_No_NAIP_200_samples_r2_No_NAIP_200_samples_r3_\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 20s 124ms/step - loss: -0.1615 - dice_coef: 0.1615 - accuracy: 0.8295 - val_loss: -0.0573 - val_dice_coef: 0.0573 - val_accuracy: 0.3231\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.2676 - dice_coef: 0.2676 - accuracy: 0.9269 - val_loss: -0.1251 - val_dice_coef: 0.1251 - val_accuracy: 0.9226\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3325 - dice_coef: 0.3325 - accuracy: 0.9553 - val_loss: -0.1718 - val_dice_coef: 0.1718 - val_accuracy: 0.9576\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3629 - dice_coef: 0.3629 - accuracy: 0.9635 - val_loss: -0.1926 - val_dice_coef: 0.1926 - val_accuracy: 0.9568\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.3998 - dice_coef: 0.3998 - accuracy: 0.9674 - val_loss: -0.1904 - val_dice_coef: 0.1904 - val_accuracy: 0.9606\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4241 - dice_coef: 0.4241 - accuracy: 0.9712 - val_loss: -0.1854 - val_dice_coef: 0.1854 - val_accuracy: 0.9734\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4643 - dice_coef: 0.4643 - accuracy: 0.9738 - val_loss: -0.1601 - val_dice_coef: 0.1601 - val_accuracy: 0.9751\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4906 - dice_coef: 0.4906 - accuracy: 0.9764 - val_loss: -0.1777 - val_dice_coef: 0.1777 - val_accuracy: 0.9804\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5017 - dice_coef: 0.5017 - accuracy: 0.9782 - val_loss: -0.2162 - val_dice_coef: 0.2162 - val_accuracy: 0.9706\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5223 - dice_coef: 0.5223 - accuracy: 0.9792 - val_loss: -0.1859 - val_dice_coef: 0.1859 - val_accuracy: 0.9771\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5515 - dice_coef: 0.5515 - accuracy: 0.9796 - val_loss: -0.2180 - val_dice_coef: 0.2180 - val_accuracy: 0.9770\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5641 - dice_coef: 0.5641 - accuracy: 0.9803 - val_loss: -0.2302 - val_dice_coef: 0.2302 - val_accuracy: 0.9759\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5832 - dice_coef: 0.5832 - accuracy: 0.9807 - val_loss: -0.2183 - val_dice_coef: 0.2183 - val_accuracy: 0.9801\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6153 - dice_coef: 0.6153 - accuracy: 0.9815 - val_loss: -0.2595 - val_dice_coef: 0.2595 - val_accuracy: 0.9755\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6147 - dice_coef: 0.6147 - accuracy: 0.9817 - val_loss: -0.1741 - val_dice_coef: 0.1741 - val_accuracy: 0.9801\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6437 - dice_coef: 0.6437 - accuracy: 0.9837 - val_loss: -0.2518 - val_dice_coef: 0.2518 - val_accuracy: 0.9811\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6394 - dice_coef: 0.6394 - accuracy: 0.9825 - val_loss: -0.2266 - val_dice_coef: 0.2266 - val_accuracy: 0.9776\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6594 - dice_coef: 0.6594 - accuracy: 0.9843 - val_loss: -0.2524 - val_dice_coef: 0.2524 - val_accuracy: 0.9775\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6365 - dice_coef: 0.6365 - accuracy: 0.9822 - val_loss: -0.2533 - val_dice_coef: 0.2533 - val_accuracy: 0.9811\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6451 - dice_coef: 0.6451 - accuracy: 0.9834 - val_loss: -0.2428 - val_dice_coef: 0.2428 - val_accuracy: 0.9810\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7096 - dice_coef: 0.7096 - accuracy: 0.9860 - val_loss: -0.2385 - val_dice_coef: 0.2385 - val_accuracy: 0.9806\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7049 - dice_coef: 0.7049 - accuracy: 0.9865 - val_loss: -0.2922 - val_dice_coef: 0.2922 - val_accuracy: 0.9806\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7178 - dice_coef: 0.7178 - accuracy: 0.9877 - val_loss: -0.1932 - val_dice_coef: 0.1932 - val_accuracy: 0.9801\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7573 - dice_coef: 0.7573 - accuracy: 0.9881 - val_loss: -0.2350 - val_dice_coef: 0.2350 - val_accuracy: 0.9812\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7204 - dice_coef: 0.7204 - accuracy: 0.9872 - val_loss: -0.3186 - val_dice_coef: 0.3186 - val_accuracy: 0.9780\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7659 - dice_coef: 0.7659 - accuracy: 0.9890 - val_loss: -0.3190 - val_dice_coef: 0.3190 - val_accuracy: 0.9796\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7663 - dice_coef: 0.7663 - accuracy: 0.9885 - val_loss: -0.2670 - val_dice_coef: 0.2670 - val_accuracy: 0.9775\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7517 - dice_coef: 0.7517 - accuracy: 0.9881 - val_loss: -0.2275 - val_dice_coef: 0.2275 - val_accuracy: 0.9805\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7449 - dice_coef: 0.7449 - accuracy: 0.9877 - val_loss: -0.2675 - val_dice_coef: 0.2675 - val_accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7412 - dice_coef: 0.7412 - accuracy: 0.9885 - val_loss: -0.1847 - val_dice_coef: 0.1847 - val_accuracy: 0.9803\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7470 - dice_coef: 0.7470 - accuracy: 0.9893 - val_loss: -0.2906 - val_dice_coef: 0.2906 - val_accuracy: 0.9815\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7785 - dice_coef: 0.7785 - accuracy: 0.9895 - val_loss: -0.3417 - val_dice_coef: 0.3417 - val_accuracy: 0.9793\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7806 - dice_coef: 0.7806 - accuracy: 0.9897 - val_loss: -0.3019 - val_dice_coef: 0.3019 - val_accuracy: 0.9803\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7981 - dice_coef: 0.7981 - accuracy: 0.9901 - val_loss: -0.3117 - val_dice_coef: 0.3117 - val_accuracy: 0.9806\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7666 - dice_coef: 0.7666 - accuracy: 0.9901 - val_loss: -0.1889 - val_dice_coef: 0.1889 - val_accuracy: 0.9802\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7950 - dice_coef: 0.7950 - accuracy: 0.9907 - val_loss: -0.2740 - val_dice_coef: 0.2740 - val_accuracy: 0.9817\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8409 - dice_coef: 0.8409 - accuracy: 0.9918 - val_loss: -0.2075 - val_dice_coef: 0.2075 - val_accuracy: 0.9807\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7702 - dice_coef: 0.7702 - accuracy: 0.9897 - val_loss: -0.2719 - val_dice_coef: 0.2719 - val_accuracy: 0.9809\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8084 - dice_coef: 0.8084 - accuracy: 0.9912 - val_loss: -0.3135 - val_dice_coef: 0.3135 - val_accuracy: 0.9808\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8246 - dice_coef: 0.8246 - accuracy: 0.9916 - val_loss: -0.2833 - val_dice_coef: 0.2833 - val_accuracy: 0.9815\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.7816 - dice_coef: 0.7816 - accuracy: 0.9908 - val_loss: -0.3010 - val_dice_coef: 0.3010 - val_accuracy: 0.9817\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8300 - dice_coef: 0.8300 - accuracy: 0.9930 - val_loss: -0.3263 - val_dice_coef: 0.3263 - val_accuracy: 0.9803\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.7670 - dice_coef: 0.7670 - accuracy: 0.9908 - val_loss: -0.2952 - val_dice_coef: 0.2952 - val_accuracy: 0.9813\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8137 - dice_coef: 0.8137 - accuracy: 0.9931 - val_loss: -0.3432 - val_dice_coef: 0.3432 - val_accuracy: 0.9692\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8009 - dice_coef: 0.8009 - accuracy: 0.9925 - val_loss: -0.2918 - val_dice_coef: 0.2918 - val_accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8489 - dice_coef: 0.8489 - accuracy: 0.9937 - val_loss: -0.2161 - val_dice_coef: 0.2161 - val_accuracy: 0.9803\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8440 - dice_coef: 0.8440 - accuracy: 0.9937 - val_loss: -0.2610 - val_dice_coef: 0.2610 - val_accuracy: 0.9811\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8599 - dice_coef: 0.8599 - accuracy: 0.9941 - val_loss: -0.3038 - val_dice_coef: 0.3038 - val_accuracy: 0.9813\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8285 - dice_coef: 0.8285 - accuracy: 0.9937 - val_loss: -0.2832 - val_dice_coef: 0.2832 - val_accuracy: 0.9816\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.8394 - dice_coef: 0.8394 - accuracy: 0.9926 - val_loss: -0.3105 - val_dice_coef: 0.3105 - val_accuracy: 0.9791\n",
      "(160, 224, 224, 8)\n",
      "(160, 224, 224, 1)\n",
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "model_train_from_scratch_No_NAIP_200_samples_r1_No_NAIP_200_samples_r2_No_NAIP_200_samples_r3_No_NAIP_200_samples_r4_\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 20s 125ms/step - loss: -0.1178 - dice_coef: 0.1178 - accuracy: 0.6900 - val_loss: -0.0567 - val_dice_coef: 0.0567 - val_accuracy: 0.2136\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.1850 - dice_coef: 0.1850 - accuracy: 0.9161 - val_loss: -0.1178 - val_dice_coef: 0.1178 - val_accuracy: 0.8898\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.2298 - dice_coef: 0.2298 - accuracy: 0.9489 - val_loss: -0.1604 - val_dice_coef: 0.1604 - val_accuracy: 0.9683\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2531 - dice_coef: 0.2531 - accuracy: 0.9562 - val_loss: -0.1764 - val_dice_coef: 0.1764 - val_accuracy: 0.9553\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2737 - dice_coef: 0.2737 - accuracy: 0.9609 - val_loss: -0.1702 - val_dice_coef: 0.1702 - val_accuracy: 0.9380\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.2953 - dice_coef: 0.2953 - accuracy: 0.9688 - val_loss: -0.1520 - val_dice_coef: 0.1520 - val_accuracy: 0.9069\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3102 - dice_coef: 0.3102 - accuracy: 0.9698 - val_loss: -0.0774 - val_dice_coef: 0.0774 - val_accuracy: 0.9753\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3253 - dice_coef: 0.3253 - accuracy: 0.9687 - val_loss: -0.1927 - val_dice_coef: 0.1927 - val_accuracy: 0.9523\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3517 - dice_coef: 0.3517 - accuracy: 0.9747 - val_loss: -0.2125 - val_dice_coef: 0.2125 - val_accuracy: 0.9478\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3657 - dice_coef: 0.3657 - accuracy: 0.9741 - val_loss: -0.2176 - val_dice_coef: 0.2176 - val_accuracy: 0.9657\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3966 - dice_coef: 0.3966 - accuracy: 0.9749 - val_loss: -0.2205 - val_dice_coef: 0.2205 - val_accuracy: 0.9521\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4142 - dice_coef: 0.4142 - accuracy: 0.9780 - val_loss: -0.2289 - val_dice_coef: 0.2289 - val_accuracy: 0.9257\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4295 - dice_coef: 0.4295 - accuracy: 0.9778 - val_loss: -0.2641 - val_dice_coef: 0.2641 - val_accuracy: 0.9740\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4678 - dice_coef: 0.4678 - accuracy: 0.9816 - val_loss: -0.2178 - val_dice_coef: 0.2178 - val_accuracy: 0.9287\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4752 - dice_coef: 0.4752 - accuracy: 0.9819 - val_loss: -0.2507 - val_dice_coef: 0.2507 - val_accuracy: 0.9271\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2305 - dice_coef: 0.2305 - accuracy: 0.8781 - val_loss: -0.0265 - val_dice_coef: 0.0265 - val_accuracy: 0.9634\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1051 - dice_coef: 0.1051 - accuracy: 0.8409 - val_loss: -0.0258 - val_dice_coef: 0.0258 - val_accuracy: 0.9699\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1091 - dice_coef: 0.1091 - accuracy: 0.8870 - val_loss: -0.0180 - val_dice_coef: 0.0180 - val_accuracy: 0.9799\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1134 - dice_coef: 0.1134 - accuracy: 0.9051 - val_loss: -0.0774 - val_dice_coef: 0.0774 - val_accuracy: 0.8549\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1120 - dice_coef: 0.1120 - accuracy: 0.8945 - val_loss: -0.0451 - val_dice_coef: 0.0451 - val_accuracy: 0.2892\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1131 - dice_coef: 0.1131 - accuracy: 0.8873 - val_loss: -0.0418 - val_dice_coef: 0.0418 - val_accuracy: 0.1598\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.1090 - dice_coef: 0.1090 - accuracy: 0.8864 - val_loss: -0.0400 - val_dice_coef: 0.0400 - val_accuracy: 0.0763\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1138 - dice_coef: 0.1138 - accuracy: 0.8946 - val_loss: -0.0400 - val_dice_coef: 0.0400 - val_accuracy: 0.0764\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 12s 72ms/step - loss: -0.1137 - dice_coef: 0.1137 - accuracy: 0.8911 - val_loss: -0.0401 - val_dice_coef: 0.0401 - val_accuracy: 0.0826\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1126 - dice_coef: 0.1126 - accuracy: 0.8922 - val_loss: -0.0404 - val_dice_coef: 0.0404 - val_accuracy: 0.1022\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1156 - dice_coef: 0.1156 - accuracy: 0.9007 - val_loss: -0.0404 - val_dice_coef: 0.0404 - val_accuracy: 0.1039\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1191 - dice_coef: 0.1191 - accuracy: 0.9011 - val_loss: -0.0415 - val_dice_coef: 0.0415 - val_accuracy: 0.1527\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1158 - dice_coef: 0.1158 - accuracy: 0.8929 - val_loss: -0.0406 - val_dice_coef: 0.0406 - val_accuracy: 0.1069\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1188 - dice_coef: 0.1188 - accuracy: 0.8961 - val_loss: -0.0404 - val_dice_coef: 0.0404 - val_accuracy: 0.0969\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1186 - dice_coef: 0.1186 - accuracy: 0.8995 - val_loss: -0.0406 - val_dice_coef: 0.0406 - val_accuracy: 0.1124\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1166 - dice_coef: 0.1166 - accuracy: 0.8938 - val_loss: -0.0409 - val_dice_coef: 0.0409 - val_accuracy: 0.1235\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1154 - dice_coef: 0.1154 - accuracy: 0.9018 - val_loss: -0.0403 - val_dice_coef: 0.0403 - val_accuracy: 0.0913\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1156 - dice_coef: 0.1156 - accuracy: 0.8956 - val_loss: -0.0402 - val_dice_coef: 0.0402 - val_accuracy: 0.0881\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.999999823165126e-05.\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1179 - dice_coef: 0.1179 - accuracy: 0.8979 - val_loss: -0.0407 - val_dice_coef: 0.0407 - val_accuracy: 0.1171\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1204 - dice_coef: 0.1204 - accuracy: 0.9000 - val_loss: -0.0432 - val_dice_coef: 0.0432 - val_accuracy: 0.2393\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1175 - dice_coef: 0.1175 - accuracy: 0.8997 - val_loss: -0.0690 - val_dice_coef: 0.0690 - val_accuracy: 0.7825\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1208 - dice_coef: 0.1208 - accuracy: 0.9034 - val_loss: -0.0428 - val_dice_coef: 0.0428 - val_accuracy: 0.2271\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1201 - dice_coef: 0.1201 - accuracy: 0.9014 - val_loss: -0.0418 - val_dice_coef: 0.0418 - val_accuracy: 0.1818\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1189 - dice_coef: 0.1189 - accuracy: 0.9013 - val_loss: -0.0464 - val_dice_coef: 0.0464 - val_accuracy: 0.3692\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1180 - dice_coef: 0.1180 - accuracy: 0.8985 - val_loss: -0.0823 - val_dice_coef: 0.0823 - val_accuracy: 0.8722\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1196 - dice_coef: 0.1196 - accuracy: 0.8985 - val_loss: -0.0580 - val_dice_coef: 0.0580 - val_accuracy: 0.6223\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1181 - dice_coef: 0.1181 - accuracy: 0.9040 - val_loss: -0.0470 - val_dice_coef: 0.0470 - val_accuracy: 0.3731\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.1205 - dice_coef: 0.1205 - accuracy: 0.9005 - val_loss: -0.0149 - val_dice_coef: 0.0149 - val_accuracy: 0.9799\n",
      "(160, 224, 224, 8)\n",
      "(160, 224, 224, 1)\n",
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "model_train_from_scratch_No_NAIP_200_samples_r1_No_NAIP_200_samples_r2_No_NAIP_200_samples_r3_No_NAIP_200_samples_r4_No_NAIP_200_samples_r5_\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 20s 124ms/step - loss: -0.1421 - dice_coef: 0.1421 - accuracy: 0.7589 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.4087\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.2495 - dice_coef: 0.2495 - accuracy: 0.9174 - val_loss: -0.1106 - val_dice_coef: 0.1106 - val_accuracy: 0.8505\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3031 - dice_coef: 0.3031 - accuracy: 0.9496 - val_loss: -0.1253 - val_dice_coef: 0.1253 - val_accuracy: 0.9032\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3372 - dice_coef: 0.3372 - accuracy: 0.9608 - val_loss: -0.1279 - val_dice_coef: 0.1279 - val_accuracy: 0.9810\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3592 - dice_coef: 0.3592 - accuracy: 0.9648 - val_loss: -0.1627 - val_dice_coef: 0.1627 - val_accuracy: 0.9747\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.3765 - dice_coef: 0.3765 - accuracy: 0.9672 - val_loss: -0.1758 - val_dice_coef: 0.1758 - val_accuracy: 0.9642\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4275 - dice_coef: 0.4275 - accuracy: 0.9730 - val_loss: -0.1485 - val_dice_coef: 0.1485 - val_accuracy: 0.9839\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4334 - dice_coef: 0.4334 - accuracy: 0.9735 - val_loss: -0.1423 - val_dice_coef: 0.1423 - val_accuracy: 0.9724\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4568 - dice_coef: 0.4568 - accuracy: 0.9738 - val_loss: -0.1712 - val_dice_coef: 0.1712 - val_accuracy: 0.8981\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4852 - dice_coef: 0.4852 - accuracy: 0.9770 - val_loss: -0.1851 - val_dice_coef: 0.1851 - val_accuracy: 0.9820\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.4986 - dice_coef: 0.4986 - accuracy: 0.9779 - val_loss: -0.1530 - val_dice_coef: 0.1530 - val_accuracy: 0.9719\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5215 - dice_coef: 0.5215 - accuracy: 0.9790 - val_loss: -0.2413 - val_dice_coef: 0.2413 - val_accuracy: 0.9733\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5252 - dice_coef: 0.5252 - accuracy: 0.9800 - val_loss: -0.2483 - val_dice_coef: 0.2483 - val_accuracy: 0.9792\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5554 - dice_coef: 0.5554 - accuracy: 0.9796 - val_loss: -0.1910 - val_dice_coef: 0.1910 - val_accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.5814 - dice_coef: 0.5814 - accuracy: 0.9819 - val_loss: -0.1985 - val_dice_coef: 0.1985 - val_accuracy: 0.9825\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6384 - dice_coef: 0.6384 - accuracy: 0.9845 - val_loss: -0.2080 - val_dice_coef: 0.2080 - val_accuracy: 0.9805\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 12s 73ms/step - loss: -0.6138 - dice_coef: 0.6138 - accuracy: 0.9828 - val_loss: -0.2594 - val_dice_coef: 0.2594 - val_accuracy: 0.9810\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 13s 78ms/step - loss: -0.6194 - dice_coef: 0.6194 - accuracy: 0.9829 - val_loss: -0.2191 - val_dice_coef: 0.2191 - val_accuracy: 0.9839\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 12s 74ms/step - loss: -0.6405 - dice_coef: 0.6405 - accuracy: 0.9843 - val_loss: -0.1896 - val_dice_coef: 0.1896 - val_accuracy: 0.9703\n",
      "Epoch 20/50\n",
      " 20/160 [==>...........................] - ETA: 9s - loss: -0.6896 - dice_coef: 0.6896 - accuracy: 0.9801 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-008d7fdd9648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mno_transfer_learning_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Validation_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_Validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_data_format() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate\n",
    "\n",
    "# The structure of the constructed U-net model\n",
    "def UNET_224(weights=None):\n",
    "    if K.image_data_format() == 'th':\n",
    "        inputs = Input((INPUT_CHANNELS, IMG_WIDTH, IMG_WIDTH))\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((IMG_WIDTH, IMG_WIDTH, INPUT_CHANNELS))\n",
    "        axis = 3\n",
    "    filters = 32\n",
    "    last_dropout = 0.2\n",
    "# convolutiona and pooling level 1\n",
    "    conv_224 = Residual_CNN_block(inputs,filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "# convolutiona and pooling level 2\n",
    "    conv_112 = Residual_CNN_block(pool_112,2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "# convolutiona and pooling level 3\n",
    "    conv_56 = Residual_CNN_block(pool_56,4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "# convolutiona and pooling level 4\n",
    "    conv_28 = Residual_CNN_block(pool_28,8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "# convolutiona and pooling level 5\n",
    "    conv_14 = Residual_CNN_block(pool_14,16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "# Conlovlution and feature concatenation\n",
    "    conv_7 = Residual_CNN_block(pool_7,32*filters)\n",
    "# Upsampling with convolution \n",
    "    up_14 = attention_up_and_concatenate([conv_7, conv_14]) \n",
    "    up_conv_14 = Residual_CNN_block(up_14,16*filters)\n",
    "# Upsampling with convolution 2\n",
    "    up_28 = attention_up_and_concatenate([up_conv_14, conv_28])\n",
    "    up_conv_28 = Residual_CNN_block(up_28,8*filters)\n",
    "# Upsampling with convolution 3\n",
    "    up_56 = attention_up_and_concatenate2([up_conv_28, conv_56])\n",
    "    up_conv_56 = Residual_CNN_block(up_56,4*filters)\n",
    "# Upsampling with convolution 4\n",
    "    up_112 = attention_up_and_concatenate2([up_conv_56, conv_112])\n",
    "    up_conv_112 = Residual_CNN_block(up_112,2*filters)\n",
    "# Upsampling with convolution 5\n",
    "    up_224 = attention_up_and_concatenate2([up_conv_112, conv_224])\n",
    "    #up_224 = attention_up_and_concatenate2(up_conv_112, conv_224)\n",
    "    up_conv_224 = Residual_CNN_block(up_224,filters,dropout = last_dropout)\n",
    "# 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)  \n",
    "    conv_final = Activation('sigmoid')(conv_final)\n",
    "# Generate model\n",
    "    model = Model(inputs, conv_final, name=\"UNET_224\")\n",
    "    return model\n",
    "\n",
    "for sample_size in range(200,600,100):\n",
    "    for round_num in range(1,11):\n",
    "        \n",
    "        name = \"\"\n",
    "        name = \"model_train_from_scratch_\"\n",
    "        name += 'No_NAIP_'\n",
    "        name += str(sample_size)+\"_\"\n",
    "        name += \"samples_r\"+str(round_num)+\"_\"\n",
    "        data_path = './samples/'+str(sample_size)+'/'+str(round_num)+'/'\n",
    "        \n",
    "        print(name)\n",
    "        root_path = './training_results/'+str(sample_size)+'/'\n",
    "        \n",
    "        if os.path.exists(root_path+name+\".h5\"):\n",
    "            print(\"exists\")\n",
    "            continue;\n",
    "        \n",
    "        \n",
    "        # read in training and validation data\n",
    "        X_train_new = np.load(data_path+'train_data.npy')\n",
    "        print(X_train_new.shape)\n",
    "        Y_train = np.load(data_path+'train_label.npy')\n",
    "        print(Y_train.shape)\n",
    "        X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "        print(X_Validation_new.shape)\n",
    "        Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "        print(Y_Validation.shape)\n",
    "\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # learning_rate = 0.0000359\n",
    "        learning_rate = 0.0001\n",
    "        patience = 20\n",
    "        model = UNET_224()\n",
    "        model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('model_train_from_scratch_no_NAIP.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        # name += str(maxepoch)+'_epoch_'\n",
    "        print(name)\n",
    "\n",
    "        no_transfer_learning_results = model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=2, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "        import pickle\n",
    "#         import time\n",
    "#         timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "#         name += timestr\n",
    "        root_path = './training_results/'+str(sample_size)+'/'\n",
    "\n",
    "        # save the trained model\n",
    "        if not os.path.exists(root_path):\n",
    "                os.makedirs(root_path)\n",
    "\n",
    "        model_yaml = model.to_yaml()\n",
    "        with open(root_path+name+\".yaml\", \"w\") as yaml_file:\n",
    "            yaml_file.write(model_yaml)\n",
    "        # save the weights\n",
    "        model.save(root_path+name+\".h5\")\n",
    "        # save the intermdediate results and training statistics\n",
    "        with open(root_path+name+\".pickle\", 'wb') as file_pi:\n",
    "            pickle.dump(no_transfer_learning_results.history, file_pi, protocol=2)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = '../../wink.mp3'\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
