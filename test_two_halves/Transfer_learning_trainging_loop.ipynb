{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "model_fine_tuning_No_NAIP_200_samples_r1_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r2_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r3_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r4_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r5_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r6_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r7_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r8_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r9_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_200_samples_r10_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r1_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r2_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r3_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r4_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r5_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r6_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r7_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r8_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r9_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_300_samples_r10_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r1_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r2_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r3_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r4_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r5_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r6_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r7_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r8_\n",
      "exists\n",
      "model_fine_tuning_No_NAIP_400_samples_r9_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(320, 224, 224, 8)\n",
      "(320, 224, 224, 1)\n",
      "(80, 224, 224, 8)\n",
      "(80, 224, 224, 1)\n",
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "320/320 [==============================] - 21s 64ms/step - loss: -0.0874 - dice_coef: 0.0874 - accuracy: 0.3188 - val_loss: -0.1157 - val_dice_coef: 0.1157 - val_accuracy: 0.9400\n",
      "Epoch 2/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.3077 - dice_coef: 0.3077 - accuracy: 0.9622 - val_loss: -0.2334 - val_dice_coef: 0.2334 - val_accuracy: 0.8176\n",
      "Epoch 3/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5047 - dice_coef: 0.5047 - accuracy: 0.9698 - val_loss: -0.3125 - val_dice_coef: 0.3125 - val_accuracy: 0.9672\n",
      "Epoch 4/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5615 - dice_coef: 0.5615 - accuracy: 0.9736 - val_loss: -0.3825 - val_dice_coef: 0.3825 - val_accuracy: 0.9573\n",
      "Epoch 5/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5797 - dice_coef: 0.5797 - accuracy: 0.9749 - val_loss: -0.3002 - val_dice_coef: 0.3002 - val_accuracy: 0.9778\n",
      "Epoch 6/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5808 - dice_coef: 0.5808 - accuracy: 0.9751 - val_loss: -0.3724 - val_dice_coef: 0.3724 - val_accuracy: 0.9695\n",
      "Epoch 7/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6178 - dice_coef: 0.6178 - accuracy: 0.9767 - val_loss: -0.2611 - val_dice_coef: 0.2611 - val_accuracy: 0.9781\n",
      "Epoch 8/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6042 - dice_coef: 0.6042 - accuracy: 0.9765 - val_loss: -0.3398 - val_dice_coef: 0.3398 - val_accuracy: 0.9796\n",
      "Epoch 9/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5955 - dice_coef: 0.5955 - accuracy: 0.9771 - val_loss: -0.3196 - val_dice_coef: 0.3196 - val_accuracy: 0.9793\n",
      "Epoch 10/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6012 - dice_coef: 0.6012 - accuracy: 0.9769 - val_loss: -0.3113 - val_dice_coef: 0.3113 - val_accuracy: 0.9783\n",
      "Epoch 11/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6024 - dice_coef: 0.6024 - accuracy: 0.9771 - val_loss: -0.3296 - val_dice_coef: 0.3296 - val_accuracy: 0.9795\n",
      "Epoch 12/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.5869 - dice_coef: 0.5869 - accuracy: 0.9767 - val_loss: -0.3447 - val_dice_coef: 0.3447 - val_accuracy: 0.9800\n",
      "Epoch 13/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6119 - dice_coef: 0.6119 - accuracy: 0.9771 - val_loss: -0.2404 - val_dice_coef: 0.2404 - val_accuracy: 0.9777\n",
      "Epoch 14/50\n",
      "320/320 [==============================] - 13s 39ms/step - loss: -0.5992 - dice_coef: 0.5992 - accuracy: 0.9762 - val_loss: -0.2305 - val_dice_coef: 0.2305 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 15/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6092 - dice_coef: 0.6092 - accuracy: 0.9774 - val_loss: -0.3306 - val_dice_coef: 0.3306 - val_accuracy: 0.9796\n",
      "Epoch 16/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6097 - dice_coef: 0.6097 - accuracy: 0.9775 - val_loss: -0.3172 - val_dice_coef: 0.3172 - val_accuracy: 0.9793\n",
      "Epoch 17/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6069 - dice_coef: 0.6069 - accuracy: 0.9779 - val_loss: -0.3271 - val_dice_coef: 0.3271 - val_accuracy: 0.9787\n",
      "Epoch 18/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6209 - dice_coef: 0.6209 - accuracy: 0.9779 - val_loss: -0.3010 - val_dice_coef: 0.3010 - val_accuracy: 0.9788\n",
      "Epoch 19/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6263 - dice_coef: 0.6263 - accuracy: 0.9783 - val_loss: -0.3540 - val_dice_coef: 0.3540 - val_accuracy: 0.9790\n",
      "Epoch 20/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6249 - dice_coef: 0.6249 - accuracy: 0.9784 - val_loss: -0.3593 - val_dice_coef: 0.3593 - val_accuracy: 0.9790\n",
      "Epoch 21/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6132 - dice_coef: 0.6132 - accuracy: 0.9778 - val_loss: -0.3418 - val_dice_coef: 0.3418 - val_accuracy: 0.9797\n",
      "Epoch 22/50\n",
      "320/320 [==============================] - 12s 39ms/step - loss: -0.6052 - dice_coef: 0.6052 - accuracy: 0.9780 - val_loss: -0.3079 - val_dice_coef: 0.3079 - val_accuracy: 0.9790\n",
      "Epoch 23/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6219 - dice_coef: 0.6219 - accuracy: 0.9783 - val_loss: -0.3221 - val_dice_coef: 0.3221 - val_accuracy: 0.9791\n",
      "Epoch 24/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6275 - dice_coef: 0.6275 - accuracy: 0.9781 - val_loss: -0.3391 - val_dice_coef: 0.3391 - val_accuracy: 0.9794\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "320/320 [==============================] - 49s 153ms/step - loss: -0.4821 - dice_coef: 0.4821 - accuracy: 0.9739 - val_loss: -0.4250 - val_dice_coef: 0.4250 - val_accuracy: 0.9755\n",
      "Epoch 2/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5193 - dice_coef: 0.5193 - accuracy: 0.9790 - val_loss: -0.2437 - val_dice_coef: 0.2437 - val_accuracy: 0.8748\n",
      "Epoch 3/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5378 - dice_coef: 0.5378 - accuracy: 0.9813 - val_loss: -0.4066 - val_dice_coef: 0.4066 - val_accuracy: 0.9750\n",
      "Epoch 4/50\n",
      "320/320 [==============================] - 38s 120ms/step - loss: -0.5492 - dice_coef: 0.5492 - accuracy: 0.9822 - val_loss: -0.3894 - val_dice_coef: 0.3894 - val_accuracy: 0.9781\n",
      "Epoch 5/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5633 - dice_coef: 0.5633 - accuracy: 0.9840 - val_loss: -0.4010 - val_dice_coef: 0.4010 - val_accuracy: 0.9742\n",
      "Epoch 6/50\n",
      "320/320 [==============================] - 38s 120ms/step - loss: -0.5795 - dice_coef: 0.5795 - accuracy: 0.9864 - val_loss: -0.2977 - val_dice_coef: 0.2977 - val_accuracy: 0.9772\n",
      "Epoch 7/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5811 - dice_coef: 0.5811 - accuracy: 0.9872 - val_loss: -0.3776 - val_dice_coef: 0.3776 - val_accuracy: 0.9664\n",
      "Epoch 8/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5395 - dice_coef: 0.5395 - accuracy: 0.9829 - val_loss: -0.3949 - val_dice_coef: 0.3949 - val_accuracy: 0.9795\n",
      "Epoch 9/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5938 - dice_coef: 0.5938 - accuracy: 0.9864 - val_loss: -0.2733 - val_dice_coef: 0.2733 - val_accuracy: 0.9753\n",
      "Epoch 10/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5835 - dice_coef: 0.5835 - accuracy: 0.9844 - val_loss: -0.4279 - val_dice_coef: 0.4279 - val_accuracy: 0.9803\n",
      "Epoch 11/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6116 - dice_coef: 0.6116 - accuracy: 0.9862 - val_loss: -0.4470 - val_dice_coef: 0.4470 - val_accuracy: 0.9801\n",
      "Epoch 12/50\n",
      "320/320 [==============================] - 38s 120ms/step - loss: -0.5633 - dice_coef: 0.5633 - accuracy: 0.9827 - val_loss: -0.3696 - val_dice_coef: 0.3696 - val_accuracy: 0.9788\n",
      "Epoch 13/50\n",
      "320/320 [==============================] - 38s 120ms/step - loss: -0.5915 - dice_coef: 0.5915 - accuracy: 0.9825 - val_loss: -0.4198 - val_dice_coef: 0.4198 - val_accuracy: 0.9787\n",
      "Epoch 14/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6738 - dice_coef: 0.6738 - accuracy: 0.9855 - val_loss: -0.4478 - val_dice_coef: 0.4478 - val_accuracy: 0.9792\n",
      "Epoch 15/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5386 - dice_coef: 0.5386 - accuracy: 0.9791 - val_loss: -0.4011 - val_dice_coef: 0.4011 - val_accuracy: 0.9782\n",
      "Epoch 16/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6571 - dice_coef: 0.6571 - accuracy: 0.9828 - val_loss: -0.4500 - val_dice_coef: 0.4500 - val_accuracy: 0.9788\n",
      "Epoch 17/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6025 - dice_coef: 0.6025 - accuracy: 0.9809 - val_loss: -0.2972 - val_dice_coef: 0.2972 - val_accuracy: 0.9716\n",
      "Epoch 18/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6154 - dice_coef: 0.6154 - accuracy: 0.9808 - val_loss: -0.4482 - val_dice_coef: 0.4482 - val_accuracy: 0.9788\n",
      "Epoch 19/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6386 - dice_coef: 0.6386 - accuracy: 0.9808 - val_loss: -0.3212 - val_dice_coef: 0.3212 - val_accuracy: 0.9781\n",
      "Epoch 20/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6798 - dice_coef: 0.6798 - accuracy: 0.9832 - val_loss: -0.4397 - val_dice_coef: 0.4397 - val_accuracy: 0.9788\n",
      "Epoch 21/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6614 - dice_coef: 0.6614 - accuracy: 0.9831 - val_loss: -0.5122 - val_dice_coef: 0.5122 - val_accuracy: 0.9800\n",
      "Epoch 22/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.7161 - dice_coef: 0.7161 - accuracy: 0.9845 - val_loss: -0.5144 - val_dice_coef: 0.5144 - val_accuracy: 0.9801\n",
      "Epoch 23/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.7494 - dice_coef: 0.7494 - accuracy: 0.9861 - val_loss: -0.5155 - val_dice_coef: 0.5155 - val_accuracy: 0.9804\n",
      "Epoch 24/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7736 - dice_coef: 0.7736 - accuracy: 0.9878 - val_loss: -0.5037 - val_dice_coef: 0.5037 - val_accuracy: 0.9799\n",
      "Epoch 25/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7781 - dice_coef: 0.7781 - accuracy: 0.9879 - val_loss: -0.5159 - val_dice_coef: 0.5159 - val_accuracy: 0.9803\n",
      "Epoch 26/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.7525 - dice_coef: 0.7525 - accuracy: 0.9868 - val_loss: -0.5067 - val_dice_coef: 0.5067 - val_accuracy: 0.9799\n",
      "Epoch 27/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5754 - dice_coef: 0.5754 - accuracy: 0.9784 - val_loss: -0.2330 - val_dice_coef: 0.2330 - val_accuracy: 0.9772\n",
      "Epoch 28/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6356 - dice_coef: 0.6356 - accuracy: 0.9796 - val_loss: -0.4509 - val_dice_coef: 0.4509 - val_accuracy: 0.9782\n",
      "Epoch 29/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6724 - dice_coef: 0.6724 - accuracy: 0.9816 - val_loss: -0.4569 - val_dice_coef: 0.4569 - val_accuracy: 0.9762\n",
      "Epoch 30/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6770 - dice_coef: 0.6770 - accuracy: 0.9826 - val_loss: -0.0978 - val_dice_coef: 0.0978 - val_accuracy: 0.9737\n",
      "Epoch 31/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.2747 - dice_coef: 0.2747 - accuracy: 0.9654 - val_loss: -0.2714 - val_dice_coef: 0.2714 - val_accuracy: 0.9730\n",
      "Epoch 32/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2801 - dice_coef: 0.2801 - accuracy: 0.9654 - val_loss: -0.2754 - val_dice_coef: 0.2754 - val_accuracy: 0.9730\n",
      "Epoch 33/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.2815 - dice_coef: 0.2815 - accuracy: 0.9654 - val_loss: -0.2776 - val_dice_coef: 0.2776 - val_accuracy: 0.9730\n",
      "Epoch 34/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.2825 - dice_coef: 0.2825 - accuracy: 0.9654 - val_loss: -0.2789 - val_dice_coef: 0.2789 - val_accuracy: 0.9730\n",
      "Epoch 35/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.2834 - dice_coef: 0.2834 - accuracy: 0.9654 - val_loss: -0.2797 - val_dice_coef: 0.2797 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 36/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.2840 - dice_coef: 0.2840 - accuracy: 0.9654 - val_loss: -0.2806 - val_dice_coef: 0.2806 - val_accuracy: 0.9730\n",
      "Epoch 37/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2845 - dice_coef: 0.2845 - accuracy: 0.9654 - val_loss: -0.2813 - val_dice_coef: 0.2813 - val_accuracy: 0.9730\n",
      "Epoch 38/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2850 - dice_coef: 0.2850 - accuracy: 0.9654 - val_loss: -0.2821 - val_dice_coef: 0.2821 - val_accuracy: 0.9730\n",
      "Epoch 39/50\n",
      "320/320 [==============================] - 37s 117ms/step - loss: -0.2854 - dice_coef: 0.2854 - accuracy: 0.9654 - val_loss: -0.2829 - val_dice_coef: 0.2829 - val_accuracy: 0.9730\n",
      "Epoch 40/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2858 - dice_coef: 0.2858 - accuracy: 0.9654 - val_loss: -0.2834 - val_dice_coef: 0.2834 - val_accuracy: 0.9730\n",
      "Epoch 41/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2862 - dice_coef: 0.2862 - accuracy: 0.9654 - val_loss: -0.2838 - val_dice_coef: 0.2838 - val_accuracy: 0.9730\n",
      "Epoch 42/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2865 - dice_coef: 0.2865 - accuracy: 0.9654 - val_loss: -0.2841 - val_dice_coef: 0.2841 - val_accuracy: 0.9730\n",
      "Epoch 43/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2868 - dice_coef: 0.2868 - accuracy: 0.9654 - val_loss: -0.2845 - val_dice_coef: 0.2845 - val_accuracy: 0.9730\n",
      "Epoch 44/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2871 - dice_coef: 0.2871 - accuracy: 0.9654 - val_loss: -0.2850 - val_dice_coef: 0.2850 - val_accuracy: 0.9730\n",
      "Epoch 45/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.2873 - dice_coef: 0.2873 - accuracy: 0.9654 - val_loss: -0.2853 - val_dice_coef: 0.2853 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_400_samples_r10_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(320, 224, 224, 8)\n",
      "(320, 224, 224, 1)\n",
      "(80, 224, 224, 8)\n",
      "(80, 224, 224, 1)\n",
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "320/320 [==============================] - 16s 51ms/step - loss: -0.1712 - dice_coef: 0.1712 - accuracy: 0.8974 - val_loss: -0.1996 - val_dice_coef: 0.1996 - val_accuracy: 0.9695\n",
      "Epoch 2/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.4215 - dice_coef: 0.4215 - accuracy: 0.9665 - val_loss: -0.3123 - val_dice_coef: 0.3123 - val_accuracy: 0.9301\n",
      "Epoch 3/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5539 - dice_coef: 0.5539 - accuracy: 0.9741 - val_loss: -0.4287 - val_dice_coef: 0.4287 - val_accuracy: 0.9763\n",
      "Epoch 4/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5705 - dice_coef: 0.5705 - accuracy: 0.9747 - val_loss: -0.4349 - val_dice_coef: 0.4349 - val_accuracy: 0.9682\n",
      "Epoch 5/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5800 - dice_coef: 0.5800 - accuracy: 0.9754 - val_loss: -0.4022 - val_dice_coef: 0.4022 - val_accuracy: 0.9815\n",
      "Epoch 6/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.5948 - dice_coef: 0.5948 - accuracy: 0.9762 - val_loss: -0.4400 - val_dice_coef: 0.4400 - val_accuracy: 0.9765\n",
      "Epoch 7/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6045 - dice_coef: 0.6045 - accuracy: 0.9771 - val_loss: -0.4072 - val_dice_coef: 0.4072 - val_accuracy: 0.9823\n",
      "Epoch 8/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6025 - dice_coef: 0.6025 - accuracy: 0.9769 - val_loss: -0.2544 - val_dice_coef: 0.2544 - val_accuracy: 0.7456\n",
      "Epoch 9/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6265 - dice_coef: 0.6265 - accuracy: 0.9776 - val_loss: -0.2465 - val_dice_coef: 0.2465 - val_accuracy: 0.7959\n",
      "Epoch 10/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6155 - dice_coef: 0.6155 - accuracy: 0.9777 - val_loss: -0.3651 - val_dice_coef: 0.3651 - val_accuracy: 0.9188\n",
      "Epoch 11/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6187 - dice_coef: 0.6187 - accuracy: 0.9777 - val_loss: -0.4507 - val_dice_coef: 0.4507 - val_accuracy: 0.9811\n",
      "Epoch 12/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6279 - dice_coef: 0.6279 - accuracy: 0.9784 - val_loss: -0.3954 - val_dice_coef: 0.3954 - val_accuracy: 0.9812\n",
      "Epoch 13/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6290 - dice_coef: 0.6290 - accuracy: 0.9784 - val_loss: -0.3578 - val_dice_coef: 0.3578 - val_accuracy: 0.9812\n",
      "Epoch 14/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6394 - dice_coef: 0.6394 - accuracy: 0.9784 - val_loss: -0.3943 - val_dice_coef: 0.3943 - val_accuracy: 0.9704\n",
      "Epoch 15/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6238 - dice_coef: 0.6238 - accuracy: 0.9778 - val_loss: -0.3954 - val_dice_coef: 0.3954 - val_accuracy: 0.9667\n",
      "Epoch 16/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6059 - dice_coef: 0.6059 - accuracy: 0.9777 - val_loss: -0.4507 - val_dice_coef: 0.4507 - val_accuracy: 0.9813\n",
      "Epoch 17/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6270 - dice_coef: 0.6270 - accuracy: 0.9783 - val_loss: -0.4033 - val_dice_coef: 0.4033 - val_accuracy: 0.9822\n",
      "Epoch 18/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6338 - dice_coef: 0.6338 - accuracy: 0.9787 - val_loss: -0.4289 - val_dice_coef: 0.4289 - val_accuracy: 0.9819\n",
      "Epoch 19/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6256 - dice_coef: 0.6256 - accuracy: 0.9788 - val_loss: -0.3035 - val_dice_coef: 0.3035 - val_accuracy: 0.8187\n",
      "Epoch 20/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6278 - dice_coef: 0.6278 - accuracy: 0.9788 - val_loss: -0.3153 - val_dice_coef: 0.3153 - val_accuracy: 0.8487\n",
      "Epoch 21/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6378 - dice_coef: 0.6378 - accuracy: 0.9794 - val_loss: -0.4379 - val_dice_coef: 0.4379 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 22/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6308 - dice_coef: 0.6308 - accuracy: 0.9791 - val_loss: -0.4279 - val_dice_coef: 0.4279 - val_accuracy: 0.9825\n",
      "Epoch 23/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6125 - dice_coef: 0.6125 - accuracy: 0.9783 - val_loss: -0.2773 - val_dice_coef: 0.2773 - val_accuracy: 0.7918\n",
      "Epoch 24/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6456 - dice_coef: 0.6456 - accuracy: 0.9798 - val_loss: -0.2362 - val_dice_coef: 0.2362 - val_accuracy: 0.7562\n",
      "Epoch 25/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6483 - dice_coef: 0.6483 - accuracy: 0.9791 - val_loss: -0.3988 - val_dice_coef: 0.3988 - val_accuracy: 0.9804\n",
      "Epoch 26/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6249 - dice_coef: 0.6249 - accuracy: 0.9790 - val_loss: -0.2582 - val_dice_coef: 0.2582 - val_accuracy: 0.8308\n",
      "Epoch 27/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6444 - dice_coef: 0.6444 - accuracy: 0.9796 - val_loss: -0.3190 - val_dice_coef: 0.3190 - val_accuracy: 0.8799\n",
      "Epoch 28/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6139 - dice_coef: 0.6139 - accuracy: 0.9784 - val_loss: -0.4359 - val_dice_coef: 0.4359 - val_accuracy: 0.9824\n",
      "Epoch 29/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6509 - dice_coef: 0.6509 - accuracy: 0.9797 - val_loss: -0.2650 - val_dice_coef: 0.2650 - val_accuracy: 0.7559\n",
      "Epoch 30/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6188 - dice_coef: 0.6188 - accuracy: 0.9792 - val_loss: -0.2768 - val_dice_coef: 0.2768 - val_accuracy: 0.8213\n",
      "Epoch 31/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6263 - dice_coef: 0.6263 - accuracy: 0.9795 - val_loss: -0.3342 - val_dice_coef: 0.3342 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 32/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6429 - dice_coef: 0.6429 - accuracy: 0.9794 - val_loss: -0.2773 - val_dice_coef: 0.2773 - val_accuracy: 0.8114\n",
      "Epoch 33/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6495 - dice_coef: 0.6495 - accuracy: 0.9793 - val_loss: -0.2849 - val_dice_coef: 0.2849 - val_accuracy: 0.8427\n",
      "Epoch 34/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6450 - dice_coef: 0.6450 - accuracy: 0.9796 - val_loss: -0.3921 - val_dice_coef: 0.3921 - val_accuracy: 0.9466\n",
      "Epoch 35/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6571 - dice_coef: 0.6571 - accuracy: 0.9800 - val_loss: -0.3842 - val_dice_coef: 0.3842 - val_accuracy: 0.9488\n",
      "Epoch 36/50\n",
      "320/320 [==============================] - 12s 38ms/step - loss: -0.6335 - dice_coef: 0.6335 - accuracy: 0.9793 - val_loss: -0.4078 - val_dice_coef: 0.4078 - val_accuracy: 0.9599\n",
      "Train on 320 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "320/320 [==============================] - 47s 145ms/step - loss: -0.4936 - dice_coef: 0.4936 - accuracy: 0.9726 - val_loss: -0.3891 - val_dice_coef: 0.3891 - val_accuracy: 0.7655\n",
      "Epoch 2/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.5363 - dice_coef: 0.5363 - accuracy: 0.9786 - val_loss: -0.3551 - val_dice_coef: 0.3551 - val_accuracy: 0.7707\n",
      "Epoch 3/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5502 - dice_coef: 0.5502 - accuracy: 0.9807 - val_loss: -0.4979 - val_dice_coef: 0.4979 - val_accuracy: 0.9787\n",
      "Epoch 4/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5672 - dice_coef: 0.5672 - accuracy: 0.9827 - val_loss: -0.4377 - val_dice_coef: 0.4377 - val_accuracy: 0.9666\n",
      "Epoch 5/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5753 - dice_coef: 0.5753 - accuracy: 0.9844 - val_loss: -0.4436 - val_dice_coef: 0.4436 - val_accuracy: 0.9793\n",
      "Epoch 6/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5899 - dice_coef: 0.5899 - accuracy: 0.9865 - val_loss: -0.5942 - val_dice_coef: 0.5942 - val_accuracy: 0.9819\n",
      "Epoch 7/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5661 - dice_coef: 0.5661 - accuracy: 0.9849 - val_loss: -0.3458 - val_dice_coef: 0.3458 - val_accuracy: 0.7921\n",
      "Epoch 8/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.5848 - dice_coef: 0.5848 - accuracy: 0.9844 - val_loss: -0.4933 - val_dice_coef: 0.4933 - val_accuracy: 0.9764\n",
      "Epoch 9/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6770 - dice_coef: 0.6770 - accuracy: 0.9878 - val_loss: -0.5178 - val_dice_coef: 0.5178 - val_accuracy: 0.9816\n",
      "Epoch 10/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.6304 - dice_coef: 0.6304 - accuracy: 0.9840 - val_loss: -0.3719 - val_dice_coef: 0.3719 - val_accuracy: 0.7571\n",
      "Epoch 11/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6669 - dice_coef: 0.6669 - accuracy: 0.9847 - val_loss: -0.3911 - val_dice_coef: 0.3911 - val_accuracy: 0.8939\n",
      "Epoch 12/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6854 - dice_coef: 0.6854 - accuracy: 0.9852 - val_loss: -0.3697 - val_dice_coef: 0.3697 - val_accuracy: 0.8482\n",
      "Epoch 13/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6578 - dice_coef: 0.6578 - accuracy: 0.9831 - val_loss: -0.3542 - val_dice_coef: 0.3542 - val_accuracy: 0.9483\n",
      "Epoch 14/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6544 - dice_coef: 0.6544 - accuracy: 0.9816 - val_loss: -0.4506 - val_dice_coef: 0.4506 - val_accuracy: 0.9393\n",
      "Epoch 15/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6253 - dice_coef: 0.6253 - accuracy: 0.9833 - val_loss: -0.3582 - val_dice_coef: 0.3582 - val_accuracy: 0.7690\n",
      "Epoch 16/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.6737 - dice_coef: 0.6737 - accuracy: 0.9825 - val_loss: -0.3969 - val_dice_coef: 0.3969 - val_accuracy: 0.7334\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 17/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7044 - dice_coef: 0.7044 - accuracy: 0.9843 - val_loss: -0.3879 - val_dice_coef: 0.3879 - val_accuracy: 0.7367\n",
      "Epoch 18/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.7434 - dice_coef: 0.7434 - accuracy: 0.9857 - val_loss: -0.3905 - val_dice_coef: 0.3905 - val_accuracy: 0.7361\n",
      "Epoch 19/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7491 - dice_coef: 0.7491 - accuracy: 0.9867 - val_loss: -0.3634 - val_dice_coef: 0.3634 - val_accuracy: 0.7450\n",
      "Epoch 20/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7745 - dice_coef: 0.7745 - accuracy: 0.9876 - val_loss: -0.4242 - val_dice_coef: 0.4242 - val_accuracy: 0.8044\n",
      "Epoch 21/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.7936 - dice_coef: 0.7936 - accuracy: 0.9886 - val_loss: -0.4190 - val_dice_coef: 0.4190 - val_accuracy: 0.8168\n",
      "Epoch 22/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.8088 - dice_coef: 0.8088 - accuracy: 0.9897 - val_loss: -0.3984 - val_dice_coef: 0.3984 - val_accuracy: 0.7981\n",
      "Epoch 23/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.8219 - dice_coef: 0.8219 - accuracy: 0.9905 - val_loss: -0.4284 - val_dice_coef: 0.4284 - val_accuracy: 0.7985\n",
      "Epoch 24/50\n",
      "320/320 [==============================] - 38s 118ms/step - loss: -0.8348 - dice_coef: 0.8348 - accuracy: 0.9911 - val_loss: -0.4203 - val_dice_coef: 0.4203 - val_accuracy: 0.8381\n",
      "Epoch 25/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.8432 - dice_coef: 0.8432 - accuracy: 0.9915 - val_loss: -0.4011 - val_dice_coef: 0.4011 - val_accuracy: 0.8272\n",
      "Epoch 26/50\n",
      "320/320 [==============================] - 38s 119ms/step - loss: -0.8523 - dice_coef: 0.8523 - accuracy: 0.9922 - val_loss: -0.3947 - val_dice_coef: 0.3947 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r1_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 19s 48ms/step - loss: -0.1982 - dice_coef: 0.1982 - accuracy: 0.8037 - val_loss: -0.2108 - val_dice_coef: 0.2108 - val_accuracy: 0.9433\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.4715 - dice_coef: 0.4715 - accuracy: 0.9671 - val_loss: -0.3535 - val_dice_coef: 0.3535 - val_accuracy: 0.9677\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5710 - dice_coef: 0.5710 - accuracy: 0.9732 - val_loss: -0.3154 - val_dice_coef: 0.3154 - val_accuracy: 0.8947\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6045 - dice_coef: 0.6045 - accuracy: 0.9745 - val_loss: -0.3007 - val_dice_coef: 0.3007 - val_accuracy: 0.9122\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5968 - dice_coef: 0.5968 - accuracy: 0.9742 - val_loss: -0.2348 - val_dice_coef: 0.2348 - val_accuracy: 0.8319\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6073 - dice_coef: 0.6073 - accuracy: 0.9748 - val_loss: -0.3556 - val_dice_coef: 0.3556 - val_accuracy: 0.9825\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6203 - dice_coef: 0.6203 - accuracy: 0.9753 - val_loss: -0.3075 - val_dice_coef: 0.3075 - val_accuracy: 0.9824\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6028 - dice_coef: 0.6028 - accuracy: 0.9747 - val_loss: -0.4176 - val_dice_coef: 0.4176 - val_accuracy: 0.9802\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6143 - dice_coef: 0.6143 - accuracy: 0.9758 - val_loss: -0.3454 - val_dice_coef: 0.3454 - val_accuracy: 0.9825\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6191 - dice_coef: 0.6191 - accuracy: 0.9762 - val_loss: -0.3151 - val_dice_coef: 0.3151 - val_accuracy: 0.9818\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6170 - dice_coef: 0.6170 - accuracy: 0.9767 - val_loss: -0.3959 - val_dice_coef: 0.3959 - val_accuracy: 0.9824\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6181 - dice_coef: 0.6181 - accuracy: 0.9765 - val_loss: -0.2963 - val_dice_coef: 0.2963 - val_accuracy: 0.9819\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6361 - dice_coef: 0.6361 - accuracy: 0.9777 - val_loss: -0.3499 - val_dice_coef: 0.3499 - val_accuracy: 0.9820\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5981 - dice_coef: 0.5981 - accuracy: 0.9761 - val_loss: -0.3409 - val_dice_coef: 0.3409 - val_accuracy: 0.9820\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6428 - dice_coef: 0.6428 - accuracy: 0.9777 - val_loss: -0.3763 - val_dice_coef: 0.3763 - val_accuracy: 0.9821\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6277 - dice_coef: 0.6277 - accuracy: 0.9773 - val_loss: -0.2966 - val_dice_coef: 0.2966 - val_accuracy: 0.9814\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6390 - dice_coef: 0.6390 - accuracy: 0.9776 - val_loss: -0.3630 - val_dice_coef: 0.3630 - val_accuracy: 0.9826\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6328 - dice_coef: 0.6328 - accuracy: 0.9773 - val_loss: -0.3249 - val_dice_coef: 0.3249 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6364 - dice_coef: 0.6364 - accuracy: 0.9778 - val_loss: -0.3833 - val_dice_coef: 0.3833 - val_accuracy: 0.9812\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6463 - dice_coef: 0.6463 - accuracy: 0.9779 - val_loss: -0.3623 - val_dice_coef: 0.3623 - val_accuracy: 0.9819\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6406 - dice_coef: 0.6406 - accuracy: 0.9781 - val_loss: -0.3679 - val_dice_coef: 0.3679 - val_accuracy: 0.9816\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6363 - dice_coef: 0.6363 - accuracy: 0.9782 - val_loss: -0.3015 - val_dice_coef: 0.3015 - val_accuracy: 0.9809\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6317 - dice_coef: 0.6317 - accuracy: 0.9777 - val_loss: -0.3221 - val_dice_coef: 0.3221 - val_accuracy: 0.9816\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6341 - dice_coef: 0.6341 - accuracy: 0.9780 - val_loss: -0.2578 - val_dice_coef: 0.2578 - val_accuracy: 0.9802\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6344 - dice_coef: 0.6344 - accuracy: 0.9785 - val_loss: -0.3727 - val_dice_coef: 0.3727 - val_accuracy: 0.9823\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6380 - dice_coef: 0.6380 - accuracy: 0.9781 - val_loss: -0.3626 - val_dice_coef: 0.3626 - val_accuracy: 0.9816\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6615 - dice_coef: 0.6615 - accuracy: 0.9787 - val_loss: -0.3603 - val_dice_coef: 0.3603 - val_accuracy: 0.9808\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6239 - dice_coef: 0.6239 - accuracy: 0.9773 - val_loss: -0.3729 - val_dice_coef: 0.3729 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 140ms/step - loss: -0.5163 - dice_coef: 0.5163 - accuracy: 0.9725 - val_loss: -0.4181 - val_dice_coef: 0.4181 - val_accuracy: 0.9714\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5565 - dice_coef: 0.5565 - accuracy: 0.9775 - val_loss: -0.5463 - val_dice_coef: 0.5463 - val_accuracy: 0.9790\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5817 - dice_coef: 0.5817 - accuracy: 0.9810 - val_loss: -0.4985 - val_dice_coef: 0.4985 - val_accuracy: 0.9832\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5936 - dice_coef: 0.5936 - accuracy: 0.9825 - val_loss: -0.5178 - val_dice_coef: 0.5178 - val_accuracy: 0.9825\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5959 - dice_coef: 0.5959 - accuracy: 0.9832 - val_loss: -0.5144 - val_dice_coef: 0.5144 - val_accuracy: 0.9811\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6104 - dice_coef: 0.6104 - accuracy: 0.9839 - val_loss: -0.5005 - val_dice_coef: 0.5005 - val_accuracy: 0.9828\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6235 - dice_coef: 0.6235 - accuracy: 0.9864 - val_loss: -0.5179 - val_dice_coef: 0.5179 - val_accuracy: 0.9835\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6240 - dice_coef: 0.6240 - accuracy: 0.9864 - val_loss: -0.5392 - val_dice_coef: 0.5392 - val_accuracy: 0.9834\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5372 - dice_coef: 0.5372 - accuracy: 0.9812 - val_loss: -0.4597 - val_dice_coef: 0.4597 - val_accuracy: 0.9791\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5115 - dice_coef: 0.5115 - accuracy: 0.9763 - val_loss: -0.4412 - val_dice_coef: 0.4412 - val_accuracy: 0.9823\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5703 - dice_coef: 0.5703 - accuracy: 0.9810 - val_loss: -0.4358 - val_dice_coef: 0.4358 - val_accuracy: 0.9803\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5650 - dice_coef: 0.5650 - accuracy: 0.9793 - val_loss: -0.5347 - val_dice_coef: 0.5347 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6670 - dice_coef: 0.6670 - accuracy: 0.9824 - val_loss: -0.5578 - val_dice_coef: 0.5578 - val_accuracy: 0.9834\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7091 - dice_coef: 0.7091 - accuracy: 0.9856 - val_loss: -0.5424 - val_dice_coef: 0.5424 - val_accuracy: 0.9835\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7109 - dice_coef: 0.7109 - accuracy: 0.9852 - val_loss: -0.5545 - val_dice_coef: 0.5545 - val_accuracy: 0.9820\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7266 - dice_coef: 0.7266 - accuracy: 0.9855 - val_loss: -0.5843 - val_dice_coef: 0.5843 - val_accuracy: 0.9826\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7525 - dice_coef: 0.7525 - accuracy: 0.9871 - val_loss: -0.5893 - val_dice_coef: 0.5893 - val_accuracy: 0.9835\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6778 - dice_coef: 0.6778 - accuracy: 0.9819 - val_loss: -0.5671 - val_dice_coef: 0.5671 - val_accuracy: 0.9820\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6863 - dice_coef: 0.6863 - accuracy: 0.9825 - val_loss: -0.4599 - val_dice_coef: 0.4599 - val_accuracy: 0.9792\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6966 - dice_coef: 0.6966 - accuracy: 0.9818 - val_loss: -0.5023 - val_dice_coef: 0.5023 - val_accuracy: 0.9818\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7364 - dice_coef: 0.7364 - accuracy: 0.9844 - val_loss: -0.5682 - val_dice_coef: 0.5682 - val_accuracy: 0.9827\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7869 - dice_coef: 0.7869 - accuracy: 0.9870 - val_loss: -0.5810 - val_dice_coef: 0.5810 - val_accuracy: 0.9820\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8026 - dice_coef: 0.8026 - accuracy: 0.9880 - val_loss: -0.5726 - val_dice_coef: 0.5726 - val_accuracy: 0.9816\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.8184 - dice_coef: 0.8184 - accuracy: 0.9886 - val_loss: -0.5586 - val_dice_coef: 0.5586 - val_accuracy: 0.9824\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7066 - dice_coef: 0.7066 - accuracy: 0.9840 - val_loss: -0.4753 - val_dice_coef: 0.4753 - val_accuracy: 0.9798\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6399 - dice_coef: 0.6399 - accuracy: 0.9780 - val_loss: -0.5453 - val_dice_coef: 0.5453 - val_accuracy: 0.9822\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6564 - dice_coef: 0.6564 - accuracy: 0.9796 - val_loss: -0.5408 - val_dice_coef: 0.5408 - val_accuracy: 0.9804\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7326 - dice_coef: 0.7326 - accuracy: 0.9822 - val_loss: -0.5907 - val_dice_coef: 0.5907 - val_accuracy: 0.9830\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7558 - dice_coef: 0.7558 - accuracy: 0.9844 - val_loss: -0.5780 - val_dice_coef: 0.5780 - val_accuracy: 0.9832\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7968 - dice_coef: 0.7968 - accuracy: 0.9871 - val_loss: -0.5781 - val_dice_coef: 0.5781 - val_accuracy: 0.9837\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8273 - dice_coef: 0.8273 - accuracy: 0.9888 - val_loss: -0.6030 - val_dice_coef: 0.6030 - val_accuracy: 0.9833\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8373 - dice_coef: 0.8373 - accuracy: 0.9897 - val_loss: -0.6102 - val_dice_coef: 0.6102 - val_accuracy: 0.9835\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8549 - dice_coef: 0.8549 - accuracy: 0.9904 - val_loss: -0.6127 - val_dice_coef: 0.6127 - val_accuracy: 0.9834\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7154 - dice_coef: 0.7154 - accuracy: 0.9828 - val_loss: -0.6098 - val_dice_coef: 0.6098 - val_accuracy: 0.9818\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7993 - dice_coef: 0.7993 - accuracy: 0.9867 - val_loss: -0.5899 - val_dice_coef: 0.5899 - val_accuracy: 0.9824\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8222 - dice_coef: 0.8222 - accuracy: 0.9885 - val_loss: -0.6169 - val_dice_coef: 0.6169 - val_accuracy: 0.9841\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8179 - dice_coef: 0.8179 - accuracy: 0.9888 - val_loss: -0.5766 - val_dice_coef: 0.5766 - val_accuracy: 0.9816\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7905 - dice_coef: 0.7905 - accuracy: 0.9866 - val_loss: -0.5844 - val_dice_coef: 0.5844 - val_accuracy: 0.9825\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8457 - dice_coef: 0.8457 - accuracy: 0.9895 - val_loss: -0.5770 - val_dice_coef: 0.5770 - val_accuracy: 0.9822\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7942 - dice_coef: 0.7942 - accuracy: 0.9866 - val_loss: -0.5849 - val_dice_coef: 0.5849 - val_accuracy: 0.9831\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8625 - dice_coef: 0.8625 - accuracy: 0.9905 - val_loss: -0.6069 - val_dice_coef: 0.6069 - val_accuracy: 0.9838\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8765 - dice_coef: 0.8765 - accuracy: 0.9914 - val_loss: -0.5940 - val_dice_coef: 0.5940 - val_accuracy: 0.9833\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8837 - dice_coef: 0.8837 - accuracy: 0.9919 - val_loss: -0.6061 - val_dice_coef: 0.6061 - val_accuracy: 0.9837\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8908 - dice_coef: 0.8908 - accuracy: 0.9924 - val_loss: -0.5921 - val_dice_coef: 0.5921 - val_accuracy: 0.9838\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8962 - dice_coef: 0.8962 - accuracy: 0.9928 - val_loss: -0.6133 - val_dice_coef: 0.6133 - val_accuracy: 0.9839\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.7526 - dice_coef: 0.7526 - accuracy: 0.9852 - val_loss: -0.5126 - val_dice_coef: 0.5126 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.2313700608501676e-05.\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8021 - dice_coef: 0.8021 - accuracy: 0.9869 - val_loss: -0.5774 - val_dice_coef: 0.5774 - val_accuracy: 0.9826\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8456 - dice_coef: 0.8456 - accuracy: 0.9891 - val_loss: -0.6051 - val_dice_coef: 0.6051 - val_accuracy: 0.9834\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8691 - dice_coef: 0.8691 - accuracy: 0.9905 - val_loss: -0.5902 - val_dice_coef: 0.5902 - val_accuracy: 0.9827\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.8818 - dice_coef: 0.8818 - accuracy: 0.9916 - val_loss: -0.6082 - val_dice_coef: 0.6082 - val_accuracy: 0.9832\n",
      "model_fine_tuning_No_NAIP_500_samples_r2_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 19s 48ms/step - loss: -0.1676 - dice_coef: 0.1676 - accuracy: 0.6942 - val_loss: -0.1554 - val_dice_coef: 0.1554 - val_accuracy: 0.8231\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.4650 - dice_coef: 0.4650 - accuracy: 0.9670 - val_loss: -0.3479 - val_dice_coef: 0.3479 - val_accuracy: 0.9650\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5646 - dice_coef: 0.5646 - accuracy: 0.9725 - val_loss: -0.2695 - val_dice_coef: 0.2695 - val_accuracy: 0.8410\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5819 - dice_coef: 0.5819 - accuracy: 0.9736 - val_loss: -0.4179 - val_dice_coef: 0.4179 - val_accuracy: 0.9665\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6038 - dice_coef: 0.6038 - accuracy: 0.9753 - val_loss: -0.3631 - val_dice_coef: 0.3631 - val_accuracy: 0.9139\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6096 - dice_coef: 0.6096 - accuracy: 0.9756 - val_loss: -0.4211 - val_dice_coef: 0.4211 - val_accuracy: 0.9743\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6219 - dice_coef: 0.6219 - accuracy: 0.9759 - val_loss: -0.3417 - val_dice_coef: 0.3417 - val_accuracy: 0.8921\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1655 - dice_coef: 0.1655 - accuracy: 0.9058 - val_loss: -0.0056 - val_dice_coef: 0.0056 - val_accuracy: 0.9770\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0317 - dice_coef: 0.0317 - accuracy: 0.8850 - val_loss: -0.0056 - val_dice_coef: 0.0056 - val_accuracy: 0.9770\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0321 - dice_coef: 0.0321 - accuracy: 0.8844 - val_loss: -0.0055 - val_dice_coef: 0.0055 - val_accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0322 - dice_coef: 0.0322 - accuracy: 0.8838 - val_loss: -0.0054 - val_dice_coef: 0.0054 - val_accuracy: 0.9770\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0324 - dice_coef: 0.0324 - accuracy: 0.8836 - val_loss: -0.0054 - val_dice_coef: 0.0054 - val_accuracy: 0.9770\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0326 - dice_coef: 0.0326 - accuracy: 0.8833 - val_loss: -0.0053 - val_dice_coef: 0.0053 - val_accuracy: 0.9770\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0324 - dice_coef: 0.0324 - accuracy: 0.8830 - val_loss: -0.0052 - val_dice_coef: 0.0052 - val_accuracy: 0.9770\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0325 - dice_coef: 0.0325 - accuracy: 0.8828 - val_loss: -0.0052 - val_dice_coef: 0.0052 - val_accuracy: 0.9770\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0328 - dice_coef: 0.0328 - accuracy: 0.8825 - val_loss: -0.0051 - val_dice_coef: 0.0051 - val_accuracy: 0.9770\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0326 - dice_coef: 0.0326 - accuracy: 0.8824 - val_loss: -0.0050 - val_dice_coef: 0.0050 - val_accuracy: 0.9770\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0327 - dice_coef: 0.0327 - accuracy: 0.8822 - val_loss: -0.0050 - val_dice_coef: 0.0050 - val_accuracy: 0.9770\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0327 - dice_coef: 0.0327 - accuracy: 0.8821 - val_loss: -0.0049 - val_dice_coef: 0.0049 - val_accuracy: 0.9770\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0328 - dice_coef: 0.0328 - accuracy: 0.8820 - val_loss: -0.0048 - val_dice_coef: 0.0048 - val_accuracy: 0.9770\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0331 - dice_coef: 0.0331 - accuracy: 0.8819 - val_loss: -0.0048 - val_dice_coef: 0.0048 - val_accuracy: 0.9770\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0328 - dice_coef: 0.0328 - accuracy: 0.8818 - val_loss: -0.0047 - val_dice_coef: 0.0047 - val_accuracy: 0.9770\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0324 - dice_coef: 0.0324 - accuracy: 0.8817 - val_loss: -0.0046 - val_dice_coef: 0.0046 - val_accuracy: 0.9770\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0328 - dice_coef: 0.0328 - accuracy: 0.8817 - val_loss: -0.0045 - val_dice_coef: 0.0045 - val_accuracy: 0.9770\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0326 - dice_coef: 0.0326 - accuracy: 0.8815 - val_loss: -0.0044 - val_dice_coef: 0.0044 - val_accuracy: 0.9770\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.0325 - dice_coef: 0.0325 - accuracy: 0.8815 - val_loss: -0.0043 - val_dice_coef: 0.0043 - val_accuracy: 0.9770\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 139ms/step - loss: -0.0681 - dice_coef: 0.0681 - accuracy: 0.8528 - val_loss: -0.0066 - val_dice_coef: 0.0066 - val_accuracy: 0.9768\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1098 - dice_coef: 0.1098 - accuracy: 0.8566 - val_loss: -0.0129 - val_dice_coef: 0.0129 - val_accuracy: 0.9768\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1109 - dice_coef: 0.1109 - accuracy: 0.8607 - val_loss: -0.0053 - val_dice_coef: 0.0053 - val_accuracy: 0.9707\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1118 - dice_coef: 0.1118 - accuracy: 0.8659 - val_loss: -0.0060 - val_dice_coef: 0.0060 - val_accuracy: 0.9561\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1116 - dice_coef: 0.1116 - accuracy: 0.8611 - val_loss: -0.0059 - val_dice_coef: 0.0059 - val_accuracy: 0.9666\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1110 - dice_coef: 0.1110 - accuracy: 0.8643 - val_loss: -0.0048 - val_dice_coef: 0.0048 - val_accuracy: 0.9767\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1118 - dice_coef: 0.1118 - accuracy: 0.8786 - val_loss: -0.0320 - val_dice_coef: 0.0320 - val_accuracy: 0.9770\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1121 - dice_coef: 0.1121 - accuracy: 0.8770 - val_loss: -0.0232 - val_dice_coef: 0.0232 - val_accuracy: 0.9770\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.1127 - dice_coef: 0.1127 - accuracy: 0.8775 - val_loss: -0.0039 - val_dice_coef: 0.0039 - val_accuracy: 0.9698\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1123 - dice_coef: 0.1123 - accuracy: 0.8740 - val_loss: -0.0505 - val_dice_coef: 0.0505 - val_accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1123 - dice_coef: 0.1123 - accuracy: 0.8569 - val_loss: -0.0486 - val_dice_coef: 0.0486 - val_accuracy: 0.9770\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1127 - dice_coef: 0.1127 - accuracy: 0.8669 - val_loss: -0.0451 - val_dice_coef: 0.0451 - val_accuracy: 0.5943\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.1129 - dice_coef: 0.1129 - accuracy: 0.8762 - val_loss: -0.0522 - val_dice_coef: 0.0522 - val_accuracy: 0.9770\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1133 - dice_coef: 0.1133 - accuracy: 0.8751 - val_loss: -0.0599 - val_dice_coef: 0.0599 - val_accuracy: 0.9770\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1130 - dice_coef: 0.1130 - accuracy: 0.8723 - val_loss: -0.0041 - val_dice_coef: 0.0041 - val_accuracy: 0.9729\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.1134 - dice_coef: 0.1134 - accuracy: 0.8766 - val_loss: -0.0589 - val_dice_coef: 0.0589 - val_accuracy: 0.9770\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.1136 - dice_coef: 0.1136 - accuracy: 0.8779 - val_loss: -0.0042 - val_dice_coef: 0.0042 - val_accuracy: 0.9730\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1136 - dice_coef: 0.1136 - accuracy: 0.8819 - val_loss: -0.0391 - val_dice_coef: 0.0391 - val_accuracy: 0.9770\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1133 - dice_coef: 0.1133 - accuracy: 0.8745 - val_loss: -0.0914 - val_dice_coef: 0.0914 - val_accuracy: 0.9770\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1139 - dice_coef: 0.1139 - accuracy: 0.8755 - val_loss: -0.0758 - val_dice_coef: 0.0758 - val_accuracy: 0.9770\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1139 - dice_coef: 0.1139 - accuracy: 0.8795 - val_loss: -0.0937 - val_dice_coef: 0.0937 - val_accuracy: 0.9770\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1140 - dice_coef: 0.1140 - accuracy: 0.8768 - val_loss: -0.0857 - val_dice_coef: 0.0857 - val_accuracy: 0.9770\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1137 - dice_coef: 0.1137 - accuracy: 0.8763 - val_loss: -0.0406 - val_dice_coef: 0.0406 - val_accuracy: 0.9770\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1137 - dice_coef: 0.1137 - accuracy: 0.8792 - val_loss: -0.0245 - val_dice_coef: 0.0245 - val_accuracy: 0.9770\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1145 - dice_coef: 0.1145 - accuracy: 0.8788 - val_loss: -0.0863 - val_dice_coef: 0.0863 - val_accuracy: 0.9770\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1146 - dice_coef: 0.1146 - accuracy: 0.8764 - val_loss: -0.0997 - val_dice_coef: 0.0997 - val_accuracy: 0.9770\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1145 - dice_coef: 0.1145 - accuracy: 0.8779 - val_loss: -0.0602 - val_dice_coef: 0.0602 - val_accuracy: 0.9770\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1147 - dice_coef: 0.1147 - accuracy: 0.8779 - val_loss: -0.0099 - val_dice_coef: 0.0099 - val_accuracy: 0.9770\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1147 - dice_coef: 0.1147 - accuracy: 0.8766 - val_loss: -0.1511 - val_dice_coef: 0.1511 - val_accuracy: 0.9770\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1139 - dice_coef: 0.1139 - accuracy: 0.8721 - val_loss: -0.1438 - val_dice_coef: 0.1438 - val_accuracy: 0.9770\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1142 - dice_coef: 0.1142 - accuracy: 0.8721 - val_loss: -0.1537 - val_dice_coef: 0.1537 - val_accuracy: 0.9770\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1145 - dice_coef: 0.1145 - accuracy: 0.8723 - val_loss: -0.1577 - val_dice_coef: 0.1577 - val_accuracy: 0.9770\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1147 - dice_coef: 0.1147 - accuracy: 0.8786 - val_loss: -0.1706 - val_dice_coef: 0.1706 - val_accuracy: 0.9770\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1149 - dice_coef: 0.1149 - accuracy: 0.8760 - val_loss: -0.1682 - val_dice_coef: 0.1682 - val_accuracy: 0.9770\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1150 - dice_coef: 0.1150 - accuracy: 0.8780 - val_loss: -0.1796 - val_dice_coef: 0.1796 - val_accuracy: 0.9770\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1149 - dice_coef: 0.1149 - accuracy: 0.8761 - val_loss: -0.1807 - val_dice_coef: 0.1807 - val_accuracy: 0.9770\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1149 - dice_coef: 0.1149 - accuracy: 0.8770 - val_loss: -0.1897 - val_dice_coef: 0.1897 - val_accuracy: 0.9770\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1149 - dice_coef: 0.1149 - accuracy: 0.8781 - val_loss: -0.2005 - val_dice_coef: 0.2005 - val_accuracy: 0.9770\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1152 - dice_coef: 0.1152 - accuracy: 0.8785 - val_loss: -0.2004 - val_dice_coef: 0.2004 - val_accuracy: 0.9770\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1150 - dice_coef: 0.1150 - accuracy: 0.8780 - val_loss: -0.2149 - val_dice_coef: 0.2149 - val_accuracy: 0.9770\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1150 - dice_coef: 0.1150 - accuracy: 0.8769 - val_loss: -0.0593 - val_dice_coef: 0.0593 - val_accuracy: 0.9770\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1150 - dice_coef: 0.1150 - accuracy: 0.8773 - val_loss: -0.2409 - val_dice_coef: 0.2409 - val_accuracy: 0.9770\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1150 - dice_coef: 0.1150 - accuracy: 0.8779 - val_loss: -0.2333 - val_dice_coef: 0.2333 - val_accuracy: 0.9770\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1148 - dice_coef: 0.1148 - accuracy: 0.8759 - val_loss: -0.2503 - val_dice_coef: 0.2503 - val_accuracy: 0.9770\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1140 - dice_coef: 0.1140 - accuracy: 0.8764 - val_loss: -0.2514 - val_dice_coef: 0.2514 - val_accuracy: 0.9770\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1141 - dice_coef: 0.1141 - accuracy: 0.8744 - val_loss: -0.2725 - val_dice_coef: 0.2725 - val_accuracy: 0.9770\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1141 - dice_coef: 0.1141 - accuracy: 0.8765 - val_loss: -0.2799 - val_dice_coef: 0.2799 - val_accuracy: 0.9770\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1147 - dice_coef: 0.1147 - accuracy: 0.8768 - val_loss: -0.2779 - val_dice_coef: 0.2779 - val_accuracy: 0.9770\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1148 - dice_coef: 0.1148 - accuracy: 0.8801 - val_loss: -0.2815 - val_dice_coef: 0.2815 - val_accuracy: 0.9770\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.1152 - dice_coef: 0.1152 - accuracy: 0.8758 - val_loss: -0.2720 - val_dice_coef: 0.2720 - val_accuracy: 0.9770\n",
      "model_fine_tuning_No_NAIP_500_samples_r3_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 19s 48ms/step - loss: -0.3276 - dice_coef: 0.3276 - accuracy: 0.9582 - val_loss: -0.0801 - val_dice_coef: 0.0801 - val_accuracy: 0.4277\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.5137 - dice_coef: 0.5137 - accuracy: 0.9669 - val_loss: -0.3542 - val_dice_coef: 0.3542 - val_accuracy: 0.9722\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5702 - dice_coef: 0.5702 - accuracy: 0.9720 - val_loss: -0.3115 - val_dice_coef: 0.3115 - val_accuracy: 0.9336\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.5953 - dice_coef: 0.5953 - accuracy: 0.9733 - val_loss: -0.2728 - val_dice_coef: 0.2728 - val_accuracy: 0.9836\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5948 - dice_coef: 0.5948 - accuracy: 0.9736 - val_loss: -0.3107 - val_dice_coef: 0.3107 - val_accuracy: 0.9841\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6229 - dice_coef: 0.6229 - accuracy: 0.9751 - val_loss: -0.3268 - val_dice_coef: 0.3268 - val_accuracy: 0.9813\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6231 - dice_coef: 0.6231 - accuracy: 0.9751 - val_loss: -0.2653 - val_dice_coef: 0.2653 - val_accuracy: 0.9831\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6034 - dice_coef: 0.6034 - accuracy: 0.9744 - val_loss: -0.3338 - val_dice_coef: 0.3338 - val_accuracy: 0.9840\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6138 - dice_coef: 0.6138 - accuracy: 0.9748 - val_loss: -0.3545 - val_dice_coef: 0.3545 - val_accuracy: 0.9834\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6365 - dice_coef: 0.6365 - accuracy: 0.9761 - val_loss: -0.3315 - val_dice_coef: 0.3315 - val_accuracy: 0.9841\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6291 - dice_coef: 0.6291 - accuracy: 0.9757 - val_loss: -0.3639 - val_dice_coef: 0.3639 - val_accuracy: 0.9831\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6275 - dice_coef: 0.6275 - accuracy: 0.9760 - val_loss: -0.3471 - val_dice_coef: 0.3471 - val_accuracy: 0.9838\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6279 - dice_coef: 0.6279 - accuracy: 0.9755 - val_loss: -0.3500 - val_dice_coef: 0.3500 - val_accuracy: 0.9832\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6333 - dice_coef: 0.6333 - accuracy: 0.9758 - val_loss: -0.3594 - val_dice_coef: 0.3594 - val_accuracy: 0.9814\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6363 - dice_coef: 0.6363 - accuracy: 0.9762 - val_loss: -0.3372 - val_dice_coef: 0.3372 - val_accuracy: 0.9787\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6417 - dice_coef: 0.6417 - accuracy: 0.9766 - val_loss: -0.3562 - val_dice_coef: 0.3562 - val_accuracy: 0.9838\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6463 - dice_coef: 0.6463 - accuracy: 0.9765 - val_loss: -0.3748 - val_dice_coef: 0.3748 - val_accuracy: 0.9826\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6508 - dice_coef: 0.6508 - accuracy: 0.9773 - val_loss: -0.3553 - val_dice_coef: 0.3553 - val_accuracy: 0.9839\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6394 - dice_coef: 0.6394 - accuracy: 0.9764 - val_loss: -0.3558 - val_dice_coef: 0.3558 - val_accuracy: 0.9842\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6456 - dice_coef: 0.6456 - accuracy: 0.9770 - val_loss: -0.1742 - val_dice_coef: 0.1742 - val_accuracy: 0.9812\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6413 - dice_coef: 0.6413 - accuracy: 0.9767 - val_loss: -0.2766 - val_dice_coef: 0.2766 - val_accuracy: 0.9547\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6375 - dice_coef: 0.6375 - accuracy: 0.9766 - val_loss: -0.3158 - val_dice_coef: 0.3158 - val_accuracy: 0.9804\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6451 - dice_coef: 0.6451 - accuracy: 0.9769 - val_loss: -0.3834 - val_dice_coef: 0.3834 - val_accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6418 - dice_coef: 0.6418 - accuracy: 0.9771 - val_loss: -0.3953 - val_dice_coef: 0.3953 - val_accuracy: 0.9846\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6423 - dice_coef: 0.6423 - accuracy: 0.9771 - val_loss: -0.4002 - val_dice_coef: 0.4002 - val_accuracy: 0.9843\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6469 - dice_coef: 0.6469 - accuracy: 0.9768 - val_loss: -0.4467 - val_dice_coef: 0.4467 - val_accuracy: 0.9840\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6450 - dice_coef: 0.6450 - accuracy: 0.9775 - val_loss: -0.4582 - val_dice_coef: 0.4582 - val_accuracy: 0.9824\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6386 - dice_coef: 0.6386 - accuracy: 0.9770 - val_loss: -0.3730 - val_dice_coef: 0.3730 - val_accuracy: 0.9837\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6490 - dice_coef: 0.6490 - accuracy: 0.9774 - val_loss: -0.4392 - val_dice_coef: 0.4392 - val_accuracy: 0.9844\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6639 - dice_coef: 0.6639 - accuracy: 0.9778 - val_loss: -0.4080 - val_dice_coef: 0.4080 - val_accuracy: 0.9837\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6598 - dice_coef: 0.6598 - accuracy: 0.9779 - val_loss: -0.5433 - val_dice_coef: 0.5433 - val_accuracy: 0.9846\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 15s 37ms/step - loss: -0.6524 - dice_coef: 0.6524 - accuracy: 0.9775 - val_loss: -0.3788 - val_dice_coef: 0.3788 - val_accuracy: 0.9832\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6560 - dice_coef: 0.6560 - accuracy: 0.9782 - val_loss: -0.4703 - val_dice_coef: 0.4703 - val_accuracy: 0.9841\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6591 - dice_coef: 0.6591 - accuracy: 0.9779 - val_loss: -0.4821 - val_dice_coef: 0.4821 - val_accuracy: 0.9840\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6515 - dice_coef: 0.6515 - accuracy: 0.9774 - val_loss: -0.4694 - val_dice_coef: 0.4694 - val_accuracy: 0.9835\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6523 - dice_coef: 0.6523 - accuracy: 0.9778 - val_loss: -0.3967 - val_dice_coef: 0.3967 - val_accuracy: 0.9830\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6368 - dice_coef: 0.6368 - accuracy: 0.9775 - val_loss: -0.4985 - val_dice_coef: 0.4985 - val_accuracy: 0.9846\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6383 - dice_coef: 0.6383 - accuracy: 0.9772 - val_loss: -0.3015 - val_dice_coef: 0.3015 - val_accuracy: 0.9716\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6552 - dice_coef: 0.6552 - accuracy: 0.9780 - val_loss: -0.4722 - val_dice_coef: 0.4722 - val_accuracy: 0.9836\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6340 - dice_coef: 0.6340 - accuracy: 0.9770 - val_loss: -0.5045 - val_dice_coef: 0.5045 - val_accuracy: 0.9843\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6639 - dice_coef: 0.6639 - accuracy: 0.9781 - val_loss: -0.4949 - val_dice_coef: 0.4949 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6440 - dice_coef: 0.6440 - accuracy: 0.9772 - val_loss: -0.4883 - val_dice_coef: 0.4883 - val_accuracy: 0.9841\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6517 - dice_coef: 0.6517 - accuracy: 0.9779 - val_loss: -0.5509 - val_dice_coef: 0.5509 - val_accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6605 - dice_coef: 0.6605 - accuracy: 0.9783 - val_loss: -0.4890 - val_dice_coef: 0.4890 - val_accuracy: 0.9844\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6489 - dice_coef: 0.6489 - accuracy: 0.9775 - val_loss: -0.4711 - val_dice_coef: 0.4711 - val_accuracy: 0.9836\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6435 - dice_coef: 0.6435 - accuracy: 0.9774 - val_loss: -0.4976 - val_dice_coef: 0.4976 - val_accuracy: 0.9845\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6600 - dice_coef: 0.6600 - accuracy: 0.9783 - val_loss: -0.4604 - val_dice_coef: 0.4604 - val_accuracy: 0.9837\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6504 - dice_coef: 0.6504 - accuracy: 0.9779 - val_loss: -0.4571 - val_dice_coef: 0.4571 - val_accuracy: 0.9836\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6474 - dice_coef: 0.6474 - accuracy: 0.9783 - val_loss: -0.4375 - val_dice_coef: 0.4375 - val_accuracy: 0.9830\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6495 - dice_coef: 0.6495 - accuracy: 0.9783 - val_loss: -0.4887 - val_dice_coef: 0.4887 - val_accuracy: 0.9840\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 139ms/step - loss: -0.5306 - dice_coef: 0.5306 - accuracy: 0.9726 - val_loss: -0.6315 - val_dice_coef: 0.6315 - val_accuracy: 0.9849\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5638 - dice_coef: 0.5638 - accuracy: 0.9773 - val_loss: -0.6408 - val_dice_coef: 0.6408 - val_accuracy: 0.9851\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5853 - dice_coef: 0.5853 - accuracy: 0.9797 - val_loss: -0.6355 - val_dice_coef: 0.6355 - val_accuracy: 0.9827\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6018 - dice_coef: 0.6018 - accuracy: 0.9818 - val_loss: -0.6196 - val_dice_coef: 0.6196 - val_accuracy: 0.9840\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6212 - dice_coef: 0.6212 - accuracy: 0.9840 - val_loss: -0.3947 - val_dice_coef: 0.3947 - val_accuracy: 0.9824\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6359 - dice_coef: 0.6359 - accuracy: 0.9857 - val_loss: -0.6064 - val_dice_coef: 0.6064 - val_accuracy: 0.9835\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6097 - dice_coef: 0.6097 - accuracy: 0.9832 - val_loss: -0.0623 - val_dice_coef: 0.0623 - val_accuracy: 0.6246\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5399 - dice_coef: 0.5399 - accuracy: 0.9775 - val_loss: -0.5862 - val_dice_coef: 0.5862 - val_accuracy: 0.9837\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6168 - dice_coef: 0.6168 - accuracy: 0.9807 - val_loss: -0.5423 - val_dice_coef: 0.5423 - val_accuracy: 0.9839\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5991 - dice_coef: 0.5991 - accuracy: 0.9778 - val_loss: -0.5923 - val_dice_coef: 0.5923 - val_accuracy: 0.9845\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6918 - dice_coef: 0.6918 - accuracy: 0.9821 - val_loss: -0.6385 - val_dice_coef: 0.6385 - val_accuracy: 0.9850\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.2462 - dice_coef: 0.2462 - accuracy: 0.9630 - val_loss: -0.3870 - val_dice_coef: 0.3870 - val_accuracy: 0.9789\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 47s 117ms/step - loss: -0.2236 - dice_coef: 0.2236 - accuracy: 0.9621 - val_loss: -0.3953 - val_dice_coef: 0.3953 - val_accuracy: 0.9789\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5966 - dice_coef: 0.5966 - accuracy: 0.9769 - val_loss: -0.5510 - val_dice_coef: 0.5510 - val_accuracy: 0.9851\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6686 - dice_coef: 0.6686 - accuracy: 0.9796 - val_loss: -0.5874 - val_dice_coef: 0.5874 - val_accuracy: 0.9848\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7066 - dice_coef: 0.7066 - accuracy: 0.9805 - val_loss: -0.6104 - val_dice_coef: 0.6104 - val_accuracy: 0.9835\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6916 - dice_coef: 0.6916 - accuracy: 0.9818 - val_loss: -0.5214 - val_dice_coef: 0.5214 - val_accuracy: 0.9823\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7561 - dice_coef: 0.7561 - accuracy: 0.9845 - val_loss: -0.6202 - val_dice_coef: 0.6202 - val_accuracy: 0.9855\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7673 - dice_coef: 0.7673 - accuracy: 0.9852 - val_loss: -0.6206 - val_dice_coef: 0.6206 - val_accuracy: 0.9855\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7341 - dice_coef: 0.7341 - accuracy: 0.9838 - val_loss: -0.5971 - val_dice_coef: 0.5971 - val_accuracy: 0.9854\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7523 - dice_coef: 0.7523 - accuracy: 0.9848 - val_loss: -0.6236 - val_dice_coef: 0.6236 - val_accuracy: 0.9856\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7123 - dice_coef: 0.7123 - accuracy: 0.9828 - val_loss: -0.6251 - val_dice_coef: 0.6251 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r4_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 19s 48ms/step - loss: -0.2179 - dice_coef: 0.2179 - accuracy: 0.8387 - val_loss: -0.3003 - val_dice_coef: 0.3003 - val_accuracy: 0.9787\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.4859 - dice_coef: 0.4859 - accuracy: 0.9681 - val_loss: -0.3008 - val_dice_coef: 0.3008 - val_accuracy: 0.9295\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5719 - dice_coef: 0.5719 - accuracy: 0.9731 - val_loss: -0.2995 - val_dice_coef: 0.2995 - val_accuracy: 0.9830\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6033 - dice_coef: 0.6033 - accuracy: 0.9747 - val_loss: -0.3473 - val_dice_coef: 0.3473 - val_accuracy: 0.9844\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6065 - dice_coef: 0.6065 - accuracy: 0.9751 - val_loss: -0.3630 - val_dice_coef: 0.3630 - val_accuracy: 0.9849\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5982 - dice_coef: 0.5982 - accuracy: 0.9753 - val_loss: -0.3952 - val_dice_coef: 0.3952 - val_accuracy: 0.9835\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6173 - dice_coef: 0.6173 - accuracy: 0.9761 - val_loss: -0.3299 - val_dice_coef: 0.3299 - val_accuracy: 0.9845\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6089 - dice_coef: 0.6089 - accuracy: 0.9759 - val_loss: -0.3629 - val_dice_coef: 0.3629 - val_accuracy: 0.9623\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6273 - dice_coef: 0.6273 - accuracy: 0.9763 - val_loss: -0.3711 - val_dice_coef: 0.3711 - val_accuracy: 0.9691\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6029 - dice_coef: 0.6029 - accuracy: 0.9755 - val_loss: -0.3261 - val_dice_coef: 0.3261 - val_accuracy: 0.9849\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6350 - dice_coef: 0.6350 - accuracy: 0.9767 - val_loss: -0.3990 - val_dice_coef: 0.3990 - val_accuracy: 0.9837\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6254 - dice_coef: 0.6254 - accuracy: 0.9764 - val_loss: -0.3450 - val_dice_coef: 0.3450 - val_accuracy: 0.9853\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6034 - dice_coef: 0.6034 - accuracy: 0.9762 - val_loss: -0.3446 - val_dice_coef: 0.3446 - val_accuracy: 0.9852\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6198 - dice_coef: 0.6198 - accuracy: 0.9766 - val_loss: -0.3495 - val_dice_coef: 0.3495 - val_accuracy: 0.9824\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6231 - dice_coef: 0.6231 - accuracy: 0.9767 - val_loss: -0.3363 - val_dice_coef: 0.3363 - val_accuracy: 0.9822\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6422 - dice_coef: 0.6422 - accuracy: 0.9776 - val_loss: -0.3236 - val_dice_coef: 0.3236 - val_accuracy: 0.9771\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6112 - dice_coef: 0.6112 - accuracy: 0.9765 - val_loss: -0.3784 - val_dice_coef: 0.3784 - val_accuracy: 0.9848\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6038 - dice_coef: 0.6038 - accuracy: 0.9767 - val_loss: -0.3891 - val_dice_coef: 0.3891 - val_accuracy: 0.9848\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6197 - dice_coef: 0.6197 - accuracy: 0.9771 - val_loss: -0.4434 - val_dice_coef: 0.4434 - val_accuracy: 0.9844\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6031 - dice_coef: 0.6031 - accuracy: 0.9764 - val_loss: -0.3232 - val_dice_coef: 0.3232 - val_accuracy: 0.9204\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6427 - dice_coef: 0.6427 - accuracy: 0.9779 - val_loss: -0.3286 - val_dice_coef: 0.3286 - val_accuracy: 0.9739\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6206 - dice_coef: 0.6206 - accuracy: 0.9771 - val_loss: -0.3805 - val_dice_coef: 0.3805 - val_accuracy: 0.9830\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6153 - dice_coef: 0.6153 - accuracy: 0.9770 - val_loss: -0.4182 - val_dice_coef: 0.4182 - val_accuracy: 0.9843\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6283 - dice_coef: 0.6283 - accuracy: 0.9780 - val_loss: -0.4018 - val_dice_coef: 0.4018 - val_accuracy: 0.9846\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6186 - dice_coef: 0.6186 - accuracy: 0.9776 - val_loss: -0.3838 - val_dice_coef: 0.3838 - val_accuracy: 0.9840\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6433 - dice_coef: 0.6433 - accuracy: 0.9781 - val_loss: -0.3963 - val_dice_coef: 0.3963 - val_accuracy: 0.9849\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6268 - dice_coef: 0.6268 - accuracy: 0.9773 - val_loss: -0.3968 - val_dice_coef: 0.3968 - val_accuracy: 0.9838\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6349 - dice_coef: 0.6349 - accuracy: 0.9783 - val_loss: -0.2892 - val_dice_coef: 0.2892 - val_accuracy: 0.9424\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6270 - dice_coef: 0.6270 - accuracy: 0.9777 - val_loss: -0.3367 - val_dice_coef: 0.3367 - val_accuracy: 0.9793s: -0.6356 - dice_\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6356 - dice_coef: 0.6356 - accuracy: 0.9780 - val_loss: -0.4029 - val_dice_coef: 0.4029 - val_accuracy: 0.9839\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6258 - dice_coef: 0.6258 - accuracy: 0.9782 - val_loss: -0.3870 - val_dice_coef: 0.3870 - val_accuracy: 0.9839\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6267 - dice_coef: 0.6267 - accuracy: 0.9783 - val_loss: -0.4210 - val_dice_coef: 0.4210 - val_accuracy: 0.9841\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6361 - dice_coef: 0.6361 - accuracy: 0.9786 - val_loss: -0.4415 - val_dice_coef: 0.4415 - val_accuracy: 0.9842\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6432 - dice_coef: 0.6432 - accuracy: 0.9787 - val_loss: -0.4289 - val_dice_coef: 0.4289 - val_accuracy: 0.9806\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6324 - dice_coef: 0.6324 - accuracy: 0.9783 - val_loss: -0.4156 - val_dice_coef: 0.4156 - val_accuracy: 0.9839\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6471 - dice_coef: 0.6471 - accuracy: 0.9786 - val_loss: -0.4268 - val_dice_coef: 0.4268 - val_accuracy: 0.9842\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6272 - dice_coef: 0.6272 - accuracy: 0.9784 - val_loss: -0.4361 - val_dice_coef: 0.4361 - val_accuracy: 0.9846\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6362 - dice_coef: 0.6362 - accuracy: 0.9786 - val_loss: -0.4780 - val_dice_coef: 0.4780 - val_accuracy: 0.9843\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6393 - dice_coef: 0.6393 - accuracy: 0.9785 - val_loss: -0.4110 - val_dice_coef: 0.4110 - val_accuracy: 0.9840\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6391 - dice_coef: 0.6391 - accuracy: 0.9785 - val_loss: -0.4354 - val_dice_coef: 0.4354 - val_accuracy: 0.9846\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6470 - dice_coef: 0.6470 - accuracy: 0.9789 - val_loss: -0.4057 - val_dice_coef: 0.4057 - val_accuracy: 0.9836\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6357 - dice_coef: 0.6357 - accuracy: 0.9787 - val_loss: -0.4482 - val_dice_coef: 0.4482 - val_accuracy: 0.9842\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6381 - dice_coef: 0.6381 - accuracy: 0.9792 - val_loss: -0.4599 - val_dice_coef: 0.4599 - val_accuracy: 0.9846\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6355 - dice_coef: 0.6355 - accuracy: 0.9786 - val_loss: -0.4165 - val_dice_coef: 0.4165 - val_accuracy: 0.9835\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6308 - dice_coef: 0.6308 - accuracy: 0.9785 - val_loss: -0.4236 - val_dice_coef: 0.4236 - val_accuracy: 0.9838\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6380 - dice_coef: 0.6380 - accuracy: 0.9785 - val_loss: -0.4334 - val_dice_coef: 0.4334 - val_accuracy: 0.9840\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6388 - dice_coef: 0.6388 - accuracy: 0.9785 - val_loss: -0.4183 - val_dice_coef: 0.4183 - val_accuracy: 0.9835\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6505 - dice_coef: 0.6505 - accuracy: 0.9791 - val_loss: -0.4562 - val_dice_coef: 0.4562 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6584 - dice_coef: 0.6584 - accuracy: 0.9796 - val_loss: -0.3938 - val_dice_coef: 0.3938 - val_accuracy: 0.9837\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6454 - dice_coef: 0.6454 - accuracy: 0.9788 - val_loss: -0.4198 - val_dice_coef: 0.4198 - val_accuracy: 0.9840\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 140ms/step - loss: -0.5127 - dice_coef: 0.5127 - accuracy: 0.9738 - val_loss: -0.5108 - val_dice_coef: 0.5108 - val_accuracy: 0.9285\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5452 - dice_coef: 0.5452 - accuracy: 0.9776 - val_loss: -0.4825 - val_dice_coef: 0.4825 - val_accuracy: 0.9129\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5624 - dice_coef: 0.5624 - accuracy: 0.9811 - val_loss: -0.5528 - val_dice_coef: 0.5528 - val_accuracy: 0.9673\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5818 - dice_coef: 0.5818 - accuracy: 0.9831 - val_loss: -0.5386 - val_dice_coef: 0.5386 - val_accuracy: 0.9709\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5438 - dice_coef: 0.5438 - accuracy: 0.9805 - val_loss: -0.4886 - val_dice_coef: 0.4886 - val_accuracy: 0.9596\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5309 - dice_coef: 0.5309 - accuracy: 0.9779 - val_loss: -0.1781 - val_dice_coef: 0.1781 - val_accuracy: 0.9615\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5260 - dice_coef: 0.5260 - accuracy: 0.9740 - val_loss: -0.2874 - val_dice_coef: 0.2874 - val_accuracy: 0.8659\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6090 - dice_coef: 0.6090 - accuracy: 0.9767 - val_loss: -0.3450 - val_dice_coef: 0.3450 - val_accuracy: 0.9461\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6643 - dice_coef: 0.6643 - accuracy: 0.9786 - val_loss: -0.3606 - val_dice_coef: 0.3606 - val_accuracy: 0.9731\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6388 - dice_coef: 0.6388 - accuracy: 0.9786 - val_loss: -0.3098 - val_dice_coef: 0.3098 - val_accuracy: 0.8139\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6624 - dice_coef: 0.6624 - accuracy: 0.9802 - val_loss: -0.4629 - val_dice_coef: 0.4629 - val_accuracy: 0.9785\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6398 - dice_coef: 0.6398 - accuracy: 0.9770 - val_loss: -0.4095 - val_dice_coef: 0.4095 - val_accuracy: 0.9612\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7012 - dice_coef: 0.7012 - accuracy: 0.9800 - val_loss: -0.3872 - val_dice_coef: 0.3872 - val_accuracy: 0.9610\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6976 - dice_coef: 0.6976 - accuracy: 0.9808 - val_loss: -0.3378 - val_dice_coef: 0.3378 - val_accuracy: 0.9593\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7163 - dice_coef: 0.7163 - accuracy: 0.9817 - val_loss: -0.3512 - val_dice_coef: 0.3512 - val_accuracy: 0.9447\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7430 - dice_coef: 0.7430 - accuracy: 0.9829 - val_loss: -0.4084 - val_dice_coef: 0.4084 - val_accuracy: 0.9408\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7148 - dice_coef: 0.7148 - accuracy: 0.9821 - val_loss: -0.3453 - val_dice_coef: 0.3453 - val_accuracy: 0.8330\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6847 - dice_coef: 0.6847 - accuracy: 0.9815 - val_loss: -0.4687 - val_dice_coef: 0.4687 - val_accuracy: 0.9811\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7329 - dice_coef: 0.7329 - accuracy: 0.9822 - val_loss: -0.4993 - val_dice_coef: 0.4993 - val_accuracy: 0.9481\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7666 - dice_coef: 0.7666 - accuracy: 0.9842 - val_loss: -0.5197 - val_dice_coef: 0.5197 - val_accuracy: 0.9498\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7543 - dice_coef: 0.7543 - accuracy: 0.9841 - val_loss: -0.4506 - val_dice_coef: 0.4506 - val_accuracy: 0.9658\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.7196 - dice_coef: 0.7196 - accuracy: 0.9826 - val_loss: -0.2495 - val_dice_coef: 0.2495 - val_accuracy: 0.8051\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6717 - dice_coef: 0.6717 - accuracy: 0.9800 - val_loss: -0.3561 - val_dice_coef: 0.3561 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r5_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 20s 49ms/step - loss: -0.0993 - dice_coef: 0.0993 - accuracy: 0.5731 - val_loss: -0.0536 - val_dice_coef: 0.0536 - val_accuracy: 0.3943\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1339 - dice_coef: 0.1339 - accuracy: 0.5917 - val_loss: -0.1041 - val_dice_coef: 0.1041 - val_accuracy: 0.9042\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1401 - dice_coef: 0.1401 - accuracy: 0.5947 - val_loss: -0.0644 - val_dice_coef: 0.0644 - val_accuracy: 0.4255\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1448 - dice_coef: 0.1448 - accuracy: 0.6041 - val_loss: -0.0911 - val_dice_coef: 0.0911 - val_accuracy: 0.6672\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1486 - dice_coef: 0.1486 - accuracy: 0.6096 - val_loss: -0.1009 - val_dice_coef: 0.1009 - val_accuracy: 0.6961\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1493 - dice_coef: 0.1493 - accuracy: 0.6159 - val_loss: -0.0859 - val_dice_coef: 0.0859 - val_accuracy: 0.6601\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1511 - dice_coef: 0.1511 - accuracy: 0.6185 - val_loss: -0.1096 - val_dice_coef: 0.1096 - val_accuracy: 0.7518\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1532 - dice_coef: 0.1532 - accuracy: 0.6216 - val_loss: -0.0879 - val_dice_coef: 0.0879 - val_accuracy: 0.6247\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1549 - dice_coef: 0.1549 - accuracy: 0.6260 - val_loss: -0.0759 - val_dice_coef: 0.0759 - val_accuracy: 0.5624\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1537 - dice_coef: 0.1537 - accuracy: 0.6265 - val_loss: -0.0776 - val_dice_coef: 0.0776 - val_accuracy: 0.5611\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1546 - dice_coef: 0.1546 - accuracy: 0.6313 - val_loss: -0.1252 - val_dice_coef: 0.1252 - val_accuracy: 0.7610\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1564 - dice_coef: 0.1564 - accuracy: 0.6315 - val_loss: -0.1030 - val_dice_coef: 0.1030 - val_accuracy: 0.7443\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1559 - dice_coef: 0.1559 - accuracy: 0.6332 - val_loss: -0.0564 - val_dice_coef: 0.0564 - val_accuracy: 0.3363\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1566 - dice_coef: 0.1566 - accuracy: 0.6314 - val_loss: -0.0662 - val_dice_coef: 0.0662 - val_accuracy: 0.4113\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1604 - dice_coef: 0.1604 - accuracy: 0.6389 - val_loss: -0.0568 - val_dice_coef: 0.0568 - val_accuracy: 0.2808\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1599 - dice_coef: 0.1599 - accuracy: 0.6385 - val_loss: -0.0511 - val_dice_coef: 0.0511 - val_accuracy: 0.1347\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1593 - dice_coef: 0.1593 - accuracy: 0.6373 - val_loss: -0.0542 - val_dice_coef: 0.0542 - val_accuracy: 0.2141\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1593 - dice_coef: 0.1593 - accuracy: 0.6421 - val_loss: -0.0744 - val_dice_coef: 0.0744 - val_accuracy: 0.5496\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1632 - dice_coef: 0.1632 - accuracy: 0.6474 - val_loss: -0.0723 - val_dice_coef: 0.0723 - val_accuracy: 0.5296\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1615 - dice_coef: 0.1615 - accuracy: 0.6456 - val_loss: -0.0627 - val_dice_coef: 0.0627 - val_accuracy: 0.4227\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1631 - dice_coef: 0.1631 - accuracy: 0.6481 - val_loss: -0.0665 - val_dice_coef: 0.0665 - val_accuracy: 0.4622\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1636 - dice_coef: 0.1636 - accuracy: 0.6511 - val_loss: -0.0575 - val_dice_coef: 0.0575 - val_accuracy: 0.3282\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1645 - dice_coef: 0.1645 - accuracy: 0.6525 - val_loss: -0.0766 - val_dice_coef: 0.0766 - val_accuracy: 0.5935\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1649 - dice_coef: 0.1649 - accuracy: 0.6541 - val_loss: -0.0499 - val_dice_coef: 0.0499 - val_accuracy: 0.1177\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1643 - dice_coef: 0.1643 - accuracy: 0.6570 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.1251\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1632 - dice_coef: 0.1632 - accuracy: 0.6568 - val_loss: -0.0667 - val_dice_coef: 0.0667 - val_accuracy: 0.4304\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: -0.1666 - dice_coef: 0.1666 - accuracy: 0.6580 - val_loss: -0.0828 - val_dice_coef: 0.0828 - val_accuracy: 0.5684\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1665 - dice_coef: 0.1665 - accuracy: 0.6577 - val_loss: -0.0547 - val_dice_coef: 0.0547 - val_accuracy: 0.2668\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1646 - dice_coef: 0.1646 - accuracy: 0.6576 - val_loss: -0.0530 - val_dice_coef: 0.0530 - val_accuracy: 0.1729\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1654 - dice_coef: 0.1654 - accuracy: 0.6603 - val_loss: -0.0516 - val_dice_coef: 0.0516 - val_accuracy: 0.1276\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.1670 - dice_coef: 0.1670 - accuracy: 0.6611 - val_loss: -0.0624 - val_dice_coef: 0.0624 - val_accuracy: 0.3930\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 140ms/step - loss: -0.4001 - dice_coef: 0.4001 - accuracy: 0.9342 - val_loss: -0.3394 - val_dice_coef: 0.3394 - val_accuracy: 0.9615\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.4863 - dice_coef: 0.4863 - accuracy: 0.9695 - val_loss: -0.3398 - val_dice_coef: 0.3398 - val_accuracy: 0.9807\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5122 - dice_coef: 0.5122 - accuracy: 0.9731 - val_loss: -0.3538 - val_dice_coef: 0.3538 - val_accuracy: 0.9802\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5335 - dice_coef: 0.5335 - accuracy: 0.9751 - val_loss: -0.3572 - val_dice_coef: 0.3572 - val_accuracy: 0.9816\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5540 - dice_coef: 0.5540 - accuracy: 0.9776 - val_loss: -0.3139 - val_dice_coef: 0.3139 - val_accuracy: 0.9756\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5664 - dice_coef: 0.5664 - accuracy: 0.9790 - val_loss: -0.4038 - val_dice_coef: 0.4038 - val_accuracy: 0.9761\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5848 - dice_coef: 0.5848 - accuracy: 0.9812 - val_loss: -0.4098 - val_dice_coef: 0.4098 - val_accuracy: 0.9804\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6009 - dice_coef: 0.6009 - accuracy: 0.9830 - val_loss: -0.4207 - val_dice_coef: 0.4207 - val_accuracy: 0.9819\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6024 - dice_coef: 0.6024 - accuracy: 0.9835 - val_loss: -0.4516 - val_dice_coef: 0.4516 - val_accuracy: 0.9811\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6112 - dice_coef: 0.6112 - accuracy: 0.9846 - val_loss: -0.3609 - val_dice_coef: 0.3609 - val_accuracy: 0.9786\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6209 - dice_coef: 0.6209 - accuracy: 0.9852 - val_loss: -0.4206 - val_dice_coef: 0.4206 - val_accuracy: 0.9804\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6393 - dice_coef: 0.6393 - accuracy: 0.9874 - val_loss: -0.4636 - val_dice_coef: 0.4636 - val_accuracy: 0.9803\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6017 - dice_coef: 0.6017 - accuracy: 0.9845 - val_loss: -0.2660 - val_dice_coef: 0.2660 - val_accuracy: 0.9785\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5871 - dice_coef: 0.5871 - accuracy: 0.9827 - val_loss: -0.3708 - val_dice_coef: 0.3708 - val_accuracy: 0.9777\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5334 - dice_coef: 0.5334 - accuracy: 0.9800 - val_loss: -0.2472 - val_dice_coef: 0.2472 - val_accuracy: 0.9767\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.4750 - dice_coef: 0.4750 - accuracy: 0.9732 - val_loss: -0.3358 - val_dice_coef: 0.3358 - val_accuracy: 0.9801\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5532 - dice_coef: 0.5532 - accuracy: 0.9774 - val_loss: -0.5143 - val_dice_coef: 0.5143 - val_accuracy: 0.9804\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5642 - dice_coef: 0.5642 - accuracy: 0.9780 - val_loss: -0.4678 - val_dice_coef: 0.4678 - val_accuracy: 0.9792\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5247 - dice_coef: 0.5247 - accuracy: 0.9747 - val_loss: -0.5431 - val_dice_coef: 0.5431 - val_accuracy: 0.9804\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5521 - dice_coef: 0.5521 - accuracy: 0.9741 - val_loss: -0.5357 - val_dice_coef: 0.5357 - val_accuracy: 0.9803\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5880 - dice_coef: 0.5880 - accuracy: 0.9764 - val_loss: -0.5666 - val_dice_coef: 0.5666 - val_accuracy: 0.9812\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6156 - dice_coef: 0.6156 - accuracy: 0.9775 - val_loss: -0.5450 - val_dice_coef: 0.5450 - val_accuracy: 0.9812\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5967 - dice_coef: 0.5967 - accuracy: 0.9765 - val_loss: -0.3579 - val_dice_coef: 0.3579 - val_accuracy: 0.9753\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.3807 - dice_coef: 0.3807 - accuracy: 0.9692 - val_loss: -0.3666 - val_dice_coef: 0.3666 - val_accuracy: 0.9763\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5460 - dice_coef: 0.5460 - accuracy: 0.9724 - val_loss: -0.4323 - val_dice_coef: 0.4323 - val_accuracy: 0.9780\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6146 - dice_coef: 0.6146 - accuracy: 0.9757 - val_loss: -0.4426 - val_dice_coef: 0.4426 - val_accuracy: 0.9787\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6323 - dice_coef: 0.6323 - accuracy: 0.9770 - val_loss: -0.5844 - val_dice_coef: 0.5844 - val_accuracy: 0.9819\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5997 - dice_coef: 0.5997 - accuracy: 0.9749 - val_loss: -0.5559 - val_dice_coef: 0.5559 - val_accuracy: 0.9812\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6406 - dice_coef: 0.6406 - accuracy: 0.9777 - val_loss: -0.5774 - val_dice_coef: 0.5774 - val_accuracy: 0.9820\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6299 - dice_coef: 0.6299 - accuracy: 0.9776 - val_loss: -0.5512 - val_dice_coef: 0.5512 - val_accuracy: 0.9806\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6332 - dice_coef: 0.6332 - accuracy: 0.9785 - val_loss: -0.5839 - val_dice_coef: 0.5839 - val_accuracy: 0.9815\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6476 - dice_coef: 0.6476 - accuracy: 0.9790 - val_loss: -0.5934 - val_dice_coef: 0.5934 - val_accuracy: 0.9803\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6670 - dice_coef: 0.6670 - accuracy: 0.9798 - val_loss: -0.4851 - val_dice_coef: 0.4851 - val_accuracy: 0.9788\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6591 - dice_coef: 0.6591 - accuracy: 0.9790 - val_loss: -0.3767 - val_dice_coef: 0.3767 - val_accuracy: 0.9744\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6385 - dice_coef: 0.6385 - accuracy: 0.9777 - val_loss: -0.3805 - val_dice_coef: 0.3805 - val_accuracy: 0.9766\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6315 - dice_coef: 0.6315 - accuracy: 0.9778 - val_loss: -0.3400 - val_dice_coef: 0.3400 - val_accuracy: 0.9766\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6271 - dice_coef: 0.6271 - accuracy: 0.9767 - val_loss: -0.4152 - val_dice_coef: 0.4152 - val_accuracy: 0.9774\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6538 - dice_coef: 0.6538 - accuracy: 0.9786 - val_loss: -0.4910 - val_dice_coef: 0.4910 - val_accuracy: 0.9793\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5772 - dice_coef: 0.5772 - accuracy: 0.9747 - val_loss: -0.5600 - val_dice_coef: 0.5600 - val_accuracy: 0.9802\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6462 - dice_coef: 0.6462 - accuracy: 0.9774 - val_loss: -0.5293 - val_dice_coef: 0.5293 - val_accuracy: 0.9803\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.3169 - dice_coef: 0.3169 - accuracy: 0.9657 - val_loss: -0.3599 - val_dice_coef: 0.3599 - val_accuracy: 0.9756\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.4469 - dice_coef: 0.4469 - accuracy: 0.9700 - val_loss: -0.3935 - val_dice_coef: 0.3935 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5627 - dice_coef: 0.5627 - accuracy: 0.9737 - val_loss: -0.5321 - val_dice_coef: 0.5321 - val_accuracy: 0.9803\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6366 - dice_coef: 0.6366 - accuracy: 0.9767 - val_loss: -0.5362 - val_dice_coef: 0.5362 - val_accuracy: 0.9805\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6572 - dice_coef: 0.6572 - accuracy: 0.9775 - val_loss: -0.4776 - val_dice_coef: 0.4776 - val_accuracy: 0.9790\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6633 - dice_coef: 0.6633 - accuracy: 0.9779 - val_loss: -0.4787 - val_dice_coef: 0.4787 - val_accuracy: 0.9791\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6829 - dice_coef: 0.6829 - accuracy: 0.9789 - val_loss: -0.5819 - val_dice_coef: 0.5819 - val_accuracy: 0.9823\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6881 - dice_coef: 0.6881 - accuracy: 0.9797 - val_loss: -0.5554 - val_dice_coef: 0.5554 - val_accuracy: 0.9810\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6775 - dice_coef: 0.6775 - accuracy: 0.9794 - val_loss: -0.3771 - val_dice_coef: 0.3771 - val_accuracy: 0.9763\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5883 - dice_coef: 0.5883 - accuracy: 0.9761 - val_loss: -0.4235 - val_dice_coef: 0.4235 - val_accuracy: 0.9778\n",
      "model_fine_tuning_No_NAIP_500_samples_r6_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 20s 49ms/step - loss: -0.3379 - dice_coef: 0.3379 - accuracy: 0.9605 - val_loss: -0.1104 - val_dice_coef: 0.1104 - val_accuracy: 0.6270\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5264 - dice_coef: 0.5264 - accuracy: 0.9703 - val_loss: -0.2588 - val_dice_coef: 0.2588 - val_accuracy: 0.9742\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5774 - dice_coef: 0.5774 - accuracy: 0.9731 - val_loss: -0.2902 - val_dice_coef: 0.2902 - val_accuracy: 0.9790\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5869 - dice_coef: 0.5869 - accuracy: 0.9737 - val_loss: -0.2660 - val_dice_coef: 0.2660 - val_accuracy: 0.9653\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.5696 - dice_coef: 0.5696 - accuracy: 0.9734 - val_loss: -0.3238 - val_dice_coef: 0.3238 - val_accuracy: 0.9742\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6035 - dice_coef: 0.6035 - accuracy: 0.9751 - val_loss: -0.3055 - val_dice_coef: 0.3055 - val_accuracy: 0.9828\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6241 - dice_coef: 0.6241 - accuracy: 0.9762 - val_loss: -0.3422 - val_dice_coef: 0.3422 - val_accuracy: 0.9806\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6132 - dice_coef: 0.6132 - accuracy: 0.9763 - val_loss: -0.3305 - val_dice_coef: 0.3305 - val_accuracy: 0.9820\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6066 - dice_coef: 0.6066 - accuracy: 0.9760 - val_loss: -0.3356 - val_dice_coef: 0.3356 - val_accuracy: 0.9812\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6257 - dice_coef: 0.6257 - accuracy: 0.9765 - val_loss: -0.2948 - val_dice_coef: 0.2948 - val_accuracy: 0.9825\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6080 - dice_coef: 0.6080 - accuracy: 0.9767 - val_loss: -0.3359 - val_dice_coef: 0.3359 - val_accuracy: 0.9804\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6128 - dice_coef: 0.6128 - accuracy: 0.9768 - val_loss: -0.3632 - val_dice_coef: 0.3632 - val_accuracy: 0.9804\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6470 - dice_coef: 0.6470 - accuracy: 0.9778 - val_loss: -0.3373 - val_dice_coef: 0.3373 - val_accuracy: 0.9828\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6225 - dice_coef: 0.6225 - accuracy: 0.9772 - val_loss: -0.3498 - val_dice_coef: 0.3498 - val_accuracy: 0.9795\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6205 - dice_coef: 0.6205 - accuracy: 0.9770 - val_loss: -0.3010 - val_dice_coef: 0.3010 - val_accuracy: 0.9821\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6161 - dice_coef: 0.6161 - accuracy: 0.9770 - val_loss: -0.3624 - val_dice_coef: 0.3624 - val_accuracy: 0.9813\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6210 - dice_coef: 0.6210 - accuracy: 0.9771 - val_loss: -0.1975 - val_dice_coef: 0.1975 - val_accuracy: 0.9805\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6274 - dice_coef: 0.6274 - accuracy: 0.9779 - val_loss: -0.3173 - val_dice_coef: 0.3173 - val_accuracy: 0.9824\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6264 - dice_coef: 0.6264 - accuracy: 0.9782 - val_loss: -0.3709 - val_dice_coef: 0.3709 - val_accuracy: 0.9820\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6161 - dice_coef: 0.6161 - accuracy: 0.9768 - val_loss: -0.3085 - val_dice_coef: 0.3085 - val_accuracy: 0.9821\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6333 - dice_coef: 0.6333 - accuracy: 0.9780 - val_loss: -0.3493 - val_dice_coef: 0.3493 - val_accuracy: 0.9821\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6297 - dice_coef: 0.6297 - accuracy: 0.9781 - val_loss: -0.3996 - val_dice_coef: 0.3996 - val_accuracy: 0.9826\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6245 - dice_coef: 0.6245 - accuracy: 0.9767 - val_loss: -0.3119 - val_dice_coef: 0.3119 - val_accuracy: 0.9816\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6412 - dice_coef: 0.6412 - accuracy: 0.9782 - val_loss: -0.1823 - val_dice_coef: 0.1823 - val_accuracy: 0.9796\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6290 - dice_coef: 0.6290 - accuracy: 0.9785 - val_loss: -0.3370 - val_dice_coef: 0.3370 - val_accuracy: 0.9824\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6392 - dice_coef: 0.6392 - accuracy: 0.9788 - val_loss: -0.3376 - val_dice_coef: 0.3376 - val_accuracy: 0.9822\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6446 - dice_coef: 0.6446 - accuracy: 0.9788 - val_loss: -0.3858 - val_dice_coef: 0.3858 - val_accuracy: 0.9822\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6250 - dice_coef: 0.6250 - accuracy: 0.9781 - val_loss: -0.3472 - val_dice_coef: 0.3472 - val_accuracy: 0.9818\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6404 - dice_coef: 0.6404 - accuracy: 0.9787 - val_loss: -0.3505 - val_dice_coef: 0.3505 - val_accuracy: 0.9823\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6253 - dice_coef: 0.6253 - accuracy: 0.9788 - val_loss: -0.3854 - val_dice_coef: 0.3854 - val_accuracy: 0.9814\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6553 - dice_coef: 0.6553 - accuracy: 0.9789 - val_loss: -0.3436 - val_dice_coef: 0.3436 - val_accuracy: 0.9816\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6414 - dice_coef: 0.6414 - accuracy: 0.9785 - val_loss: -0.3520 - val_dice_coef: 0.3520 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6411 - dice_coef: 0.6411 - accuracy: 0.9786 - val_loss: -0.3758 - val_dice_coef: 0.3758 - val_accuracy: 0.9818\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6306 - dice_coef: 0.6306 - accuracy: 0.9781 - val_loss: -0.4063 - val_dice_coef: 0.4063 - val_accuracy: 0.9822\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6487 - dice_coef: 0.6487 - accuracy: 0.9793 - val_loss: -0.3276 - val_dice_coef: 0.3276 - val_accuracy: 0.9809\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6548 - dice_coef: 0.6548 - accuracy: 0.9792 - val_loss: -0.3722 - val_dice_coef: 0.3722 - val_accuracy: 0.9819\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6306 - dice_coef: 0.6306 - accuracy: 0.9788 - val_loss: -0.3813 - val_dice_coef: 0.3813 - val_accuracy: 0.9819\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6468 - dice_coef: 0.6468 - accuracy: 0.9792 - val_loss: -0.3536 - val_dice_coef: 0.3536 - val_accuracy: 0.9814\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6409 - dice_coef: 0.6409 - accuracy: 0.9786 - val_loss: -0.3926 - val_dice_coef: 0.3926 - val_accuracy: 0.9822\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6586 - dice_coef: 0.6586 - accuracy: 0.9796 - val_loss: -0.3979 - val_dice_coef: 0.3979 - val_accuracy: 0.9822\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6552 - dice_coef: 0.6552 - accuracy: 0.9795 - val_loss: -0.4037 - val_dice_coef: 0.4037 - val_accuracy: 0.9820\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6460 - dice_coef: 0.6460 - accuracy: 0.9791 - val_loss: -0.3901 - val_dice_coef: 0.3901 - val_accuracy: 0.9819\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6522 - dice_coef: 0.6522 - accuracy: 0.9790 - val_loss: -0.4089 - val_dice_coef: 0.4089 - val_accuracy: 0.9823\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6381 - dice_coef: 0.6381 - accuracy: 0.9786 - val_loss: -0.4191 - val_dice_coef: 0.4191 - val_accuracy: 0.9819\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6321 - dice_coef: 0.6321 - accuracy: 0.9785 - val_loss: -0.4366 - val_dice_coef: 0.4366 - val_accuracy: 0.9820\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6389 - dice_coef: 0.6389 - accuracy: 0.9790 - val_loss: -0.3390 - val_dice_coef: 0.3390 - val_accuracy: 0.9805\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6516 - dice_coef: 0.6516 - accuracy: 0.9791 - val_loss: -0.4132 - val_dice_coef: 0.4132 - val_accuracy: 0.9819\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6183 - dice_coef: 0.6183 - accuracy: 0.9785 - val_loss: -0.3723 - val_dice_coef: 0.3723 - val_accuracy: 0.9814\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6429 - dice_coef: 0.6429 - accuracy: 0.9796 - val_loss: -0.4344 - val_dice_coef: 0.4344 - val_accuracy: 0.9817\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: -0.6492 - dice_coef: 0.6492 - accuracy: 0.9793 - val_loss: -0.4116 - val_dice_coef: 0.4116 - val_accuracy: 0.9821\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 56s 141ms/step - loss: -0.5121 - dice_coef: 0.5121 - accuracy: 0.9746 - val_loss: -0.6254 - val_dice_coef: 0.6254 - val_accuracy: 0.9814\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5443 - dice_coef: 0.5443 - accuracy: 0.9794 - val_loss: -0.6571 - val_dice_coef: 0.6571 - val_accuracy: 0.9779\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5424 - dice_coef: 0.5424 - accuracy: 0.9809 - val_loss: -0.4569 - val_dice_coef: 0.4569 - val_accuracy: 0.9728\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.5814 - dice_coef: 0.5814 - accuracy: 0.9815 - val_loss: -0.5821 - val_dice_coef: 0.5821 - val_accuracy: 0.9821\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5365 - dice_coef: 0.5365 - accuracy: 0.9785 - val_loss: -0.5438 - val_dice_coef: 0.5438 - val_accuracy: 0.9808\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.5402 - dice_coef: 0.5402 - accuracy: 0.9752 - val_loss: -0.5738 - val_dice_coef: 0.5738 - val_accuracy: 0.9823\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.6116 - dice_coef: 0.6116 - accuracy: 0.9783 - val_loss: -0.6164 - val_dice_coef: 0.6164 - val_accuracy: 0.9797\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.4731 - dice_coef: 0.4731 - accuracy: 0.9749 - val_loss: -0.4245 - val_dice_coef: 0.4245 - val_accuracy: 0.9777\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.3869 - dice_coef: 0.3869 - accuracy: 0.9694 - val_loss: -0.4284 - val_dice_coef: 0.4284 - val_accuracy: 0.9776\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 47s 118ms/step - loss: -0.5071 - dice_coef: 0.5071 - accuracy: 0.9733 - val_loss: -0.5767 - val_dice_coef: 0.5767 - val_accuracy: 0.9823\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6752 - dice_coef: 0.6752 - accuracy: 0.9812 - val_loss: -0.6217 - val_dice_coef: 0.6217 - val_accuracy: 0.9821\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 48s 120ms/step - loss: -0.6766 - dice_coef: 0.6766 - accuracy: 0.9815 - val_loss: -0.6069 - val_dice_coef: 0.6069 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7120 - dice_coef: 0.7120 - accuracy: 0.9836 - val_loss: -0.6100 - val_dice_coef: 0.6100 - val_accuracy: 0.9826\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7015 - dice_coef: 0.7015 - accuracy: 0.9831 - val_loss: -0.5971 - val_dice_coef: 0.5971 - val_accuracy: 0.9803\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.6628 - dice_coef: 0.6628 - accuracy: 0.9815 - val_loss: -0.4939 - val_dice_coef: 0.4939 - val_accuracy: 0.9793\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6955 - dice_coef: 0.6955 - accuracy: 0.9834 - val_loss: -0.5899 - val_dice_coef: 0.5899 - val_accuracy: 0.9809\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7008 - dice_coef: 0.7008 - accuracy: 0.9825 - val_loss: -0.6204 - val_dice_coef: 0.6204 - val_accuracy: 0.9810\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7483 - dice_coef: 0.7483 - accuracy: 0.9852 - val_loss: -0.5212 - val_dice_coef: 0.5212 - val_accuracy: 0.9802\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 47s 119ms/step - loss: -0.7567 - dice_coef: 0.7567 - accuracy: 0.9856 - val_loss: -0.5528 - val_dice_coef: 0.5528 - val_accuracy: 0.9804\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7795 - dice_coef: 0.7795 - accuracy: 0.9867 - val_loss: -0.6283 - val_dice_coef: 0.6283 - val_accuracy: 0.9828\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.7975 - dice_coef: 0.7975 - accuracy: 0.9876 - val_loss: -0.5666 - val_dice_coef: 0.5666 - val_accuracy: 0.9818\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 48s 119ms/step - loss: -0.6856 - dice_coef: 0.6856 - accuracy: 0.9837 - val_loss: -0.4405 - val_dice_coef: 0.4405 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r7_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 21s 51ms/step - loss: -0.2223 - dice_coef: 0.2223 - accuracy: 0.8986 - val_loss: -0.1708 - val_dice_coef: 0.1708 - val_accuracy: 0.7914\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.5153 - dice_coef: 0.5153 - accuracy: 0.9694 - val_loss: -0.3837 - val_dice_coef: 0.3837 - val_accuracy: 0.9756\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.5805 - dice_coef: 0.5805 - accuracy: 0.9727 - val_loss: -0.3993 - val_dice_coef: 0.3993 - val_accuracy: 0.9776\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.6165 - dice_coef: 0.6165 - accuracy: 0.9742 - val_loss: -0.3395 - val_dice_coef: 0.3395 - val_accuracy: 0.9812\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.6100 - dice_coef: 0.6100 - accuracy: 0.9747 - val_loss: -0.4129 - val_dice_coef: 0.4129 - val_accuracy: 0.9814\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: -0.6144 - dice_coef: 0.6144 - accuracy: 0.9748 - val_loss: -0.3598 - val_dice_coef: 0.3598 - val_accuracy: 0.9817\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: -0.6274 - dice_coef: 0.6274 - accuracy: 0.9756 - val_loss: -0.3102 - val_dice_coef: 0.3102 - val_accuracy: 0.9818\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.6333 - dice_coef: 0.6333 - accuracy: 0.9756 - val_loss: -0.2628 - val_dice_coef: 0.2628 - val_accuracy: 0.9809\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.6286 - dice_coef: 0.6286 - accuracy: 0.9760 - val_loss: -0.3746 - val_dice_coef: 0.3746 - val_accuracy: 0.9823\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.6436 - dice_coef: 0.6436 - accuracy: 0.9766 - val_loss: -0.4141 - val_dice_coef: 0.4141 - val_accuracy: 0.9820\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.6460 - dice_coef: 0.6460 - accuracy: 0.9764 - val_loss: -0.2443 - val_dice_coef: 0.2443 - val_accuracy: 0.9806\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 20s 50ms/step - loss: -0.6454 - dice_coef: 0.6454 - accuracy: 0.9768 - val_loss: -0.3252 - val_dice_coef: 0.3252 - val_accuracy: 0.9816\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 20s 50ms/step - loss: -0.6391 - dice_coef: 0.6391 - accuracy: 0.9763 - val_loss: -0.3159 - val_dice_coef: 0.3159 - val_accuracy: 0.9820\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 20s 51ms/step - loss: -0.6215 - dice_coef: 0.6215 - accuracy: 0.9757 - val_loss: -0.2825 - val_dice_coef: 0.2825 - val_accuracy: 0.9812\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 20s 51ms/step - loss: -0.6430 - dice_coef: 0.6430 - accuracy: 0.9763 - val_loss: -0.1324 - val_dice_coef: 0.1324 - val_accuracy: 0.9780\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 17s 43ms/step - loss: -0.6316 - dice_coef: 0.6316 - accuracy: 0.9765 - val_loss: -0.3518 - val_dice_coef: 0.3518 - val_accuracy: 0.9825\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6402 - dice_coef: 0.6402 - accuracy: 0.9770 - val_loss: -0.4137 - val_dice_coef: 0.4137 - val_accuracy: 0.9829\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6283 - dice_coef: 0.6283 - accuracy: 0.9758 - val_loss: -0.2480 - val_dice_coef: 0.2480 - val_accuracy: 0.9799\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6455 - dice_coef: 0.6455 - accuracy: 0.9773 - val_loss: -0.2235 - val_dice_coef: 0.2235 - val_accuracy: 0.9801\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6133 - dice_coef: 0.6133 - accuracy: 0.9760 - val_loss: -0.3683 - val_dice_coef: 0.3683 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6551 - dice_coef: 0.6551 - accuracy: 0.9775 - val_loss: -0.3069 - val_dice_coef: 0.3069 - val_accuracy: 0.9809\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.6341 - dice_coef: 0.6341 - accuracy: 0.9766 - val_loss: -0.4230 - val_dice_coef: 0.4230 - val_accuracy: 0.9839\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6476 - dice_coef: 0.6476 - accuracy: 0.9768 - val_loss: -0.3364 - val_dice_coef: 0.3364 - val_accuracy: 0.9819\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6374 - dice_coef: 0.6374 - accuracy: 0.9768 - val_loss: -0.2886 - val_dice_coef: 0.2886 - val_accuracy: 0.9806\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.6433 - dice_coef: 0.6433 - accuracy: 0.9769 - val_loss: -0.3574 - val_dice_coef: 0.3574 - val_accuracy: 0.9824\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6605 - dice_coef: 0.6605 - accuracy: 0.9777 - val_loss: -0.3032 - val_dice_coef: 0.3032 - val_accuracy: 0.9811\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6354 - dice_coef: 0.6354 - accuracy: 0.9773 - val_loss: -0.3368 - val_dice_coef: 0.3368 - val_accuracy: 0.9811\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6484 - dice_coef: 0.6484 - accuracy: 0.9775 - val_loss: -0.3552 - val_dice_coef: 0.3552 - val_accuracy: 0.9819\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6454 - dice_coef: 0.6454 - accuracy: 0.9771 - val_loss: -0.3292 - val_dice_coef: 0.3292 - val_accuracy: 0.9809\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6376 - dice_coef: 0.6376 - accuracy: 0.9769 - val_loss: -0.2831 - val_dice_coef: 0.2831 - val_accuracy: 0.9800\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6365 - dice_coef: 0.6365 - accuracy: 0.9771 - val_loss: -0.4100 - val_dice_coef: 0.4100 - val_accuracy: 0.9828\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6531 - dice_coef: 0.6531 - accuracy: 0.9779 - val_loss: -0.3383 - val_dice_coef: 0.3383 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6572 - dice_coef: 0.6572 - accuracy: 0.9779 - val_loss: -0.3814 - val_dice_coef: 0.3814 - val_accuracy: 0.9827\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6389 - dice_coef: 0.6389 - accuracy: 0.9774 - val_loss: -0.3235 - val_dice_coef: 0.3235 - val_accuracy: 0.9806\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6555 - dice_coef: 0.6555 - accuracy: 0.9780 - val_loss: -0.3676 - val_dice_coef: 0.3676 - val_accuracy: 0.9817\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6462 - dice_coef: 0.6462 - accuracy: 0.9774 - val_loss: -0.3990 - val_dice_coef: 0.3990 - val_accuracy: 0.9827\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6490 - dice_coef: 0.6490 - accuracy: 0.9776 - val_loss: -0.3862 - val_dice_coef: 0.3862 - val_accuracy: 0.9821\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6743 - dice_coef: 0.6743 - accuracy: 0.9786 - val_loss: -0.3812 - val_dice_coef: 0.3812 - val_accuracy: 0.9818\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6487 - dice_coef: 0.6487 - accuracy: 0.9778 - val_loss: -0.3824 - val_dice_coef: 0.3824 - val_accuracy: 0.9814\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6528 - dice_coef: 0.6528 - accuracy: 0.9782 - val_loss: -0.3582 - val_dice_coef: 0.3582 - val_accuracy: 0.9821\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6534 - dice_coef: 0.6534 - accuracy: 0.9780 - val_loss: -0.3778 - val_dice_coef: 0.3778 - val_accuracy: 0.9823\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 16s 41ms/step - loss: -0.6463 - dice_coef: 0.6463 - accuracy: 0.9779 - val_loss: -0.3464 - val_dice_coef: 0.3464 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 109s 273ms/step - loss: -0.5287 - dice_coef: 0.5287 - accuracy: 0.9730 - val_loss: -0.3842 - val_dice_coef: 0.3842 - val_accuracy: 0.8064\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 88s 220ms/step - loss: -0.5634 - dice_coef: 0.5634 - accuracy: 0.9779 - val_loss: -0.3366 - val_dice_coef: 0.3366 - val_accuracy: 0.8184\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 78s 195ms/step - loss: -0.5825 - dice_coef: 0.5825 - accuracy: 0.9809 - val_loss: -0.3349 - val_dice_coef: 0.3349 - val_accuracy: 0.7501\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 77s 191ms/step - loss: -0.5950 - dice_coef: 0.5950 - accuracy: 0.9830 - val_loss: -0.4511 - val_dice_coef: 0.4511 - val_accuracy: 0.8851\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 78s 194ms/step - loss: -0.5980 - dice_coef: 0.5980 - accuracy: 0.9832 - val_loss: -0.3174 - val_dice_coef: 0.3174 - val_accuracy: 0.8242\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 76s 191ms/step - loss: -0.5862 - dice_coef: 0.5862 - accuracy: 0.9818 - val_loss: -0.3004 - val_dice_coef: 0.3004 - val_accuracy: 0.8250\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 74s 185ms/step - loss: -0.5787 - dice_coef: 0.5787 - accuracy: 0.9780 - val_loss: -0.3568 - val_dice_coef: 0.3568 - val_accuracy: 0.9566\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 79s 197ms/step - loss: -0.6363 - dice_coef: 0.6363 - accuracy: 0.9794 - val_loss: -0.4850 - val_dice_coef: 0.4850 - val_accuracy: 0.9383\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 77s 192ms/step - loss: -0.6697 - dice_coef: 0.6697 - accuracy: 0.9819 - val_loss: -0.5041 - val_dice_coef: 0.5041 - val_accuracy: 0.9571\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 76s 190ms/step - loss: -0.6445 - dice_coef: 0.6445 - accuracy: 0.9816 - val_loss: -0.3508 - val_dice_coef: 0.3508 - val_accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.5162 - dice_coef: 0.5162 - accuracy: 0.9742 - val_loss: -0.3851 - val_dice_coef: 0.3851 - val_accuracy: 0.8952\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 77s 194ms/step - loss: -0.6735 - dice_coef: 0.6735 - accuracy: 0.9797 - val_loss: -0.4701 - val_dice_coef: 0.4701 - val_accuracy: 0.9702\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 77s 193ms/step - loss: -0.6996 - dice_coef: 0.6996 - accuracy: 0.9822 - val_loss: -0.5054 - val_dice_coef: 0.5054 - val_accuracy: 0.9559\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 77s 193ms/step - loss: -0.6949 - dice_coef: 0.6949 - accuracy: 0.9819 - val_loss: -0.5513 - val_dice_coef: 0.5513 - val_accuracy: 0.9817\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.7139 - dice_coef: 0.7139 - accuracy: 0.9827 - val_loss: -0.5619 - val_dice_coef: 0.5619 - val_accuracy: 0.9836\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 77s 194ms/step - loss: -0.7790 - dice_coef: 0.7790 - accuracy: 0.9860 - val_loss: -0.5593 - val_dice_coef: 0.5593 - val_accuracy: 0.9835\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 77s 193ms/step - loss: -0.8040 - dice_coef: 0.8040 - accuracy: 0.9877 - val_loss: -0.5627 - val_dice_coef: 0.5627 - val_accuracy: 0.9841\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 76s 189ms/step - loss: -0.7657 - dice_coef: 0.7657 - accuracy: 0.9859 - val_loss: -0.4106 - val_dice_coef: 0.4106 - val_accuracy: 0.9169\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 78s 195ms/step - loss: -0.6822 - dice_coef: 0.6822 - accuracy: 0.9796 - val_loss: -0.3567 - val_dice_coef: 0.3567 - val_accuracy: 0.9762\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 77s 194ms/step - loss: -0.3181 - dice_coef: 0.3181 - accuracy: 0.9652 - val_loss: -0.3775 - val_dice_coef: 0.3775 - val_accuracy: 0.9760\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 79s 198ms/step - loss: -0.2447 - dice_coef: 0.2447 - accuracy: 0.9623 - val_loss: -0.3807 - val_dice_coef: 0.3807 - val_accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 76s 191ms/step - loss: -0.2459 - dice_coef: 0.2459 - accuracy: 0.9623 - val_loss: -0.3820 - val_dice_coef: 0.3820 - val_accuracy: 0.9760\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 73s 183ms/step - loss: -0.2469 - dice_coef: 0.2469 - accuracy: 0.9623 - val_loss: -0.3833 - val_dice_coef: 0.3833 - val_accuracy: 0.9760\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.2477 - dice_coef: 0.2477 - accuracy: 0.9623 - val_loss: -0.3844 - val_dice_coef: 0.3844 - val_accuracy: 0.9760\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 77s 192ms/step - loss: -0.2483 - dice_coef: 0.2483 - accuracy: 0.9623 - val_loss: -0.3853 - val_dice_coef: 0.3853 - val_accuracy: 0.9760\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 78s 195ms/step - loss: -0.2488 - dice_coef: 0.2488 - accuracy: 0.9623 - val_loss: -0.3861 - val_dice_coef: 0.3861 - val_accuracy: 0.9760\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 79s 197ms/step - loss: -0.2493 - dice_coef: 0.2493 - accuracy: 0.9623 - val_loss: -0.3869 - val_dice_coef: 0.3869 - val_accuracy: 0.9760\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 72s 180ms/step - loss: -0.2496 - dice_coef: 0.2496 - accuracy: 0.9623 - val_loss: -0.3872 - val_dice_coef: 0.3872 - val_accuracy: 0.9760\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.2499 - dice_coef: 0.2499 - accuracy: 0.9623 - val_loss: -0.3876 - val_dice_coef: 0.3876 - val_accuracy: 0.9760\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.2501 - dice_coef: 0.2501 - accuracy: 0.9623 - val_loss: -0.3880 - val_dice_coef: 0.3880 - val_accuracy: 0.9760\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 73s 184ms/step - loss: -0.2503 - dice_coef: 0.2503 - accuracy: 0.9623 - val_loss: -0.3883 - val_dice_coef: 0.3883 - val_accuracy: 0.9760\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 77s 192ms/step - loss: -0.2505 - dice_coef: 0.2505 - accuracy: 0.9623 - val_loss: -0.3887 - val_dice_coef: 0.3887 - val_accuracy: 0.9760\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 75s 187ms/step - loss: -0.2507 - dice_coef: 0.2507 - accuracy: 0.9623 - val_loss: -0.3889 - val_dice_coef: 0.3889 - val_accuracy: 0.9760\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 77s 192ms/step - loss: -0.2508 - dice_coef: 0.2508 - accuracy: 0.9623 - val_loss: -0.3892 - val_dice_coef: 0.3892 - val_accuracy: 0.9760\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 75s 188ms/step - loss: -0.2510 - dice_coef: 0.2510 - accuracy: 0.9623 - val_loss: -0.3894 - val_dice_coef: 0.3894 - val_accuracy: 0.9760\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 72s 179ms/step - loss: -0.2511 - dice_coef: 0.2511 - accuracy: 0.9623 - val_loss: -0.3895 - val_dice_coef: 0.3895 - val_accuracy: 0.9760\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 77s 192ms/step - loss: -0.2512 - dice_coef: 0.2512 - accuracy: 0.9623 - val_loss: -0.3897 - val_dice_coef: 0.3897 - val_accuracy: 0.9760\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r8_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 20s 50ms/step - loss: -0.0707 - dice_coef: 0.0707 - accuracy: 0.3960 - val_loss: -0.0713 - val_dice_coef: 0.0713 - val_accuracy: 0.6287\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1039 - dice_coef: 0.1039 - accuracy: 0.5513 - val_loss: -0.0494 - val_dice_coef: 0.0494 - val_accuracy: 0.1962\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1173 - dice_coef: 0.1173 - accuracy: 0.5669 - val_loss: -0.0212 - val_dice_coef: 0.0212 - val_accuracy: 0.9715\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1222 - dice_coef: 0.1222 - accuracy: 0.5766 - val_loss: -0.0489 - val_dice_coef: 0.0489 - val_accuracy: 0.1677\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1258 - dice_coef: 0.1258 - accuracy: 0.5850 - val_loss: -0.0788 - val_dice_coef: 0.0788 - val_accuracy: 0.6610\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1302 - dice_coef: 0.1302 - accuracy: 0.5931 - val_loss: -0.0518 - val_dice_coef: 0.0518 - val_accuracy: 0.9418\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1308 - dice_coef: 0.1308 - accuracy: 0.5958 - val_loss: -0.0905 - val_dice_coef: 0.0905 - val_accuracy: 0.8572\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1321 - dice_coef: 0.1321 - accuracy: 0.5999 - val_loss: -0.0645 - val_dice_coef: 0.0645 - val_accuracy: 0.9263\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1344 - dice_coef: 0.1344 - accuracy: 0.6041 - val_loss: -0.0743 - val_dice_coef: 0.0743 - val_accuracy: 0.9294\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1342 - dice_coef: 0.1342 - accuracy: 0.6052 - val_loss: -0.0676 - val_dice_coef: 0.0676 - val_accuracy: 0.9230\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1354 - dice_coef: 0.1354 - accuracy: 0.6066 - val_loss: -0.0768 - val_dice_coef: 0.0768 - val_accuracy: 0.8789\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1380 - dice_coef: 0.1380 - accuracy: 0.6129 - val_loss: -0.1094 - val_dice_coef: 0.1094 - val_accuracy: 0.7720\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: -0.1388 - dice_coef: 0.1388 - accuracy: 0.6122 - val_loss: -0.0921 - val_dice_coef: 0.0921 - val_accuracy: 0.9137\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1358 - dice_coef: 0.1358 - accuracy: 0.6111 - val_loss: -0.0631 - val_dice_coef: 0.0631 - val_accuracy: 0.9050\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.1388 - dice_coef: 0.1388 - accuracy: 0.6126 - val_loss: -0.1036 - val_dice_coef: 0.1036 - val_accuracy: 0.8940\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1385 - dice_coef: 0.1385 - accuracy: 0.6167 - val_loss: -0.0822 - val_dice_coef: 0.0822 - val_accuracy: 0.9183\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1407 - dice_coef: 0.1407 - accuracy: 0.6221 - val_loss: -0.1053 - val_dice_coef: 0.1053 - val_accuracy: 0.8085\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1404 - dice_coef: 0.1404 - accuracy: 0.6207 - val_loss: -0.0878 - val_dice_coef: 0.0878 - val_accuracy: 0.6540\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1422 - dice_coef: 0.1422 - accuracy: 0.6263 - val_loss: -0.0860 - val_dice_coef: 0.0860 - val_accuracy: 0.9667\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1411 - dice_coef: 0.1411 - accuracy: 0.6284 - val_loss: -0.0994 - val_dice_coef: 0.0994 - val_accuracy: 0.8739\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1409 - dice_coef: 0.1409 - accuracy: 0.6267 - val_loss: -0.0632 - val_dice_coef: 0.0632 - val_accuracy: 0.6632\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1434 - dice_coef: 0.1434 - accuracy: 0.6289 - val_loss: -0.1331 - val_dice_coef: 0.1331 - val_accuracy: 0.9013\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1431 - dice_coef: 0.1431 - accuracy: 0.6306 - val_loss: -0.1099 - val_dice_coef: 0.1099 - val_accuracy: 0.7374\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1433 - dice_coef: 0.1433 - accuracy: 0.6317 - val_loss: -0.1268 - val_dice_coef: 0.1268 - val_accuracy: 0.8135\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1450 - dice_coef: 0.1450 - accuracy: 0.6348 - val_loss: -0.1694 - val_dice_coef: 0.1694 - val_accuracy: 0.8877\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1430 - dice_coef: 0.1430 - accuracy: 0.6320 - val_loss: -0.1847 - val_dice_coef: 0.1847 - val_accuracy: 0.9700\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1442 - dice_coef: 0.1442 - accuracy: 0.6378 - val_loss: -0.2027 - val_dice_coef: 0.2027 - val_accuracy: 0.9726\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1443 - dice_coef: 0.1443 - accuracy: 0.6383 - val_loss: -0.1693 - val_dice_coef: 0.1693 - val_accuracy: 0.9093\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1466 - dice_coef: 0.1466 - accuracy: 0.6408 - val_loss: -0.1304 - val_dice_coef: 0.1304 - val_accuracy: 0.8000\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1447 - dice_coef: 0.1447 - accuracy: 0.6408 - val_loss: -0.1734 - val_dice_coef: 0.1734 - val_accuracy: 0.8284\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1454 - dice_coef: 0.1454 - accuracy: 0.6418 - val_loss: -0.2035 - val_dice_coef: 0.2035 - val_accuracy: 0.9699\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1473 - dice_coef: 0.1473 - accuracy: 0.6442 - val_loss: -0.1528 - val_dice_coef: 0.1528 - val_accuracy: 0.9601\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1453 - dice_coef: 0.1453 - accuracy: 0.6431 - val_loss: -0.2987 - val_dice_coef: 0.2987 - val_accuracy: 0.9702\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1478 - dice_coef: 0.1478 - accuracy: 0.6483 - val_loss: -0.1315 - val_dice_coef: 0.1315 - val_accuracy: 0.6744\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1485 - dice_coef: 0.1485 - accuracy: 0.6492 - val_loss: -0.1543 - val_dice_coef: 0.1543 - val_accuracy: 0.9018\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1489 - dice_coef: 0.1489 - accuracy: 0.6515 - val_loss: -0.1931 - val_dice_coef: 0.1931 - val_accuracy: 0.9119\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1486 - dice_coef: 0.1486 - accuracy: 0.6507 - val_loss: -0.1497 - val_dice_coef: 0.1497 - val_accuracy: 0.8932\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1479 - dice_coef: 0.1479 - accuracy: 0.6505 - val_loss: -0.0983 - val_dice_coef: 0.0983 - val_accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1509 - dice_coef: 0.1509 - accuracy: 0.6576 - val_loss: -0.0532 - val_dice_coef: 0.0532 - val_accuracy: 0.4964\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1495 - dice_coef: 0.1495 - accuracy: 0.6574 - val_loss: -0.0822 - val_dice_coef: 0.0822 - val_accuracy: 0.7952\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1495 - dice_coef: 0.1495 - accuracy: 0.6608 - val_loss: -0.1640 - val_dice_coef: 0.1640 - val_accuracy: 0.9517\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1490 - dice_coef: 0.1490 - accuracy: 0.6568 - val_loss: -0.2823 - val_dice_coef: 0.2823 - val_accuracy: 0.9645\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1522 - dice_coef: 0.1522 - accuracy: 0.6624 - val_loss: -0.1460 - val_dice_coef: 0.1460 - val_accuracy: 0.9339\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1511 - dice_coef: 0.1511 - accuracy: 0.6648 - val_loss: -0.1692 - val_dice_coef: 0.1692 - val_accuracy: 0.7902\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1532 - dice_coef: 0.1532 - accuracy: 0.6676 - val_loss: -0.1621 - val_dice_coef: 0.1621 - val_accuracy: 0.8520\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1532 - dice_coef: 0.1532 - accuracy: 0.6724 - val_loss: -0.0953 - val_dice_coef: 0.0953 - val_accuracy: 0.8503\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1541 - dice_coef: 0.1541 - accuracy: 0.6723 - val_loss: -0.0829 - val_dice_coef: 0.0829 - val_accuracy: 0.7228\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1565 - dice_coef: 0.1565 - accuracy: 0.6776 - val_loss: -0.1434 - val_dice_coef: 0.1434 - val_accuracy: 0.8593\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1558 - dice_coef: 0.1558 - accuracy: 0.6793 - val_loss: -0.1433 - val_dice_coef: 0.1433 - val_accuracy: 0.8136\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: -0.1548 - dice_coef: 0.1548 - accuracy: 0.6779 - val_loss: -0.1800 - val_dice_coef: 0.1800 - val_accuracy: 0.9443\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 78s 195ms/step - loss: -0.3724 - dice_coef: 0.3724 - accuracy: 0.9322 - val_loss: -0.5277 - val_dice_coef: 0.5277 - val_accuracy: 0.9816\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 69s 173ms/step - loss: -0.4622 - dice_coef: 0.4622 - accuracy: 0.9690 - val_loss: -0.4472 - val_dice_coef: 0.4472 - val_accuracy: 0.9780\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 72s 181ms/step - loss: -0.4909 - dice_coef: 0.4909 - accuracy: 0.9736 - val_loss: -0.4289 - val_dice_coef: 0.4289 - val_accuracy: 0.9748\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 67s 167ms/step - loss: -0.5117 - dice_coef: 0.5117 - accuracy: 0.9762 - val_loss: -0.3466 - val_dice_coef: 0.3466 - val_accuracy: 0.9762\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 69s 171ms/step - loss: -0.5324 - dice_coef: 0.5324 - accuracy: 0.9790 - val_loss: -0.4514 - val_dice_coef: 0.4514 - val_accuracy: 0.9774\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 68s 169ms/step - loss: -0.5503 - dice_coef: 0.5503 - accuracy: 0.9810 - val_loss: -0.4926 - val_dice_coef: 0.4926 - val_accuracy: 0.9797\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 70s 175ms/step - loss: -0.5613 - dice_coef: 0.5613 - accuracy: 0.9823 - val_loss: -0.1672 - val_dice_coef: 0.1672 - val_accuracy: 0.9234\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 68s 169ms/step - loss: -0.5689 - dice_coef: 0.5689 - accuracy: 0.9833 - val_loss: -0.3594 - val_dice_coef: 0.3594 - val_accuracy: 0.9794\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 72s 179ms/step - loss: -0.5345 - dice_coef: 0.5345 - accuracy: 0.9828 - val_loss: -0.2697 - val_dice_coef: 0.2697 - val_accuracy: 0.9788\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 71s 178ms/step - loss: -0.2799 - dice_coef: 0.2799 - accuracy: 0.9653 - val_loss: -0.4603 - val_dice_coef: 0.4603 - val_accuracy: 0.9775\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 68s 171ms/step - loss: -0.2814 - dice_coef: 0.2814 - accuracy: 0.9653 - val_loss: -0.4646 - val_dice_coef: 0.4646 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 69s 172ms/step - loss: -0.2816 - dice_coef: 0.2816 - accuracy: 0.9653 - val_loss: -0.4619 - val_dice_coef: 0.4619 - val_accuracy: 0.9775\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 69s 171ms/step - loss: -0.2819 - dice_coef: 0.2819 - accuracy: 0.9653 - val_loss: -0.4616 - val_dice_coef: 0.4616 - val_accuracy: 0.9775\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 72s 180ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4612 - val_dice_coef: 0.4612 - val_accuracy: 0.9775\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 70s 175ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4609 - val_dice_coef: 0.4609 - val_accuracy: 0.9775\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 69s 171ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4608 - val_dice_coef: 0.4608 - val_accuracy: 0.9775\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 69s 172ms/step - loss: -0.2799 - dice_coef: 0.2799 - accuracy: 0.9654 - val_loss: -0.4609 - val_dice_coef: 0.4609 - val_accuracy: 0.9775\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 71s 178ms/step - loss: -0.2821 - dice_coef: 0.2821 - accuracy: 0.9653 - val_loss: -0.4612 - val_dice_coef: 0.4612 - val_accuracy: 0.9775\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 67s 167ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4611 - val_dice_coef: 0.4611 - val_accuracy: 0.9775\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 72s 179ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4612 - val_dice_coef: 0.4612 - val_accuracy: 0.9775\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 70s 176ms/step - loss: -0.2820 - dice_coef: 0.2820 - accuracy: 0.9653 - val_loss: -0.4613 - val_dice_coef: 0.4613 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r9_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 21s 53ms/step - loss: -0.2238 - dice_coef: 0.2238 - accuracy: 0.9179 - val_loss: -0.1467 - val_dice_coef: 0.1467 - val_accuracy: 0.8337\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.4829 - dice_coef: 0.4829 - accuracy: 0.9678 - val_loss: -0.2577 - val_dice_coef: 0.2577 - val_accuracy: 0.8875\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.5464 - dice_coef: 0.5464 - accuracy: 0.9718 - val_loss: -0.3854 - val_dice_coef: 0.3854 - val_accuracy: 0.9870\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.5729 - dice_coef: 0.5729 - accuracy: 0.9733 - val_loss: -0.4103 - val_dice_coef: 0.4103 - val_accuracy: 0.9865\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.5933 - dice_coef: 0.5933 - accuracy: 0.9740 - val_loss: -0.4239 - val_dice_coef: 0.4239 - val_accuracy: 0.9859\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.5906 - dice_coef: 0.5906 - accuracy: 0.9748 - val_loss: -0.3892 - val_dice_coef: 0.3892 - val_accuracy: 0.9863\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6020 - dice_coef: 0.6020 - accuracy: 0.9753 - val_loss: -0.4435 - val_dice_coef: 0.4435 - val_accuracy: 0.9864\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.5980 - dice_coef: 0.5980 - accuracy: 0.9751 - val_loss: -0.4531 - val_dice_coef: 0.4531 - val_accuracy: 0.9819\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.5958 - dice_coef: 0.5958 - accuracy: 0.9758 - val_loss: -0.4133 - val_dice_coef: 0.4133 - val_accuracy: 0.9861\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6002 - dice_coef: 0.6002 - accuracy: 0.9757 - val_loss: -0.4284 - val_dice_coef: 0.4284 - val_accuracy: 0.9859\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6205 - dice_coef: 0.6205 - accuracy: 0.9766 - val_loss: -0.4448 - val_dice_coef: 0.4448 - val_accuracy: 0.9873\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6108 - dice_coef: 0.6108 - accuracy: 0.9766 - val_loss: -0.4362 - val_dice_coef: 0.4362 - val_accuracy: 0.9865\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6079 - dice_coef: 0.6079 - accuracy: 0.9763 - val_loss: -0.4345 - val_dice_coef: 0.4345 - val_accuracy: 0.9869\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6160 - dice_coef: 0.6160 - accuracy: 0.9760 - val_loss: -0.4023 - val_dice_coef: 0.4023 - val_accuracy: 0.9832\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6321 - dice_coef: 0.6321 - accuracy: 0.9770 - val_loss: -0.3914 - val_dice_coef: 0.3914 - val_accuracy: 0.9866\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6209 - dice_coef: 0.6209 - accuracy: 0.9769 - val_loss: -0.4627 - val_dice_coef: 0.4627 - val_accuracy: 0.9855\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6238 - dice_coef: 0.6238 - accuracy: 0.9770 - val_loss: -0.4196 - val_dice_coef: 0.4196 - val_accuracy: 0.9870\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6116 - dice_coef: 0.6116 - accuracy: 0.9764 - val_loss: -0.4370 - val_dice_coef: 0.4370 - val_accuracy: 0.9866\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6210 - dice_coef: 0.6210 - accuracy: 0.9764 - val_loss: -0.4608 - val_dice_coef: 0.4608 - val_accuracy: 0.9872\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6138 - dice_coef: 0.6138 - accuracy: 0.9772 - val_loss: -0.4817 - val_dice_coef: 0.4817 - val_accuracy: 0.9871\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6421 - dice_coef: 0.6421 - accuracy: 0.9779 - val_loss: -0.4215 - val_dice_coef: 0.4215 - val_accuracy: 0.9860\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6132 - dice_coef: 0.6132 - accuracy: 0.9771 - val_loss: -0.4499 - val_dice_coef: 0.4499 - val_accuracy: 0.9872\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6340 - dice_coef: 0.6340 - accuracy: 0.9779 - val_loss: -0.4465 - val_dice_coef: 0.4465 - val_accuracy: 0.9868\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6341 - dice_coef: 0.6341 - accuracy: 0.9780 - val_loss: -0.4605 - val_dice_coef: 0.4605 - val_accuracy: 0.9868\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6214 - dice_coef: 0.6214 - accuracy: 0.9770 - val_loss: -0.5059 - val_dice_coef: 0.5059 - val_accuracy: 0.9872\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6339 - dice_coef: 0.6339 - accuracy: 0.9779 - val_loss: -0.4977 - val_dice_coef: 0.4977 - val_accuracy: 0.9875\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6403 - dice_coef: 0.6403 - accuracy: 0.9782 - val_loss: -0.4932 - val_dice_coef: 0.4932 - val_accuracy: 0.9873\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6333 - dice_coef: 0.6333 - accuracy: 0.9776 - val_loss: -0.4308 - val_dice_coef: 0.4308 - val_accuracy: 0.9861\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6347 - dice_coef: 0.6347 - accuracy: 0.9780 - val_loss: -0.4651 - val_dice_coef: 0.4651 - val_accuracy: 0.9861\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6345 - dice_coef: 0.6345 - accuracy: 0.9779 - val_loss: -0.4652 - val_dice_coef: 0.4652 - val_accuracy: 0.9854\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6202 - dice_coef: 0.6202 - accuracy: 0.9773 - val_loss: -0.5325 - val_dice_coef: 0.5325 - val_accuracy: 0.9874\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6259 - dice_coef: 0.6259 - accuracy: 0.9777 - val_loss: -0.4709 - val_dice_coef: 0.4709 - val_accuracy: 0.9859\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6347 - dice_coef: 0.6347 - accuracy: 0.9783 - val_loss: -0.5529 - val_dice_coef: 0.5529 - val_accuracy: 0.9877\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6296 - dice_coef: 0.6296 - accuracy: 0.9782 - val_loss: -0.5093 - val_dice_coef: 0.5093 - val_accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6218 - dice_coef: 0.6218 - accuracy: 0.9774 - val_loss: -0.4766 - val_dice_coef: 0.4766 - val_accuracy: 0.9858\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6247 - dice_coef: 0.6247 - accuracy: 0.9780 - val_loss: -0.5143 - val_dice_coef: 0.5143 - val_accuracy: 0.9869\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6223 - dice_coef: 0.6223 - accuracy: 0.9776 - val_loss: -0.5101 - val_dice_coef: 0.5101 - val_accuracy: 0.9869\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6294 - dice_coef: 0.6294 - accuracy: 0.9779 - val_loss: -0.5375 - val_dice_coef: 0.5375 - val_accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6324 - dice_coef: 0.6324 - accuracy: 0.9782 - val_loss: -0.4795 - val_dice_coef: 0.4795 - val_accuracy: 0.9851\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6256 - dice_coef: 0.6256 - accuracy: 0.9778 - val_loss: -0.5174 - val_dice_coef: 0.5174 - val_accuracy: 0.9868\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6146 - dice_coef: 0.6146 - accuracy: 0.9776 - val_loss: -0.5498 - val_dice_coef: 0.5498 - val_accuracy: 0.9873\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6192 - dice_coef: 0.6192 - accuracy: 0.9784 - val_loss: -0.4458 - val_dice_coef: 0.4458 - val_accuracy: 0.9847\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 17s 41ms/step - loss: -0.6269 - dice_coef: 0.6269 - accuracy: 0.9785 - val_loss: -0.5739 - val_dice_coef: 0.5739 - val_accuracy: 0.9877\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6314 - dice_coef: 0.6314 - accuracy: 0.9786 - val_loss: -0.4637 - val_dice_coef: 0.4637 - val_accuracy: 0.9853\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6418 - dice_coef: 0.6418 - accuracy: 0.9786 - val_loss: -0.4582 - val_dice_coef: 0.4582 - val_accuracy: 0.9851\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6293 - dice_coef: 0.6293 - accuracy: 0.9781 - val_loss: -0.5241 - val_dice_coef: 0.5241 - val_accuracy: 0.9864\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6274 - dice_coef: 0.6274 - accuracy: 0.9780 - val_loss: -0.5459 - val_dice_coef: 0.5459 - val_accuracy: 0.9869\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6465 - dice_coef: 0.6465 - accuracy: 0.9788 - val_loss: -0.4779 - val_dice_coef: 0.4779 - val_accuracy: 0.9849\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6435 - dice_coef: 0.6435 - accuracy: 0.9787 - val_loss: -0.5416 - val_dice_coef: 0.5416 - val_accuracy: 0.9875\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 17s 42ms/step - loss: -0.6257 - dice_coef: 0.6257 - accuracy: 0.9784 - val_loss: -0.4872 - val_dice_coef: 0.4872 - val_accuracy: 0.9849\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 62s 154ms/step - loss: -0.4994 - dice_coef: 0.4994 - accuracy: 0.9726 - val_loss: -0.6578 - val_dice_coef: 0.6578 - val_accuracy: 0.9854\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 52s 131ms/step - loss: -0.5335 - dice_coef: 0.5335 - accuracy: 0.9766 - val_loss: -0.5342 - val_dice_coef: 0.5342 - val_accuracy: 0.9843\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 53s 131ms/step - loss: -0.5555 - dice_coef: 0.5555 - accuracy: 0.9803 - val_loss: -0.5508 - val_dice_coef: 0.5508 - val_accuracy: 0.9844\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 54s 134ms/step - loss: -0.5703 - dice_coef: 0.5703 - accuracy: 0.9823 - val_loss: -0.6573 - val_dice_coef: 0.6573 - val_accuracy: 0.9851\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 53s 131ms/step - loss: -0.5801 - dice_coef: 0.5801 - accuracy: 0.9844 - val_loss: -0.4255 - val_dice_coef: 0.4255 - val_accuracy: 0.9852\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 53s 133ms/step - loss: -0.5348 - dice_coef: 0.5348 - accuracy: 0.9790 - val_loss: -0.2423 - val_dice_coef: 0.2423 - val_accuracy: 0.9542\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 53s 132ms/step - loss: -0.5907 - dice_coef: 0.5907 - accuracy: 0.9802 - val_loss: -0.1917 - val_dice_coef: 0.1917 - val_accuracy: 0.9710\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 53s 131ms/step - loss: -0.5999 - dice_coef: 0.5999 - accuracy: 0.9775 - val_loss: -0.3830 - val_dice_coef: 0.3830 - val_accuracy: 0.9856\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 53s 133ms/step - loss: -0.6497 - dice_coef: 0.6497 - accuracy: 0.9807 - val_loss: -0.6378 - val_dice_coef: 0.6378 - val_accuracy: 0.9869\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 54s 135ms/step - loss: -0.6598 - dice_coef: 0.6598 - accuracy: 0.9813 - val_loss: -0.2898 - val_dice_coef: 0.2898 - val_accuracy: 0.9315\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 53s 134ms/step - loss: -0.5955 - dice_coef: 0.5955 - accuracy: 0.9773 - val_loss: -0.6089 - val_dice_coef: 0.6089 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 54s 135ms/step - loss: -0.6865 - dice_coef: 0.6865 - accuracy: 0.9801 - val_loss: -0.6261 - val_dice_coef: 0.6261 - val_accuracy: 0.9862\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 53s 132ms/step - loss: -0.6826 - dice_coef: 0.6826 - accuracy: 0.9820 - val_loss: -0.6301 - val_dice_coef: 0.6301 - val_accuracy: 0.9848\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 53s 132ms/step - loss: -0.7141 - dice_coef: 0.7141 - accuracy: 0.9835 - val_loss: -0.4443 - val_dice_coef: 0.4443 - val_accuracy: 0.9539\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 53s 132ms/step - loss: -0.7175 - dice_coef: 0.7175 - accuracy: 0.9833 - val_loss: -0.6452 - val_dice_coef: 0.6452 - val_accuracy: 0.9867\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 55s 137ms/step - loss: -0.7154 - dice_coef: 0.7154 - accuracy: 0.9835 - val_loss: -0.6313 - val_dice_coef: 0.6313 - val_accuracy: 0.9864\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 52s 131ms/step - loss: -0.7043 - dice_coef: 0.7043 - accuracy: 0.9825 - val_loss: -0.6490 - val_dice_coef: 0.6490 - val_accuracy: 0.9871\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 54s 134ms/step - loss: -0.7191 - dice_coef: 0.7191 - accuracy: 0.9834 - val_loss: -0.5755 - val_dice_coef: 0.5755 - val_accuracy: 0.9860\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 53s 133ms/step - loss: -0.7123 - dice_coef: 0.7123 - accuracy: 0.9832 - val_loss: -0.5579 - val_dice_coef: 0.5579 - val_accuracy: 0.9865\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 53s 132ms/step - loss: -0.7669 - dice_coef: 0.7669 - accuracy: 0.9851 - val_loss: -0.6457 - val_dice_coef: 0.6457 - val_accuracy: 0.9849\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 53s 133ms/step - loss: -0.7638 - dice_coef: 0.7638 - accuracy: 0.9857 - val_loss: -0.6496 - val_dice_coef: 0.6496 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n",
      "model_fine_tuning_No_NAIP_500_samples_r10_\n",
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n",
      "(400, 224, 224, 8)\n",
      "(400, 224, 224, 1)\n",
      "(100, 224, 224, 8)\n",
      "(100, 224, 224, 1)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 27s 68ms/step - loss: -0.2224 - dice_coef: 0.2224 - accuracy: 0.9474 - val_loss: -0.0751 - val_dice_coef: 0.0751 - val_accuracy: 0.3631\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.5035 - dice_coef: 0.5035 - accuracy: 0.9687 - val_loss: -0.3510 - val_dice_coef: 0.3510 - val_accuracy: 0.9613\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.5671 - dice_coef: 0.5671 - accuracy: 0.9727 - val_loss: -0.4179 - val_dice_coef: 0.4179 - val_accuracy: 0.9749\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6038 - dice_coef: 0.6038 - accuracy: 0.9747 - val_loss: -0.3513 - val_dice_coef: 0.3513 - val_accuracy: 0.9812\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6104 - dice_coef: 0.6104 - accuracy: 0.9755 - val_loss: -0.4373 - val_dice_coef: 0.4373 - val_accuracy: 0.9797\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6082 - dice_coef: 0.6082 - accuracy: 0.9749 - val_loss: -0.4438 - val_dice_coef: 0.4438 - val_accuracy: 0.9817\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6124 - dice_coef: 0.6124 - accuracy: 0.9760 - val_loss: -0.4351 - val_dice_coef: 0.4351 - val_accuracy: 0.9784\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6204 - dice_coef: 0.6204 - accuracy: 0.9760 - val_loss: -0.3407 - val_dice_coef: 0.3407 - val_accuracy: 0.9813\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6339 - dice_coef: 0.6339 - accuracy: 0.9767 - val_loss: -0.3746 - val_dice_coef: 0.3746 - val_accuracy: 0.9771\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6247 - dice_coef: 0.6247 - accuracy: 0.9766 - val_loss: -0.4252 - val_dice_coef: 0.4252 - val_accuracy: 0.9775\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6331 - dice_coef: 0.6331 - accuracy: 0.9767 - val_loss: -0.2900 - val_dice_coef: 0.2900 - val_accuracy: 0.9805\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.5990 - dice_coef: 0.5990 - accuracy: 0.9752 - val_loss: -0.4335 - val_dice_coef: 0.4335 - val_accuracy: 0.9807\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6494 - dice_coef: 0.6494 - accuracy: 0.9775 - val_loss: -0.3068 - val_dice_coef: 0.3068 - val_accuracy: 0.9799\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6364 - dice_coef: 0.6364 - accuracy: 0.9774 - val_loss: -0.3526 - val_dice_coef: 0.3526 - val_accuracy: 0.9818\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6417 - dice_coef: 0.6417 - accuracy: 0.9773 - val_loss: -0.2051 - val_dice_coef: 0.2051 - val_accuracy: 0.9795\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6316 - dice_coef: 0.6316 - accuracy: 0.9768 - val_loss: -0.4540 - val_dice_coef: 0.4540 - val_accuracy: 0.9774\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6347 - dice_coef: 0.6347 - accuracy: 0.9778 - val_loss: -0.3237 - val_dice_coef: 0.3237 - val_accuracy: 0.9807\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 23s 58ms/step - loss: -0.6394 - dice_coef: 0.6394 - accuracy: 0.9782 - val_loss: -0.4122 - val_dice_coef: 0.4122 - val_accuracy: 0.9810\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6229 - dice_coef: 0.6229 - accuracy: 0.9770 - val_loss: -0.3890 - val_dice_coef: 0.3890 - val_accuracy: 0.9811\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6337 - dice_coef: 0.6337 - accuracy: 0.9771 - val_loss: -0.3236 - val_dice_coef: 0.3236 - val_accuracy: 0.9803\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6441 - dice_coef: 0.6441 - accuracy: 0.9777 - val_loss: -0.3505 - val_dice_coef: 0.3505 - val_accuracy: 0.9809\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6466 - dice_coef: 0.6466 - accuracy: 0.9779 - val_loss: -0.3833 - val_dice_coef: 0.3833 - val_accuracy: 0.9813\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6402 - dice_coef: 0.6402 - accuracy: 0.9778 - val_loss: -0.2892 - val_dice_coef: 0.2892 - val_accuracy: 0.9800\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6363 - dice_coef: 0.6363 - accuracy: 0.9774 - val_loss: -0.4344 - val_dice_coef: 0.4344 - val_accuracy: 0.9788\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6347 - dice_coef: 0.6347 - accuracy: 0.9776 - val_loss: -0.3389 - val_dice_coef: 0.3389 - val_accuracy: 0.9816\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6567 - dice_coef: 0.6567 - accuracy: 0.9781 - val_loss: -0.3047 - val_dice_coef: 0.3047 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6332 - dice_coef: 0.6332 - accuracy: 0.9781 - val_loss: -0.3579 - val_dice_coef: 0.3579 - val_accuracy: 0.9800\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6497 - dice_coef: 0.6497 - accuracy: 0.9783 - val_loss: -0.2679 - val_dice_coef: 0.2679 - val_accuracy: 0.9790\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6515 - dice_coef: 0.6515 - accuracy: 0.9785 - val_loss: -0.2644 - val_dice_coef: 0.2644 - val_accuracy: 0.9795\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6537 - dice_coef: 0.6537 - accuracy: 0.9781 - val_loss: -0.2929 - val_dice_coef: 0.2929 - val_accuracy: 0.9788\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6349 - dice_coef: 0.6349 - accuracy: 0.9779 - val_loss: -0.3299 - val_dice_coef: 0.3299 - val_accuracy: 0.9797\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6234 - dice_coef: 0.6234 - accuracy: 0.9775 - val_loss: -0.2531 - val_dice_coef: 0.2531 - val_accuracy: 0.9780\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6376 - dice_coef: 0.6376 - accuracy: 0.9781 - val_loss: -0.3175 - val_dice_coef: 0.3175 - val_accuracy: 0.9792\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6425 - dice_coef: 0.6425 - accuracy: 0.9783 - val_loss: -0.3300 - val_dice_coef: 0.3300 - val_accuracy: 0.9789\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6520 - dice_coef: 0.6520 - accuracy: 0.9783 - val_loss: -0.3017 - val_dice_coef: 0.3017 - val_accuracy: 0.9790\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 23s 57ms/step - loss: -0.6590 - dice_coef: 0.6590 - accuracy: 0.9787 - val_loss: -0.3681 - val_dice_coef: 0.3681 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 68s 170ms/step - loss: -0.5201 - dice_coef: 0.5201 - accuracy: 0.9742 - val_loss: -0.5141 - val_dice_coef: 0.5141 - val_accuracy: 0.9719\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 60s 150ms/step - loss: -0.5551 - dice_coef: 0.5551 - accuracy: 0.9789 - val_loss: -0.4129 - val_dice_coef: 0.4129 - val_accuracy: 0.9667\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 60s 151ms/step - loss: -0.5725 - dice_coef: 0.5725 - accuracy: 0.9801 - val_loss: -0.5041 - val_dice_coef: 0.5041 - val_accuracy: 0.9731\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 59s 148ms/step - loss: -0.5896 - dice_coef: 0.5896 - accuracy: 0.9825 - val_loss: -0.5228 - val_dice_coef: 0.5228 - val_accuracy: 0.9748\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 59s 149ms/step - loss: -0.5885 - dice_coef: 0.5885 - accuracy: 0.9839 - val_loss: -0.4698 - val_dice_coef: 0.4698 - val_accuracy: 0.9787\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 62s 154ms/step - loss: -0.5776 - dice_coef: 0.5776 - accuracy: 0.9813 - val_loss: -0.4921 - val_dice_coef: 0.4921 - val_accuracy: 0.9674\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 59s 148ms/step - loss: -0.6499 - dice_coef: 0.6499 - accuracy: 0.9824 - val_loss: -0.5339 - val_dice_coef: 0.5339 - val_accuracy: 0.9807\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 59s 147ms/step - loss: -0.7086 - dice_coef: 0.7086 - accuracy: 0.9862 - val_loss: -0.4863 - val_dice_coef: 0.4863 - val_accuracy: 0.9710\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 61s 151ms/step - loss: -0.5645 - dice_coef: 0.5645 - accuracy: 0.9791 - val_loss: -0.2087 - val_dice_coef: 0.2087 - val_accuracy: 0.9753\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 59s 146ms/step - loss: -0.2165 - dice_coef: 0.2165 - accuracy: 0.9631 - val_loss: -0.2953 - val_dice_coef: 0.2953 - val_accuracy: 0.9752\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 61s 152ms/step - loss: -0.2260 - dice_coef: 0.2260 - accuracy: 0.9631 - val_loss: -0.3004 - val_dice_coef: 0.3004 - val_accuracy: 0.9752\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 60s 151ms/step - loss: -0.2306 - dice_coef: 0.2306 - accuracy: 0.9631 - val_loss: -0.3105 - val_dice_coef: 0.3105 - val_accuracy: 0.9752\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 62s 155ms/step - loss: -0.2338 - dice_coef: 0.2338 - accuracy: 0.9631 - val_loss: -0.3199 - val_dice_coef: 0.3199 - val_accuracy: 0.9752\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 59s 147ms/step - loss: -0.2363 - dice_coef: 0.2363 - accuracy: 0.9631 - val_loss: -0.3258 - val_dice_coef: 0.3258 - val_accuracy: 0.9752\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 61s 153ms/step - loss: -0.2381 - dice_coef: 0.2381 - accuracy: 0.9631 - val_loss: -0.3326 - val_dice_coef: 0.3326 - val_accuracy: 0.9752\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 61s 152ms/step - loss: -0.2396 - dice_coef: 0.2396 - accuracy: 0.9631 - val_loss: -0.3360 - val_dice_coef: 0.3360 - val_accuracy: 0.9752\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 60s 149ms/step - loss: -0.2408 - dice_coef: 0.2408 - accuracy: 0.9631 - val_loss: -0.3385 - val_dice_coef: 0.3385 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.5130000358331015e-05.\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 60s 150ms/step - loss: -0.2416 - dice_coef: 0.2416 - accuracy: 0.9631 - val_loss: -0.3395 - val_dice_coef: 0.3395 - val_accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 60s 149ms/step - loss: -0.2422 - dice_coef: 0.2422 - accuracy: 0.9631 - val_loss: -0.3416 - val_dice_coef: 0.3416 - val_accuracy: 0.9752\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 59s 148ms/step - loss: -0.2428 - dice_coef: 0.2428 - accuracy: 0.9631 - val_loss: -0.3426 - val_dice_coef: 0.3426 - val_accuracy: 0.9752\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 59s 148ms/step - loss: -0.2433 - dice_coef: 0.2433 - accuracy: 0.9631 - val_loss: -0.3440 - val_dice_coef: 0.3440 - val_accuracy: 0.9752\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 60s 149ms/step - loss: -0.2437 - dice_coef: 0.2437 - accuracy: 0.9631 - val_loss: -0.3446 - val_dice_coef: 0.3446 - val_accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 60s 150ms/step - loss: -0.2441 - dice_coef: 0.2441 - accuracy: 0.9631 - val_loss: -0.3455 - val_dice_coef: 0.3455 - val_accuracy: 0.9752\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 59s 148ms/step - loss: -0.2445 - dice_coef: 0.2445 - accuracy: 0.9631 - val_loss: -0.3462 - val_dice_coef: 0.3462 - val_accuracy: 0.9752\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 61s 152ms/step - loss: -0.2448 - dice_coef: 0.2448 - accuracy: 0.9631 - val_loss: -0.3469 - val_dice_coef: 0.3469 - val_accuracy: 0.9752\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 61s 151ms/step - loss: -0.2451 - dice_coef: 0.2451 - accuracy: 0.9631 - val_loss: -0.3475 - val_dice_coef: 0.3475 - val_accuracy: 0.9752\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 63s 157ms/step - loss: -0.2453 - dice_coef: 0.2453 - accuracy: 0.9631 - val_loss: -0.3479 - val_dice_coef: 0.3479 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.7591000505490227e-05.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "# from keras import backend as k\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate\n",
    "\n",
    "\n",
    "for sample_size in range(200,600,100):\n",
    "    for round_num in range(1,11):\n",
    "        \n",
    "        name = \"model_fine_tuning_\"\n",
    "        name += 'No_NAIP_'\n",
    "        name += str(sample_size)+\"_\"\n",
    "        name += \"samples_r\"+str(round_num)+\"_\"\n",
    "        \n",
    "        print(name)\n",
    "        root_path = './training_results/'+str(sample_size)+'/'\n",
    "        \n",
    "        if os.path.exists(root_path+name+\".h5\"):\n",
    "            print(\"exists\")\n",
    "            continue;\n",
    "\n",
    "        loaded_model = load_model('../June21/model/model_augv_attention2.h5', \n",
    "                                     custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                                     'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "        # remove the last 2 layer using pop() function\n",
    "        loaded_model.layers.pop()\n",
    "        loaded_model.layers.pop()\n",
    "\n",
    "        for (index, layer) in enumerate(loaded_model.layers):\n",
    "            if (index < 4):\n",
    "                print(\"index \",index)\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        # Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "        model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "        # See model structure\n",
    "        #model_without_last.summary()\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "        # 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "        conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "        new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "        # Created new model with the newly added last two layers \n",
    "        transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "        # New model structure\n",
    "        # transfered_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "        # The dataset has 9 channels:\n",
    "        # 0. Curvature\n",
    "        # 1. Slope\n",
    "        # 2. Openness\n",
    "        # 3. DEM\n",
    "        # 4. TPI 21\n",
    "        # 5. Reflectance (LiDAR intensity)\n",
    "        # 6. Geomorphon\n",
    "        # 7. TPI 9\n",
    "        # 8. TPI 3\n",
    "\n",
    "        data_path = './samples/'+str(sample_size)+'/'+str(round_num)+'/'\n",
    "        # read in training and validation data\n",
    "        X_train_new = np.load(data_path+'train_data.npy')\n",
    "        print(X_train_new.shape)\n",
    "        Y_train = np.load(data_path+'train_label.npy')\n",
    "        print(Y_train.shape)\n",
    "        X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "        print(X_Validation_new.shape)\n",
    "        Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "        print(Y_Validation.shape)\n",
    "\n",
    "        # The 300 training + 300 validation samples files\n",
    "        # data_path = './samples/'\n",
    "        # # read in training and validation data\n",
    "        # X_train = np.load(data_path+'train_data.npy')\n",
    "        # Y_train = np.load(data_path+'train_label.npy')\n",
    "        # X_Validation = np.load(data_path+'vali_data.npy')\n",
    "        # Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # learning_rate = 0.0000359\n",
    "        # learning_rate = 0.0001\n",
    "        learning_rate = 0.001\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('first_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P1_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=2, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        for (index, layer) in enumerate(transfered_model.layers):\n",
    "            layer.trainable = True\n",
    "\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # 100 times smaller learning rate\n",
    "        learning_rate = 0.0000359\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('second_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P2_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=1, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        import pickle\n",
    "        # save the trained model\n",
    "        model_yaml = transfered_model.to_yaml()\n",
    "        with open(root_path+name+\".yaml\", \"w\") as yaml_file:\n",
    "            yaml_file.write(model_yaml)\n",
    "        # save the weights\n",
    "        transfered_model.save(root_path+name+\".h5\")\n",
    "        # save the intermdediate rescults and training statistics\n",
    "        with open(root_path+name+\".pickle\", 'wb') as file_pi:\n",
    "            pickle.dump(fine_tuned_model_P2_history.history, file_pi, protocol=2)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = '../../wink.mp3'\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "# from keras import backend as k\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate\n",
    "\n",
    "\n",
    "for sample_size in range(200,600,100):\n",
    "    for round_num in range(1,11):\n",
    "        \n",
    "        name = \"model_fine_tuning_\"\n",
    "        name += 'No_NAIP_'\n",
    "        name += str(sample_size)+\"_\"\n",
    "        name += \"samples_r\"+str(round_num)+\"_\"\n",
    "        \n",
    "        print(name)\n",
    "        root_path = './training_results/'+str(sample_size)+'/'\n",
    "        \n",
    "        if os.path.exists(root_path+name+\".h5\"):\n",
    "            print(\"exists\")\n",
    "            continue;\n",
    "\n",
    "        loaded_model = load_model('../June21/model/model_augv_attention2.h5', \n",
    "                                     custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                                     'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "        # remove the last 2 layer using pop() function\n",
    "        loaded_model.layers.pop()\n",
    "        loaded_model.layers.pop()\n",
    "\n",
    "        for (index, layer) in enumerate(loaded_model.layers):\n",
    "            if (index < 4):\n",
    "                print(\"index \",index)\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        # Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "        model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "        # See model structure\n",
    "        #model_without_last.summary()\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "        # 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "        conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "        new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "        # Created new model with the newly added last two layers \n",
    "        transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "        # New model structure\n",
    "        # transfered_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "        # The dataset has 9 channels:\n",
    "        # 0. Curvature\n",
    "        # 1. Slope\n",
    "        # 2. Openness\n",
    "        # 3. DEM\n",
    "        # 4. TPI 21\n",
    "        # 5. Reflectance (LiDAR intensity)\n",
    "        # 6. Geomorphon\n",
    "        # 7. TPI 9\n",
    "        # 8. TPI 3\n",
    "\n",
    "        data_path = './samples/'+str(sample_size)+'/'+str(round_num)+'/'\n",
    "        # read in training and validation data\n",
    "        X_train_new = np.load(data_path+'train_data.npy')\n",
    "        print(X_train_new.shape)\n",
    "        Y_train = np.load(data_path+'train_label.npy')\n",
    "        print(Y_train.shape)\n",
    "        X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "        print(X_Validation_new.shape)\n",
    "        Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "        print(Y_Validation.shape)\n",
    "\n",
    "        # The 300 training + 300 validation samples files\n",
    "        # data_path = './samples/'\n",
    "        # # read in training and validation data\n",
    "        # X_train = np.load(data_path+'train_data.npy')\n",
    "        # Y_train = np.load(data_path+'train_label.npy')\n",
    "        # X_Validation = np.load(data_path+'vali_data.npy')\n",
    "        # Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # learning_rate = 0.0000359\n",
    "        # learning_rate = 0.0001\n",
    "        learning_rate = 0.001\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('first_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P1_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=2, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        for (index, layer) in enumerate(transfered_model.layers):\n",
    "            layer.trainable = True\n",
    "\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # 100 times smaller learning rate\n",
    "        learning_rate = 0.0000359\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('second_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P2_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=1, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        import pickle\n",
    "        # save the trained model\n",
    "        model_yaml = transfered_model.to_yaml()\n",
    "        with open(root_path+name+\".yaml\", \"w\") as yaml_file:\n",
    "            yaml_file.write(model_yaml)\n",
    "        # save the weights\n",
    "        transfered_model.save(root_path+name+\".h5\")\n",
    "        # save the intermdediate rescults and training statistics\n",
    "        with open(root_path+name+\".pickle\", 'wb') as file_pi:\n",
    "            pickle.dump(fine_tuned_model_P2_history.history, file_pi, protocol=2)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = '../../wink.mp3'\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "# from keras import backend as k\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "\n",
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate\n",
    "\n",
    "\n",
    "for sample_size in range(200,600,100):\n",
    "    for round_num in range(1,11):\n",
    "        \n",
    "        name = \"model_fine_tuning_\"\n",
    "        name += 'No_NAIP_'\n",
    "        name += str(sample_size)+\"_\"\n",
    "        name += \"samples_r\"+str(round_num)+\"_\"\n",
    "        \n",
    "        print(name)\n",
    "        root_path = './training_results/'+str(sample_size)+'/'\n",
    "        \n",
    "        if os.path.exists(root_path+name+\".h5\"):\n",
    "            print(\"exists\")\n",
    "            continue;\n",
    "\n",
    "        loaded_model = load_model('../June21/model/model_augv_attention2.h5', \n",
    "                                     custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                                     'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "        # remove the last 2 layer using pop() function\n",
    "        loaded_model.layers.pop()\n",
    "        loaded_model.layers.pop()\n",
    "\n",
    "        for (index, layer) in enumerate(loaded_model.layers):\n",
    "            if (index < 4):\n",
    "                print(\"index \",index)\n",
    "                layer.trainable = True\n",
    "            else:\n",
    "                layer.trainable = False\n",
    "\n",
    "        # Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "        model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "        # See model structure\n",
    "        #model_without_last.summary()\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "        # 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "        conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "        new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "        # Created new model with the newly added last two layers \n",
    "        transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "        # New model structure\n",
    "        # transfered_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "        # The dataset has 9 channels:\n",
    "        # 0. Curvature\n",
    "        # 1. Slope\n",
    "        # 2. Openness\n",
    "        # 3. DEM\n",
    "        # 4. TPI 21\n",
    "        # 5. Reflectance (LiDAR intensity)\n",
    "        # 6. Geomorphon\n",
    "        # 7. TPI 9\n",
    "        # 8. TPI 3\n",
    "\n",
    "        data_path = './samples/'+str(sample_size)+'/'+str(round_num)+'/'\n",
    "        # read in training and validation data\n",
    "        X_train_new = np.load(data_path+'train_data.npy')\n",
    "        print(X_train_new.shape)\n",
    "        Y_train = np.load(data_path+'train_label.npy')\n",
    "        print(Y_train.shape)\n",
    "        X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "        print(X_Validation_new.shape)\n",
    "        Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "        print(Y_Validation.shape)\n",
    "\n",
    "        # The 300 training + 300 validation samples files\n",
    "        # data_path = './samples/'\n",
    "        # # read in training and validation data\n",
    "        # X_train = np.load(data_path+'train_data.npy')\n",
    "        # Y_train = np.load(data_path+'train_label.npy')\n",
    "        # X_Validation = np.load(data_path+'vali_data.npy')\n",
    "        # Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # learning_rate = 0.0000359\n",
    "        # learning_rate = 0.0001\n",
    "        learning_rate = 0.001\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('first_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P1_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=2, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        for (index, layer) in enumerate(transfered_model.layers):\n",
    "            layer.trainable = True\n",
    "\n",
    "\n",
    "        patch_size = 224\n",
    "        IMG_WIDTH = patch_size\n",
    "        IMG_HEIGHT = patch_size\n",
    "        # Number of feature channels \n",
    "        INPUT_CHANNELS = 8\n",
    "        # Number of output masks (1 in case you predict only one type of objects)\n",
    "        OUTPUT_MASK_CHANNELS = 1\n",
    "        maxepoch = 50\n",
    "        # hyperparameters\n",
    "        # 100 times smaller learning rate\n",
    "        learning_rate = 0.0000359\n",
    "        patience = 10\n",
    "        aug = 'v'\n",
    "        transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "        callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "                EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "                ModelCheckpoint('second_pass_model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "            ]\n",
    "\n",
    "        fine_tuned_model_P2_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=1, epochs=maxepoch, callbacks=callbacks)\n",
    "\n",
    "\n",
    "        import pickle\n",
    "        # save the trained model\n",
    "        model_yaml = transfered_model.to_yaml()\n",
    "        with open(root_path+name+\".yaml\", \"w\") as yaml_file:\n",
    "            yaml_file.write(model_yaml)\n",
    "        # save the weights\n",
    "        transfered_model.save(root_path+name+\".h5\")\n",
    "        # save the intermdediate rescults and training statistics\n",
    "        with open(root_path+name+\".pickle\", 'wb') as file_pi:\n",
    "            pickle.dump(fine_tuned_model_P2_history.history, file_pi, protocol=2)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = '../../wink.mp3'\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
