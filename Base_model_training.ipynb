{"cells":[{"cell_type":"markdown","metadata":{"id":"c9zAe-uH9kEi"},"source":["# Load Libraries "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":2464,"status":"ok","timestamp":1661715130649,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"-Cb7UK6T9tUb","outputId":"b8efb962-098f-4589-861d-2a0d3bf4b50f"},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'tf.keras'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["%pip install segmentation-models &> /dev/null\n","%load_ext tensorboard\n","\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K\n","import segmentation_models as sm\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n","from unet_util import dice_coef_loss, dice_coef, jacard_coef, dice_coef_loss, Residual_CNN_block, multiplication, attention_up_and_concatenate, multiplication2, attention_up_and_concatenate2, UNET_224, evaluate_prediction_result\n","\n","sm.set_framework('tf.keras')\n","sm.framework()"]},{"cell_type":"markdown","metadata":{"id":"EUSWDipm7occ"},"source":["### Define nesscesary paths \n","\n","- Data folder\n","- Path to save models\n","- Path to save prediction data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1661715130651,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"UMOXIcgZ7nYs","outputId":"630b1c54-de46-4978-c4c5-398abdee9562"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Transfere Learning research/Notebooks\n","model location: ./models/rowancreek-Unet-attentionUnet-tf.h5\n"]}],"source":["import os\n","input_data = './samples/'\n","model_path = './models/'\n","prediction_path = './predicts/'\n","log_path = './logs/'\n","\n","# Create the folder if it does not exist\n","os.makedirs(input_data, exist_ok=True)\n","os.makedirs(model_path, exist_ok=True)\n","os.makedirs(prediction_path, exist_ok=True)\n","\n","# Avaiable backbones for Unet architechture\n","# 'vgg16' 'vgg19' 'resnet18' 'resnet34' 'resnet50' 'resnet101' 'resnet152' 'inceptionv3' \n","# 'inceptionresnetv2' 'densenet121' 'densenet169' 'densenet201' 'seresnet18' 'seresnet34' \n","# 'seresnet50' 'seresnet101' 'seresnet152', and 'attentionUnet'\n","backend = 'attentionUnet'\n","\n","# Data location\n","# 'covington' 'rowancreek'\n","location = 'rowancreek'\n","\n","# Fine-tuning flag\n","# True/False\n","finetune = True\n","\n","# Construct the model save file name\n","name = location+'-Unet-'+backend + ('-tf' if(finetune) else '')\n","\n","logdir = log_path + name\n","if(os.path.isdir(logdir)):\n","  shutil.rmtree(logdir)\n","os.makedirs(logdir, exist_ok=True)\n","# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n","\n","print('model location: '+ model_path+name+'.h5')"]},{"cell_type":"markdown","metadata":{"id":"gHBpksNiCs3g"},"source":["# Create the model with selected backend"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4740,"status":"ok","timestamp":1661715135373,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"VdJ6uFTNA87V"},"outputs":[],"source":["# Create U-net model with the chosen backbone\n","# The U-net will be initialized with ImageNet weights and the ImageNet weights will be frozen \n","# in the first pass training\n","\n","if (backend==\"attentionUnet\"):\n","  # Attention U-net model\n","  learning_rate =0.0000359\n","  model = UNET_224()\n","  model.compile(optimizer = Adam(learning_rate=learning_rate), \n","                loss = dice_coef_loss, \n","                metrics = [dice_coef,'accuracy'])\n","else:\n","  # Unet with ImageNet backends\n","  base_model = sm.Unet(backend, classes = 1, encoder_weights = 'imagenet', encoder_freeze = finetune)\n","  \n","  # The backbones are trained RGB so we need to add new input wiht 8 channels\n","  # Conv2D will convert 8 channels input to 3 channels input for the pretrained backbones\n","  inp = Input(shape=(None, None, 8))\n","  l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n","  out = base_model(l1)\n","  model = Model(inp, out, name = base_model.name)\n","  \n","  # Compile the model with 'Adam' optimizer (0.001 is the default learning rate) and define the loss and metrics\n","  model.compile(optimizer = Adam(), loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n","\n","# define hyperparameters and callback modules\n","patience = 10\n","maxepoch = 500\n","callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n","             EarlyStopping(monitor='val_loss', patience=patience, verbose=0),\n","             ModelCheckpoint(model_path+name+'.h5', monitor='val_loss', save_best_only=True, verbose=0),\n","             TensorBoard(log_dir=logdir)]"]},{"cell_type":"markdown","metadata":{"id":"c4xpDXFp9cTJ"},"source":["# Training\n","\n","- load data \n","- model.fit \n","  - save the model in ./models/\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":68309,"status":"ok","timestamp":1661715203670,"user":{"displayName":"Nattapon Jaroenchai","userId":"17092454241854925654"},"user_tz":300},"id":"5QBb8rC7-KvE"},"outputs":[],"source":["X_train = np.load(input_data+location+'/train_data.npy').astype(np.float32)\n","Y_train = np.load(input_data+location+'/train_label.npy').astype(np.float32)\n","X_validation = np.load(input_data+location+'/vali_data.npy').astype(np.float32)\n","Y_validation = np.load(input_data+location+'/vali_label.npy').astype(np.float32)"]},{"cell_type":"markdown","metadata":{"id":"lnDGHY99YgEZ"},"source":["### First pass \n","\n","- learning rate: 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzCWDEXKXkEj"},"outputs":[],"source":["train_history = model.fit(x = X_train,y = Y_train, \n","                          validation_data = (X_validation, Y_validation), \n","                          batch_size = 16, epochs = maxepoch, verbose=0, callbacks = callbacks)"]},{"cell_type":"markdown","metadata":{"id":"k32Z0L1IYpof"},"source":["### Second pass \n","- learning rate 0.00001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTGIwWiuX4rm"},"outputs":[],"source":["if(finetune and backend != \"attentionUnet\"):\n","\n","  # For fine-tuning we need to set the tranable flag to true for the whole model\n","  model.trainable = True\n","\n","  # Recompile the model with the smaller learning rate at the optimizer (Adam(1e-5))\n","  model.compile(optimizer = Adam(1e-5), loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n","\n","  # train the model again\n","  train_history_2 = model.fit(x = X_train, y = Y_train,\n","                              validation_data=(X_validation, Y_validation),\n","                              batch_size=16,epochs=maxepoch,\n","                              initial_epoch = len(train_history.history['val_loss'])-1,\n","                              verbose=0 ,callbacks=callbacks)"]},{"cell_type":"markdown","metadata":{"id":"2k7SUCqRXWP1"},"source":["# Evaluation\n","\n","### predict the test data with the best model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFnatvpDiI2Y"},"outputs":[],"source":["# Load the best model saved by the callback module\n","from keras.models import load_model\n","if(backend != \"attentionUnet\"):\n","  best_model = load_model(model_path+name+'.h5',\n","                        custom_objects={'dice_coef_loss':dice_coef_loss,\n","                                        'dice_coef':dice_coef,})\n","else:\n","  best_model = load_model(model_path+name+'.h5',\n","                        custom_objects={'multiplication': multiplication,\n","                                        'multiplication2': multiplication2,\n","                                        'dice_coef_loss':dice_coef_loss, \n","                                        'dice_coef':dice_coef,})\n","\n","# load the test data\n","X_test = np.load(input_data+location+'/bottom_half_test_data.npy').astype(np.float32)\n","\n","# predict the test data using the loaded model\n","test_predicted= best_model.predict(X_test)\n","\n","# convert the prediction probability to true or false with threshold at 0.5\n","test_predicted_threshold = (test_predicted > 0.5).astype(np.uint8)\n","\n","# save the prediction results\n","np.save(prediction_path+name+'_predict.npy',test_predicted_threshold)\n","print('Predtion results saved: ' + prediction_path+name+'_predict.npy')"]},{"cell_type":"markdown","metadata":{"id":"H-Ev_qp1zb5Z"},"source":["## Evaluate the prediction result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCmd_SfPyz7x"},"outputs":[],"source":["pred_npy = prediction_path+name+'_predict.npy'\n","mask_npy = input_data+location+'/bottom_half_test_mask.npy'\n","label_npy = input_data+location+'/bottom_half_test_label.npy'\n","model = model_path + name + '.h5'\n","text_path = prediction_path+'prediction_results.txt'\n","\n","evaluate_prediction_result(location, pred_npy, mask_npy, label_npy, model, text_path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOsi3yaImT+M5bSwuMcT8ZR","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1pyqBCIr3oBe1pjQDjUYq0CcqQyHZh4d7","name":"Base_model_training.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
