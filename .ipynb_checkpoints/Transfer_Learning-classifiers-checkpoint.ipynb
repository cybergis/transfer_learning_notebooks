{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T17:44:07.134977Z",
     "iopub.status.busy": "2020-10-05T17:44:07.134977Z",
     "iopub.status.idle": "2020-10-05T17:44:07.238070Z",
     "shell.execute_reply": "2020-10-05T17:44:07.238070Z",
     "shell.execute_reply.started": "2020-10-05T17:44:07.134977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T18:47:04.408202Z",
     "iopub.status.busy": "2020-10-05T18:47:04.408202Z",
     "iopub.status.idle": "2020-10-05T18:47:04.441232Z",
     "shell.execute_reply": "2020-10-05T18:47:04.441232Z",
     "shell.execute_reply.started": "2020-10-05T18:47:04.408202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T19:58:50.245184Z",
     "iopub.status.busy": "2020-10-05T19:58:50.245184Z",
     "iopub.status.idle": "2020-10-05T19:58:52.955203Z",
     "shell.execute_reply": "2020-10-05T19:58:52.955203Z",
     "shell.execute_reply.started": "2020-10-05T19:58:50.245184Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('June21/model/model_augv_attention2.h5', \n",
    "                             custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                             'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "# remove the last 2 layer using pop() function\n",
    "loaded_model.layers.pop()\n",
    "loaded_model.layers.pop()\n",
    "\n",
    "for (index, layer) in enumerate(loaded_model.layers):\n",
    "    if (index > len(loaded_model.layers)-5):\n",
    "#       print(\"Here\")\n",
    "      layer.trainable = True\n",
    "    else:\n",
    "      layer.trainable = False\n",
    "\n",
    "# Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "# See model structure\n",
    "# model_without_last.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T19:58:59.026304Z",
     "iopub.status.busy": "2020-10-05T19:58:59.026304Z",
     "iopub.status.idle": "2020-10-05T19:58:59.086901Z",
     "shell.execute_reply": "2020-10-05T19:58:59.086901Z",
     "shell.execute_reply.started": "2020-10-05T19:58:59.026304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "\n",
    "# new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "drop_out = Dropout(0.7)(conv_final)\n",
    "# drop_out = SpatialDropout2D(0.7)(conv_final)\n",
    "new_out = Activation('sigmoid', name='activation_last')(drop_out)\n",
    "\n",
    "# Created new model with the newly added last two layers \n",
    "transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "# New model structure\n",
    "# transfered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **without** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 224, 224, 8)\n",
      "(400, 224, 224, 8)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Covington_data/non-overlap/'\n",
    "\n",
    "# read in training and validation data\n",
    "X_train = np.load(data_path+'train_data.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "X_Validation = np.load(data_path+'vali_data.npy')\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "# The dataset has 9 channels:\n",
    "# 0. Curvature\n",
    "# 1. Slope\n",
    "# 2. Openness\n",
    "# 3. DEM\n",
    "# 4. TPI 21\n",
    "# 5. Reflectance (LiDAR intensity)\n",
    "# 6. Geomorphon\n",
    "# 7. TPI 9\n",
    "# 8. TPI 3\n",
    "# but the model expects 8 channels\n",
    "# So we exclude TPI_9 channel from the data set\n",
    "X_train_new = X_train[:,:,:,(0,1,2,3,4,5,6,8)]\n",
    "print(X_train_new.shape)\n",
    "\n",
    "X_Validation_new = X_Validation[:,:,:,(0,1,2,3,4,5,6,8)]\n",
    "print(X_Validation_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **with** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T18:47:15.459829Z",
     "iopub.status.busy": "2020-10-05T18:47:15.459829Z",
     "iopub.status.idle": "2020-10-05T18:47:17.123845Z",
     "shell.execute_reply": "2020-10-05T18:47:17.123845Z",
     "shell.execute_reply.started": "2020-10-05T18:47:15.459829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 224, 224, 8)\n",
      "(600, 224, 224, 8)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Covington_data/include_NAIP/'\n",
    "\n",
    "# read in training and validation sample patches\n",
    "X_train_new = np.load(data_path+'train_data.npy')\n",
    "X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "print(X_train_new.shape)\n",
    "print(X_Validation_new.shape)\n",
    "\n",
    "#Read training and validation labels\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "\n",
    "#Cast both labales to float32\n",
    "Y_Validation = Y_Validation.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T19:59:02.850381Z",
     "iopub.status.busy": "2020-10-05T19:59:02.850381Z",
     "iopub.status.idle": "2020-10-05T19:59:02.862392Z",
     "shell.execute_reply": "2020-10-05T19:59:02.862392Z",
     "shell.execute_reply.started": "2020-10-05T19:59:02.850381Z"
    }
   },
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_HEIGHT = patch_size\n",
    "# Number of feature channels \n",
    "INPUT_CHANNELS = 8\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "maxepoch = 400\n",
    "# hyperparameters\n",
    "# learning_rate = 0.0000359\n",
    "learning_rate = 0.0001\n",
    "patience = 20\n",
    "aug = 'v'\n",
    "transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "        ModelCheckpoint('model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T19:59:05.077436Z",
     "iopub.status.busy": "2020-10-05T19:59:05.077436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "19/19 [==============================] - 9s 452ms/step - loss: -0.0772 - dice_coef: 0.0772 - accuracy: 0.7021 - val_loss: -0.0498 - val_dice_coef: 0.0499 - val_accuracy: 0.8929\n",
      "Epoch 2/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0773 - dice_coef: 0.0774 - accuracy: 0.7401 - val_loss: -0.0499 - val_dice_coef: 0.0499 - val_accuracy: 0.9009\n",
      "Epoch 3/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0774 - dice_coef: 0.0775 - accuracy: 0.7864 - val_loss: -0.0499 - val_dice_coef: 0.0499 - val_accuracy: 0.9024\n",
      "Epoch 4/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0774 - dice_coef: 0.0773 - accuracy: 0.8233 - val_loss: -0.0500 - val_dice_coef: 0.0500 - val_accuracy: 0.9028\n",
      "Epoch 5/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0775 - dice_coef: 0.0777 - accuracy: 0.8570 - val_loss: -0.0500 - val_dice_coef: 0.0500 - val_accuracy: 0.9029\n",
      "Epoch 6/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0775 - dice_coef: 0.0772 - accuracy: 0.8886 - val_loss: -0.0500 - val_dice_coef: 0.0500 - val_accuracy: 0.9030\n",
      "Epoch 7/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0777 - dice_coef: 0.0774 - accuracy: 0.9129 - val_loss: -0.0500 - val_dice_coef: 0.0501 - val_accuracy: 0.9034\n",
      "Epoch 8/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0777 - dice_coef: 0.0778 - accuracy: 0.9269 - val_loss: -0.0501 - val_dice_coef: 0.0501 - val_accuracy: 0.9039\n",
      "Epoch 9/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0777 - dice_coef: 0.0777 - accuracy: 0.9345 - val_loss: -0.0501 - val_dice_coef: 0.0501 - val_accuracy: 0.9046\n",
      "Epoch 10/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0778 - dice_coef: 0.0776 - accuracy: 0.9383 - val_loss: -0.0501 - val_dice_coef: 0.0501 - val_accuracy: 0.9054\n",
      "Epoch 11/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0778 - dice_coef: 0.0780 - accuracy: 0.9397 - val_loss: -0.0501 - val_dice_coef: 0.0501 - val_accuracy: 0.9062\n",
      "Epoch 12/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0779 - dice_coef: 0.0782 - accuracy: 0.9406 - val_loss: -0.0501 - val_dice_coef: 0.0502 - val_accuracy: 0.9070\n",
      "Epoch 13/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0780 - dice_coef: 0.0779 - accuracy: 0.9409 - val_loss: -0.0502 - val_dice_coef: 0.0502 - val_accuracy: 0.9078\n",
      "Epoch 14/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0780 - dice_coef: 0.0778 - accuracy: 0.9411 - val_loss: -0.0502 - val_dice_coef: 0.0502 - val_accuracy: 0.9085\n",
      "Epoch 15/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0781 - dice_coef: 0.0782 - accuracy: 0.9413 - val_loss: -0.0502 - val_dice_coef: 0.0502 - val_accuracy: 0.9092\n",
      "Epoch 16/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0781 - dice_coef: 0.0781 - accuracy: 0.9414 - val_loss: -0.0502 - val_dice_coef: 0.0503 - val_accuracy: 0.9098\n",
      "Epoch 17/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0782 - dice_coef: 0.0782 - accuracy: 0.9415 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.9104\n",
      "Epoch 18/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0782 - dice_coef: 0.0785 - accuracy: 0.9416 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.9109\n",
      "Epoch 19/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0783 - dice_coef: 0.0781 - accuracy: 0.9416 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.9113\n",
      "Epoch 20/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0784 - dice_coef: 0.0784 - accuracy: 0.9417 - val_loss: -0.0504 - val_dice_coef: 0.0504 - val_accuracy: 0.9118\n",
      "Epoch 21/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0784 - dice_coef: 0.0785 - accuracy: 0.9417 - val_loss: -0.0504 - val_dice_coef: 0.0504 - val_accuracy: 0.9121\n",
      "Epoch 22/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0784 - dice_coef: 0.0784 - accuracy: 0.9418 - val_loss: -0.0504 - val_dice_coef: 0.0504 - val_accuracy: 0.9125\n",
      "Epoch 23/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0785 - dice_coef: 0.0785 - accuracy: 0.9419 - val_loss: -0.0504 - val_dice_coef: 0.0505 - val_accuracy: 0.9128\n",
      "Epoch 24/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0786 - dice_coef: 0.0786 - accuracy: 0.9420 - val_loss: -0.0505 - val_dice_coef: 0.0505 - val_accuracy: 0.9130\n",
      "Epoch 25/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0785 - dice_coef: 0.0786 - accuracy: 0.9420 - val_loss: -0.0505 - val_dice_coef: 0.0505 - val_accuracy: 0.9133\n",
      "Epoch 26/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0786 - dice_coef: 0.0785 - accuracy: 0.9420 - val_loss: -0.0505 - val_dice_coef: 0.0505 - val_accuracy: 0.9135\n",
      "Epoch 27/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0787 - dice_coef: 0.0789 - accuracy: 0.9421 - val_loss: -0.0506 - val_dice_coef: 0.0506 - val_accuracy: 0.9137\n",
      "Epoch 28/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0787 - dice_coef: 0.0787 - accuracy: 0.9421 - val_loss: -0.0506 - val_dice_coef: 0.0506 - val_accuracy: 0.9139\n",
      "Epoch 29/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0787 - dice_coef: 0.0788 - accuracy: 0.9421 - val_loss: -0.0506 - val_dice_coef: 0.0506 - val_accuracy: 0.9140\n",
      "Epoch 30/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0788 - dice_coef: 0.0789 - accuracy: 0.9422 - val_loss: -0.0507 - val_dice_coef: 0.0507 - val_accuracy: 0.9142\n",
      "Epoch 31/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0789 - dice_coef: 0.0789 - accuracy: 0.9421 - val_loss: -0.0507 - val_dice_coef: 0.0507 - val_accuracy: 0.9143\n",
      "Epoch 32/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0789 - dice_coef: 0.0790 - accuracy: 0.9422 - val_loss: -0.0507 - val_dice_coef: 0.0507 - val_accuracy: 0.9144\n",
      "Epoch 33/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0790 - dice_coef: 0.0789 - accuracy: 0.9422 - val_loss: -0.0508 - val_dice_coef: 0.0508 - val_accuracy: 0.9145\n",
      "Epoch 34/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0790 - dice_coef: 0.0790 - accuracy: 0.9423 - val_loss: -0.0508 - val_dice_coef: 0.0508 - val_accuracy: 0.9146\n",
      "Epoch 35/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0791 - dice_coef: 0.0793 - accuracy: 0.9423 - val_loss: -0.0508 - val_dice_coef: 0.0508 - val_accuracy: 0.9147\n",
      "Epoch 36/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0790 - dice_coef: 0.0787 - accuracy: 0.9423 - val_loss: -0.0509 - val_dice_coef: 0.0509 - val_accuracy: 0.9148\n",
      "Epoch 37/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0793 - dice_coef: 0.0793 - accuracy: 0.9423 - val_loss: -0.0509 - val_dice_coef: 0.0509 - val_accuracy: 0.9148\n",
      "Epoch 38/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0792 - dice_coef: 0.0792 - accuracy: 0.9423 - val_loss: -0.0509 - val_dice_coef: 0.0509 - val_accuracy: 0.9149\n",
      "Epoch 39/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0794 - dice_coef: 0.0793 - accuracy: 0.9424 - val_loss: -0.0510 - val_dice_coef: 0.0510 - val_accuracy: 0.9150\n",
      "Epoch 40/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0794 - dice_coef: 0.0793 - accuracy: 0.9424 - val_loss: -0.0510 - val_dice_coef: 0.0510 - val_accuracy: 0.9150\n",
      "Epoch 41/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0794 - dice_coef: 0.0791 - accuracy: 0.9424 - val_loss: -0.0510 - val_dice_coef: 0.0510 - val_accuracy: 0.9151\n",
      "Epoch 42/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0795 - dice_coef: 0.0795 - accuracy: 0.9424 - val_loss: -0.0511 - val_dice_coef: 0.0511 - val_accuracy: 0.9151\n",
      "Epoch 43/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0796 - dice_coef: 0.0795 - accuracy: 0.9424 - val_loss: -0.0511 - val_dice_coef: 0.0511 - val_accuracy: 0.9152\n",
      "Epoch 44/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0795 - dice_coef: 0.0789 - accuracy: 0.9425 - val_loss: -0.0511 - val_dice_coef: 0.0512 - val_accuracy: 0.9152\n",
      "Epoch 45/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0797 - dice_coef: 0.0797 - accuracy: 0.9424 - val_loss: -0.0512 - val_dice_coef: 0.0512 - val_accuracy: 0.9152\n",
      "Epoch 46/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0798 - dice_coef: 0.0797 - accuracy: 0.9425 - val_loss: -0.0512 - val_dice_coef: 0.0512 - val_accuracy: 0.9153\n",
      "Epoch 47/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0798 - dice_coef: 0.0796 - accuracy: 0.9424 - val_loss: -0.0512 - val_dice_coef: 0.0513 - val_accuracy: 0.9153\n",
      "Epoch 48/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0798 - dice_coef: 0.0797 - accuracy: 0.9425 - val_loss: -0.0513 - val_dice_coef: 0.0513 - val_accuracy: 0.9153\n",
      "Epoch 49/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0798 - dice_coef: 0.0798 - accuracy: 0.9424 - val_loss: -0.0513 - val_dice_coef: 0.0513 - val_accuracy: 0.9154\n",
      "Epoch 50/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0800 - dice_coef: 0.0798 - accuracy: 0.9425 - val_loss: -0.0514 - val_dice_coef: 0.0514 - val_accuracy: 0.9154\n",
      "Epoch 51/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0801 - dice_coef: 0.0801 - accuracy: 0.9425 - val_loss: -0.0514 - val_dice_coef: 0.0514 - val_accuracy: 0.9155\n",
      "Epoch 52/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0801 - dice_coef: 0.0799 - accuracy: 0.9425 - val_loss: -0.0514 - val_dice_coef: 0.0514 - val_accuracy: 0.9155\n",
      "Epoch 53/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0802 - dice_coef: 0.0799 - accuracy: 0.9425 - val_loss: -0.0515 - val_dice_coef: 0.0515 - val_accuracy: 0.9155\n",
      "Epoch 54/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0802 - dice_coef: 0.0801 - accuracy: 0.9426 - val_loss: -0.0515 - val_dice_coef: 0.0515 - val_accuracy: 0.9155\n",
      "Epoch 55/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0803 - dice_coef: 0.0806 - accuracy: 0.9425 - val_loss: -0.0515 - val_dice_coef: 0.0515 - val_accuracy: 0.9156\n",
      "Epoch 56/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0803 - dice_coef: 0.0804 - accuracy: 0.9425 - val_loss: -0.0516 - val_dice_coef: 0.0516 - val_accuracy: 0.9156\n",
      "Epoch 57/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0804 - dice_coef: 0.0804 - accuracy: 0.9425 - val_loss: -0.0516 - val_dice_coef: 0.0516 - val_accuracy: 0.9156\n",
      "Epoch 58/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0805 - dice_coef: 0.0803 - accuracy: 0.9425 - val_loss: -0.0516 - val_dice_coef: 0.0516 - val_accuracy: 0.9156\n",
      "Epoch 59/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0804 - dice_coef: 0.0804 - accuracy: 0.9425 - val_loss: -0.0517 - val_dice_coef: 0.0517 - val_accuracy: 0.9156\n",
      "Epoch 60/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0806 - dice_coef: 0.0806 - accuracy: 0.9425 - val_loss: -0.0517 - val_dice_coef: 0.0517 - val_accuracy: 0.9156\n",
      "Epoch 61/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0807 - dice_coef: 0.0804 - accuracy: 0.9425 - val_loss: -0.0517 - val_dice_coef: 0.0517 - val_accuracy: 0.9157\n",
      "Epoch 62/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0806 - dice_coef: 0.0805 - accuracy: 0.9425 - val_loss: -0.0518 - val_dice_coef: 0.0518 - val_accuracy: 0.9157\n",
      "Epoch 63/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0807 - dice_coef: 0.0805 - accuracy: 0.9425 - val_loss: -0.0518 - val_dice_coef: 0.0518 - val_accuracy: 0.9157\n",
      "Epoch 64/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0808 - dice_coef: 0.0807 - accuracy: 0.9425 - val_loss: -0.0518 - val_dice_coef: 0.0519 - val_accuracy: 0.9157\n",
      "Epoch 65/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0808 - dice_coef: 0.0809 - accuracy: 0.9425 - val_loss: -0.0519 - val_dice_coef: 0.0519 - val_accuracy: 0.9157\n",
      "Epoch 66/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0809 - dice_coef: 0.0808 - accuracy: 0.9426 - val_loss: -0.0519 - val_dice_coef: 0.0519 - val_accuracy: 0.9157\n",
      "Epoch 67/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0809 - dice_coef: 0.0807 - accuracy: 0.9426 - val_loss: -0.0519 - val_dice_coef: 0.0520 - val_accuracy: 0.9158\n",
      "Epoch 68/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0810 - dice_coef: 0.0812 - accuracy: 0.9426 - val_loss: -0.0520 - val_dice_coef: 0.0520 - val_accuracy: 0.9158\n",
      "Epoch 69/400\n",
      "19/19 [==============================] - 8s 401ms/step - loss: -0.0809 - dice_coef: 0.0805 - accuracy: 0.9426 - val_loss: -0.0520 - val_dice_coef: 0.0520 - val_accuracy: 0.9158\n",
      "Epoch 70/400\n",
      "19/19 [==============================] - 8s 408ms/step - loss: -0.0812 - dice_coef: 0.0811 - accuracy: 0.9426 - val_loss: -0.0521 - val_dice_coef: 0.0521 - val_accuracy: 0.9158\n",
      "Epoch 71/400\n",
      "19/19 [==============================] - 8s 407ms/step - loss: -0.0812 - dice_coef: 0.0813 - accuracy: 0.9426 - val_loss: -0.0521 - val_dice_coef: 0.0521 - val_accuracy: 0.9158\n",
      "Epoch 72/400\n",
      "19/19 [==============================] - 8s 409ms/step - loss: -0.0812 - dice_coef: 0.0810 - accuracy: 0.9426 - val_loss: -0.0521 - val_dice_coef: 0.0521 - val_accuracy: 0.9158\n",
      "Epoch 73/400\n",
      "19/19 [==============================] - 7s 393ms/step - loss: -0.0812 - dice_coef: 0.0810 - accuracy: 0.9425 - val_loss: -0.0522 - val_dice_coef: 0.0522 - val_accuracy: 0.9158\n",
      "Epoch 74/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0813 - dice_coef: 0.0811 - accuracy: 0.9426 - val_loss: -0.0522 - val_dice_coef: 0.0522 - val_accuracy: 0.9158\n",
      "Epoch 75/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0814 - dice_coef: 0.0815 - accuracy: 0.9426 - val_loss: -0.0522 - val_dice_coef: 0.0522 - val_accuracy: 0.9159\n",
      "Epoch 76/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0814 - dice_coef: 0.0813 - accuracy: 0.9426 - val_loss: -0.0523 - val_dice_coef: 0.0523 - val_accuracy: 0.9159\n",
      "Epoch 77/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0814 - dice_coef: 0.0818 - accuracy: 0.9426 - val_loss: -0.0523 - val_dice_coef: 0.0523 - val_accuracy: 0.9159\n",
      "Epoch 78/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0815 - dice_coef: 0.0816 - accuracy: 0.9426 - val_loss: -0.0523 - val_dice_coef: 0.0523 - val_accuracy: 0.9159\n",
      "Epoch 79/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0816 - dice_coef: 0.0813 - accuracy: 0.9426 - val_loss: -0.0524 - val_dice_coef: 0.0524 - val_accuracy: 0.9159\n",
      "Epoch 80/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0817 - dice_coef: 0.0815 - accuracy: 0.9426 - val_loss: -0.0524 - val_dice_coef: 0.0524 - val_accuracy: 0.9159\n",
      "Epoch 81/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0817 - dice_coef: 0.0820 - accuracy: 0.9426 - val_loss: -0.0524 - val_dice_coef: 0.0525 - val_accuracy: 0.9159\n",
      "Epoch 82/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0817 - dice_coef: 0.0816 - accuracy: 0.9426 - val_loss: -0.0525 - val_dice_coef: 0.0525 - val_accuracy: 0.9159\n",
      "Epoch 83/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0818 - dice_coef: 0.0819 - accuracy: 0.9426 - val_loss: -0.0525 - val_dice_coef: 0.0525 - val_accuracy: 0.9159\n",
      "Epoch 84/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0820 - dice_coef: 0.0820 - accuracy: 0.9426 - val_loss: -0.0526 - val_dice_coef: 0.0526 - val_accuracy: 0.9160\n",
      "Epoch 85/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0819 - dice_coef: 0.0818 - accuracy: 0.9426 - val_loss: -0.0526 - val_dice_coef: 0.0526 - val_accuracy: 0.9160\n",
      "Epoch 86/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0819 - dice_coef: 0.0825 - accuracy: 0.9426 - val_loss: -0.0526 - val_dice_coef: 0.0526 - val_accuracy: 0.9160\n",
      "Epoch 87/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0820 - dice_coef: 0.0820 - accuracy: 0.9426 - val_loss: -0.0527 - val_dice_coef: 0.0527 - val_accuracy: 0.9160\n",
      "Epoch 88/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0820 - dice_coef: 0.0823 - accuracy: 0.9426 - val_loss: -0.0527 - val_dice_coef: 0.0527 - val_accuracy: 0.9160\n",
      "Epoch 89/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0822 - dice_coef: 0.0822 - accuracy: 0.9426 - val_loss: -0.0527 - val_dice_coef: 0.0527 - val_accuracy: 0.9160\n",
      "Epoch 90/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0822 - dice_coef: 0.0818 - accuracy: 0.9427 - val_loss: -0.0528 - val_dice_coef: 0.0528 - val_accuracy: 0.9160\n",
      "Epoch 91/400\n",
      "19/19 [==============================] - 7s 388ms/step - loss: -0.0822 - dice_coef: 0.0824 - accuracy: 0.9426 - val_loss: -0.0528 - val_dice_coef: 0.0528 - val_accuracy: 0.9161\n",
      "Epoch 92/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0823 - dice_coef: 0.0823 - accuracy: 0.9426 - val_loss: -0.0528 - val_dice_coef: 0.0528 - val_accuracy: 0.9161\n",
      "Epoch 93/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0823 - dice_coef: 0.0826 - accuracy: 0.9426 - val_loss: -0.0529 - val_dice_coef: 0.0529 - val_accuracy: 0.9161\n",
      "Epoch 94/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0825 - dice_coef: 0.0824 - accuracy: 0.9427 - val_loss: -0.0529 - val_dice_coef: 0.0529 - val_accuracy: 0.9161\n",
      "Epoch 95/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0824 - dice_coef: 0.0823 - accuracy: 0.9426 - val_loss: -0.0529 - val_dice_coef: 0.0530 - val_accuracy: 0.9161\n",
      "Epoch 96/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0826 - dice_coef: 0.0824 - accuracy: 0.9426 - val_loss: -0.0530 - val_dice_coef: 0.0530 - val_accuracy: 0.9161\n",
      "Epoch 97/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0824 - dice_coef: 0.0826 - accuracy: 0.9426 - val_loss: -0.0530 - val_dice_coef: 0.0530 - val_accuracy: 0.9161\n",
      "Epoch 98/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0827 - dice_coef: 0.0827 - accuracy: 0.9427 - val_loss: -0.0531 - val_dice_coef: 0.0531 - val_accuracy: 0.9161\n",
      "Epoch 99/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0827 - dice_coef: 0.0828 - accuracy: 0.9426 - val_loss: -0.0531 - val_dice_coef: 0.0531 - val_accuracy: 0.9161\n",
      "Epoch 100/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0828 - dice_coef: 0.0827 - accuracy: 0.9426 - val_loss: -0.0531 - val_dice_coef: 0.0531 - val_accuracy: 0.9161\n",
      "Epoch 101/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0827 - dice_coef: 0.0827 - accuracy: 0.9426 - val_loss: -0.0532 - val_dice_coef: 0.0532 - val_accuracy: 0.9161\n",
      "Epoch 102/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0829 - dice_coef: 0.0828 - accuracy: 0.9426 - val_loss: -0.0532 - val_dice_coef: 0.0532 - val_accuracy: 0.9161\n",
      "Epoch 103/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0829 - dice_coef: 0.0829 - accuracy: 0.9426 - val_loss: -0.0532 - val_dice_coef: 0.0532 - val_accuracy: 0.9162\n",
      "Epoch 104/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0829 - dice_coef: 0.0832 - accuracy: 0.9426 - val_loss: -0.0533 - val_dice_coef: 0.0533 - val_accuracy: 0.9162\n",
      "Epoch 105/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0831 - dice_coef: 0.0829 - accuracy: 0.9427 - val_loss: -0.0533 - val_dice_coef: 0.0533 - val_accuracy: 0.9162\n",
      "Epoch 106/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0830 - dice_coef: 0.0833 - accuracy: 0.9426 - val_loss: -0.0533 - val_dice_coef: 0.0533 - val_accuracy: 0.9162\n",
      "Epoch 107/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0831 - dice_coef: 0.0834 - accuracy: 0.9426 - val_loss: -0.0534 - val_dice_coef: 0.0534 - val_accuracy: 0.9162\n",
      "Epoch 108/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0832 - dice_coef: 0.0833 - accuracy: 0.9427 - val_loss: -0.0534 - val_dice_coef: 0.0534 - val_accuracy: 0.9162\n",
      "Epoch 109/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0832 - dice_coef: 0.0836 - accuracy: 0.9427 - val_loss: -0.0535 - val_dice_coef: 0.0535 - val_accuracy: 0.9162\n",
      "Epoch 110/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0831 - dice_coef: 0.0830 - accuracy: 0.9427 - val_loss: -0.0535 - val_dice_coef: 0.0535 - val_accuracy: 0.9163\n",
      "Epoch 111/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0833 - dice_coef: 0.0832 - accuracy: 0.9427 - val_loss: -0.0535 - val_dice_coef: 0.0535 - val_accuracy: 0.9163\n",
      "Epoch 112/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0834 - dice_coef: 0.0835 - accuracy: 0.9427 - val_loss: -0.0536 - val_dice_coef: 0.0536 - val_accuracy: 0.9163\n",
      "Epoch 113/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0832 - dice_coef: 0.0831 - accuracy: 0.9426 - val_loss: -0.0536 - val_dice_coef: 0.0536 - val_accuracy: 0.9163\n",
      "Epoch 114/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0835 - dice_coef: 0.0833 - accuracy: 0.9426 - val_loss: -0.0536 - val_dice_coef: 0.0536 - val_accuracy: 0.9163\n",
      "Epoch 115/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0836 - dice_coef: 0.0835 - accuracy: 0.9426 - val_loss: -0.0537 - val_dice_coef: 0.0537 - val_accuracy: 0.9163\n",
      "Epoch 116/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0836 - dice_coef: 0.0837 - accuracy: 0.9427 - val_loss: -0.0537 - val_dice_coef: 0.0537 - val_accuracy: 0.9163\n",
      "Epoch 117/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0836 - dice_coef: 0.0836 - accuracy: 0.9426 - val_loss: -0.0537 - val_dice_coef: 0.0537 - val_accuracy: 0.9163\n",
      "Epoch 118/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0836 - dice_coef: 0.0833 - accuracy: 0.9427 - val_loss: -0.0538 - val_dice_coef: 0.0538 - val_accuracy: 0.9163\n",
      "Epoch 119/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0836 - dice_coef: 0.0838 - accuracy: 0.9427 - val_loss: -0.0538 - val_dice_coef: 0.0538 - val_accuracy: 0.9163\n",
      "Epoch 120/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0837 - dice_coef: 0.0835 - accuracy: 0.9427 - val_loss: -0.0539 - val_dice_coef: 0.0539 - val_accuracy: 0.9164\n",
      "Epoch 121/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0839 - dice_coef: 0.0839 - accuracy: 0.9427 - val_loss: -0.0539 - val_dice_coef: 0.0539 - val_accuracy: 0.9164\n",
      "Epoch 122/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0839 - dice_coef: 0.0839 - accuracy: 0.9428 - val_loss: -0.0539 - val_dice_coef: 0.0539 - val_accuracy: 0.9164\n",
      "Epoch 123/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0839 - dice_coef: 0.0841 - accuracy: 0.9428 - val_loss: -0.0540 - val_dice_coef: 0.0540 - val_accuracy: 0.9164\n",
      "Epoch 124/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0840 - dice_coef: 0.0843 - accuracy: 0.9427 - val_loss: -0.0540 - val_dice_coef: 0.0540 - val_accuracy: 0.9164\n",
      "Epoch 125/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0840 - dice_coef: 0.0840 - accuracy: 0.9427 - val_loss: -0.0540 - val_dice_coef: 0.0540 - val_accuracy: 0.9164\n",
      "Epoch 126/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0841 - dice_coef: 0.0842 - accuracy: 0.9427 - val_loss: -0.0541 - val_dice_coef: 0.0541 - val_accuracy: 0.9164\n",
      "Epoch 127/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0840 - dice_coef: 0.0838 - accuracy: 0.9427 - val_loss: -0.0541 - val_dice_coef: 0.0541 - val_accuracy: 0.9164\n",
      "Epoch 128/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0842 - dice_coef: 0.0844 - accuracy: 0.9427 - val_loss: -0.0541 - val_dice_coef: 0.0541 - val_accuracy: 0.9164\n",
      "Epoch 129/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0843 - dice_coef: 0.0844 - accuracy: 0.9428 - val_loss: -0.0542 - val_dice_coef: 0.0542 - val_accuracy: 0.9165\n",
      "Epoch 130/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0843 - dice_coef: 0.0845 - accuracy: 0.9427 - val_loss: -0.0542 - val_dice_coef: 0.0542 - val_accuracy: 0.9165\n",
      "Epoch 131/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0844 - dice_coef: 0.0844 - accuracy: 0.9428 - val_loss: -0.0543 - val_dice_coef: 0.0543 - val_accuracy: 0.9165\n",
      "Epoch 132/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0844 - dice_coef: 0.0843 - accuracy: 0.9427 - val_loss: -0.0543 - val_dice_coef: 0.0543 - val_accuracy: 0.9165\n",
      "Epoch 133/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0845 - dice_coef: 0.0842 - accuracy: 0.9427 - val_loss: -0.0543 - val_dice_coef: 0.0543 - val_accuracy: 0.9165\n",
      "Epoch 134/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0845 - dice_coef: 0.0842 - accuracy: 0.9427 - val_loss: -0.0544 - val_dice_coef: 0.0544 - val_accuracy: 0.9165\n",
      "Epoch 135/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0846 - dice_coef: 0.0846 - accuracy: 0.9427 - val_loss: -0.0544 - val_dice_coef: 0.0544 - val_accuracy: 0.9165\n",
      "Epoch 136/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0846 - dice_coef: 0.0850 - accuracy: 0.9427 - val_loss: -0.0544 - val_dice_coef: 0.0544 - val_accuracy: 0.9165\n",
      "Epoch 137/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0847 - dice_coef: 0.0849 - accuracy: 0.9427 - val_loss: -0.0545 - val_dice_coef: 0.0545 - val_accuracy: 0.9165\n",
      "Epoch 138/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0847 - dice_coef: 0.0850 - accuracy: 0.9427 - val_loss: -0.0545 - val_dice_coef: 0.0545 - val_accuracy: 0.9166\n",
      "Epoch 139/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0849 - dice_coef: 0.0851 - accuracy: 0.9428 - val_loss: -0.0546 - val_dice_coef: 0.0546 - val_accuracy: 0.9166\n",
      "Epoch 140/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0848 - dice_coef: 0.0846 - accuracy: 0.9428 - val_loss: -0.0546 - val_dice_coef: 0.0546 - val_accuracy: 0.9166\n",
      "Epoch 141/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0848 - dice_coef: 0.0844 - accuracy: 0.9427 - val_loss: -0.0546 - val_dice_coef: 0.0546 - val_accuracy: 0.9166\n",
      "Epoch 142/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0849 - dice_coef: 0.0847 - accuracy: 0.9427 - val_loss: -0.0547 - val_dice_coef: 0.0547 - val_accuracy: 0.9166\n",
      "Epoch 143/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0849 - dice_coef: 0.0847 - accuracy: 0.9428 - val_loss: -0.0547 - val_dice_coef: 0.0547 - val_accuracy: 0.9166\n",
      "Epoch 144/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0849 - dice_coef: 0.0847 - accuracy: 0.9427 - val_loss: -0.0547 - val_dice_coef: 0.0547 - val_accuracy: 0.9166\n",
      "Epoch 145/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0849 - dice_coef: 0.0847 - accuracy: 0.9428 - val_loss: -0.0548 - val_dice_coef: 0.0548 - val_accuracy: 0.9166\n",
      "Epoch 146/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0851 - dice_coef: 0.0849 - accuracy: 0.9428 - val_loss: -0.0548 - val_dice_coef: 0.0548 - val_accuracy: 0.9166\n",
      "Epoch 147/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0851 - dice_coef: 0.0853 - accuracy: 0.9428 - val_loss: -0.0548 - val_dice_coef: 0.0548 - val_accuracy: 0.9167\n",
      "Epoch 148/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0852 - dice_coef: 0.0851 - accuracy: 0.9428 - val_loss: -0.0549 - val_dice_coef: 0.0549 - val_accuracy: 0.9167\n",
      "Epoch 149/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0852 - dice_coef: 0.0855 - accuracy: 0.9427 - val_loss: -0.0549 - val_dice_coef: 0.0549 - val_accuracy: 0.9167\n",
      "Epoch 150/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0853 - dice_coef: 0.0852 - accuracy: 0.9428 - val_loss: -0.0550 - val_dice_coef: 0.0550 - val_accuracy: 0.9167\n",
      "Epoch 151/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0852 - dice_coef: 0.0854 - accuracy: 0.9428 - val_loss: -0.0550 - val_dice_coef: 0.0550 - val_accuracy: 0.9167\n",
      "Epoch 152/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0854 - dice_coef: 0.0854 - accuracy: 0.9428 - val_loss: -0.0550 - val_dice_coef: 0.0550 - val_accuracy: 0.9167\n",
      "Epoch 153/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0855 - dice_coef: 0.0856 - accuracy: 0.9428 - val_loss: -0.0551 - val_dice_coef: 0.0551 - val_accuracy: 0.9168\n",
      "Epoch 154/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0855 - dice_coef: 0.0854 - accuracy: 0.9428 - val_loss: -0.0551 - val_dice_coef: 0.0551 - val_accuracy: 0.9168\n",
      "Epoch 155/400\n",
      "19/19 [==============================] - 7s 388ms/step - loss: -0.0855 - dice_coef: 0.0853 - accuracy: 0.9428 - val_loss: -0.0551 - val_dice_coef: 0.0551 - val_accuracy: 0.9168\n",
      "Epoch 156/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0856 - dice_coef: 0.0860 - accuracy: 0.9428 - val_loss: -0.0552 - val_dice_coef: 0.0552 - val_accuracy: 0.9168\n",
      "Epoch 157/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0857 - dice_coef: 0.0857 - accuracy: 0.9428 - val_loss: -0.0552 - val_dice_coef: 0.0552 - val_accuracy: 0.9168\n",
      "Epoch 158/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0856 - dice_coef: 0.0858 - accuracy: 0.9428 - val_loss: -0.0553 - val_dice_coef: 0.0553 - val_accuracy: 0.9168\n",
      "Epoch 159/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0857 - dice_coef: 0.0858 - accuracy: 0.9428 - val_loss: -0.0553 - val_dice_coef: 0.0553 - val_accuracy: 0.9169\n",
      "Epoch 160/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0858 - dice_coef: 0.0859 - accuracy: 0.9429 - val_loss: -0.0553 - val_dice_coef: 0.0553 - val_accuracy: 0.9169\n",
      "Epoch 161/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0858 - dice_coef: 0.0858 - accuracy: 0.9428 - val_loss: -0.0554 - val_dice_coef: 0.0554 - val_accuracy: 0.9169\n",
      "Epoch 162/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0858 - dice_coef: 0.0855 - accuracy: 0.9429 - val_loss: -0.0554 - val_dice_coef: 0.0554 - val_accuracy: 0.9169\n",
      "Epoch 163/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0859 - dice_coef: 0.0859 - accuracy: 0.9429 - val_loss: -0.0554 - val_dice_coef: 0.0554 - val_accuracy: 0.9169\n",
      "Epoch 164/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0860 - dice_coef: 0.0862 - accuracy: 0.9429 - val_loss: -0.0555 - val_dice_coef: 0.0555 - val_accuracy: 0.9169\n",
      "Epoch 165/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0860 - dice_coef: 0.0863 - accuracy: 0.9428 - val_loss: -0.0555 - val_dice_coef: 0.0555 - val_accuracy: 0.9170\n",
      "Epoch 166/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0860 - dice_coef: 0.0858 - accuracy: 0.9429 - val_loss: -0.0556 - val_dice_coef: 0.0556 - val_accuracy: 0.9170\n",
      "Epoch 167/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0861 - dice_coef: 0.0858 - accuracy: 0.9428 - val_loss: -0.0556 - val_dice_coef: 0.0556 - val_accuracy: 0.9170\n",
      "Epoch 168/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0862 - dice_coef: 0.0862 - accuracy: 0.9428 - val_loss: -0.0556 - val_dice_coef: 0.0556 - val_accuracy: 0.9170\n",
      "Epoch 169/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0862 - dice_coef: 0.0860 - accuracy: 0.9430 - val_loss: -0.0557 - val_dice_coef: 0.0557 - val_accuracy: 0.9170\n",
      "Epoch 170/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0862 - dice_coef: 0.0858 - accuracy: 0.9429 - val_loss: -0.0557 - val_dice_coef: 0.0557 - val_accuracy: 0.9170\n",
      "Epoch 171/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0864 - dice_coef: 0.0865 - accuracy: 0.9429 - val_loss: -0.0557 - val_dice_coef: 0.0557 - val_accuracy: 0.9170\n",
      "Epoch 172/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0864 - dice_coef: 0.0864 - accuracy: 0.9429 - val_loss: -0.0558 - val_dice_coef: 0.0558 - val_accuracy: 0.9170\n",
      "Epoch 173/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0863 - dice_coef: 0.0862 - accuracy: 0.9429 - val_loss: -0.0558 - val_dice_coef: 0.0558 - val_accuracy: 0.9170\n",
      "Epoch 174/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0864 - dice_coef: 0.0863 - accuracy: 0.9429 - val_loss: -0.0559 - val_dice_coef: 0.0559 - val_accuracy: 0.9171\n",
      "Epoch 175/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0866 - dice_coef: 0.0865 - accuracy: 0.9429 - val_loss: -0.0559 - val_dice_coef: 0.0559 - val_accuracy: 0.9171\n",
      "Epoch 176/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0865 - dice_coef: 0.0865 - accuracy: 0.9429 - val_loss: -0.0559 - val_dice_coef: 0.0559 - val_accuracy: 0.9171\n",
      "Epoch 177/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0866 - dice_coef: 0.0866 - accuracy: 0.9429 - val_loss: -0.0560 - val_dice_coef: 0.0560 - val_accuracy: 0.9171\n",
      "Epoch 178/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0867 - dice_coef: 0.0866 - accuracy: 0.9429 - val_loss: -0.0560 - val_dice_coef: 0.0560 - val_accuracy: 0.9171\n",
      "Epoch 179/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0866 - dice_coef: 0.0869 - accuracy: 0.9429 - val_loss: -0.0561 - val_dice_coef: 0.0560 - val_accuracy: 0.9171\n",
      "Epoch 180/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0867 - dice_coef: 0.0869 - accuracy: 0.9429 - val_loss: -0.0561 - val_dice_coef: 0.0561 - val_accuracy: 0.9172\n",
      "Epoch 181/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0869 - dice_coef: 0.0870 - accuracy: 0.9429 - val_loss: -0.0561 - val_dice_coef: 0.0561 - val_accuracy: 0.9172\n",
      "Epoch 182/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0868 - dice_coef: 0.0871 - accuracy: 0.9429 - val_loss: -0.0562 - val_dice_coef: 0.0562 - val_accuracy: 0.9172\n",
      "Epoch 183/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0866 - dice_coef: 0.0868 - accuracy: 0.9429 - val_loss: -0.0562 - val_dice_coef: 0.0562 - val_accuracy: 0.9172\n",
      "Epoch 184/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0868 - dice_coef: 0.0865 - accuracy: 0.9429 - val_loss: -0.0562 - val_dice_coef: 0.0562 - val_accuracy: 0.9172\n",
      "Epoch 185/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0869 - dice_coef: 0.0873 - accuracy: 0.9429 - val_loss: -0.0563 - val_dice_coef: 0.0563 - val_accuracy: 0.9172\n",
      "Epoch 186/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0870 - dice_coef: 0.0869 - accuracy: 0.9429 - val_loss: -0.0563 - val_dice_coef: 0.0563 - val_accuracy: 0.9173\n",
      "Epoch 187/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0871 - dice_coef: 0.0871 - accuracy: 0.9430 - val_loss: -0.0564 - val_dice_coef: 0.0564 - val_accuracy: 0.9173\n",
      "Epoch 188/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0870 - dice_coef: 0.0868 - accuracy: 0.9430 - val_loss: -0.0564 - val_dice_coef: 0.0564 - val_accuracy: 0.9173\n",
      "Epoch 189/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0869 - dice_coef: 0.0868 - accuracy: 0.9430 - val_loss: -0.0564 - val_dice_coef: 0.0564 - val_accuracy: 0.9173\n",
      "Epoch 190/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0871 - dice_coef: 0.0874 - accuracy: 0.9430 - val_loss: -0.0565 - val_dice_coef: 0.0565 - val_accuracy: 0.9173\n",
      "Epoch 191/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0872 - dice_coef: 0.0870 - accuracy: 0.9430 - val_loss: -0.0565 - val_dice_coef: 0.0565 - val_accuracy: 0.9173\n",
      "Epoch 192/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0872 - dice_coef: 0.0874 - accuracy: 0.9430 - val_loss: -0.0565 - val_dice_coef: 0.0565 - val_accuracy: 0.9174\n",
      "Epoch 193/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0873 - dice_coef: 0.0872 - accuracy: 0.9430 - val_loss: -0.0566 - val_dice_coef: 0.0566 - val_accuracy: 0.9174\n",
      "Epoch 194/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0873 - dice_coef: 0.0876 - accuracy: 0.9430 - val_loss: -0.0566 - val_dice_coef: 0.0566 - val_accuracy: 0.9174\n",
      "Epoch 195/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0872 - dice_coef: 0.0871 - accuracy: 0.9430 - val_loss: -0.0567 - val_dice_coef: 0.0567 - val_accuracy: 0.9174\n",
      "Epoch 196/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0875 - dice_coef: 0.0873 - accuracy: 0.9430 - val_loss: -0.0567 - val_dice_coef: 0.0567 - val_accuracy: 0.9174\n",
      "Epoch 197/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0876 - dice_coef: 0.0875 - accuracy: 0.9430 - val_loss: -0.0567 - val_dice_coef: 0.0567 - val_accuracy: 0.9174\n",
      "Epoch 198/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0874 - dice_coef: 0.0868 - accuracy: 0.9430 - val_loss: -0.0568 - val_dice_coef: 0.0568 - val_accuracy: 0.9174\n",
      "Epoch 199/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0875 - dice_coef: 0.0873 - accuracy: 0.9430 - val_loss: -0.0568 - val_dice_coef: 0.0568 - val_accuracy: 0.9174\n",
      "Epoch 200/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0876 - dice_coef: 0.0877 - accuracy: 0.9430 - val_loss: -0.0569 - val_dice_coef: 0.0569 - val_accuracy: 0.9175\n",
      "Epoch 201/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0877 - dice_coef: 0.0875 - accuracy: 0.9430 - val_loss: -0.0569 - val_dice_coef: 0.0569 - val_accuracy: 0.9175\n",
      "Epoch 202/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0876 - dice_coef: 0.0876 - accuracy: 0.9430 - val_loss: -0.0569 - val_dice_coef: 0.0569 - val_accuracy: 0.9175\n",
      "Epoch 203/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0876 - dice_coef: 0.0877 - accuracy: 0.9430 - val_loss: -0.0570 - val_dice_coef: 0.0570 - val_accuracy: 0.9175\n",
      "Epoch 204/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0878 - dice_coef: 0.0877 - accuracy: 0.9430 - val_loss: -0.0570 - val_dice_coef: 0.0570 - val_accuracy: 0.9175\n",
      "Epoch 205/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0877 - dice_coef: 0.0878 - accuracy: 0.9431 - val_loss: -0.0571 - val_dice_coef: 0.0570 - val_accuracy: 0.9175\n",
      "Epoch 206/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0879 - dice_coef: 0.0881 - accuracy: 0.9430 - val_loss: -0.0571 - val_dice_coef: 0.0571 - val_accuracy: 0.9176\n",
      "Epoch 207/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0879 - dice_coef: 0.0878 - accuracy: 0.9430 - val_loss: -0.0571 - val_dice_coef: 0.0571 - val_accuracy: 0.9176\n",
      "Epoch 208/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0879 - dice_coef: 0.0877 - accuracy: 0.9431 - val_loss: -0.0572 - val_dice_coef: 0.0572 - val_accuracy: 0.9176\n",
      "Epoch 209/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0881 - dice_coef: 0.0879 - accuracy: 0.9431 - val_loss: -0.0572 - val_dice_coef: 0.0572 - val_accuracy: 0.9176\n",
      "Epoch 210/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0880 - dice_coef: 0.0875 - accuracy: 0.9431 - val_loss: -0.0572 - val_dice_coef: 0.0572 - val_accuracy: 0.9176\n",
      "Epoch 211/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0880 - dice_coef: 0.0880 - accuracy: 0.9431 - val_loss: -0.0573 - val_dice_coef: 0.0573 - val_accuracy: 0.9177\n",
      "Epoch 212/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0882 - dice_coef: 0.0880 - accuracy: 0.9431 - val_loss: -0.0573 - val_dice_coef: 0.0573 - val_accuracy: 0.9177\n",
      "Epoch 213/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0882 - dice_coef: 0.0883 - accuracy: 0.9431 - val_loss: -0.0574 - val_dice_coef: 0.0574 - val_accuracy: 0.9177\n",
      "Epoch 214/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0881 - dice_coef: 0.0881 - accuracy: 0.9431 - val_loss: -0.0574 - val_dice_coef: 0.0574 - val_accuracy: 0.9177\n",
      "Epoch 215/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0883 - dice_coef: 0.0883 - accuracy: 0.9430 - val_loss: -0.0574 - val_dice_coef: 0.0574 - val_accuracy: 0.9177\n",
      "Epoch 216/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0882 - dice_coef: 0.0881 - accuracy: 0.9431 - val_loss: -0.0575 - val_dice_coef: 0.0575 - val_accuracy: 0.9177\n",
      "Epoch 217/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0883 - dice_coef: 0.0884 - accuracy: 0.9430 - val_loss: -0.0575 - val_dice_coef: 0.0575 - val_accuracy: 0.9178\n",
      "Epoch 218/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0884 - dice_coef: 0.0885 - accuracy: 0.9430 - val_loss: -0.0576 - val_dice_coef: 0.0576 - val_accuracy: 0.9178\n",
      "Epoch 219/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0883 - dice_coef: 0.0883 - accuracy: 0.9431 - val_loss: -0.0576 - val_dice_coef: 0.0576 - val_accuracy: 0.9178\n",
      "Epoch 220/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0885 - dice_coef: 0.0887 - accuracy: 0.9432 - val_loss: -0.0576 - val_dice_coef: 0.0576 - val_accuracy: 0.9178\n",
      "Epoch 221/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0884 - dice_coef: 0.0883 - accuracy: 0.9431 - val_loss: -0.0577 - val_dice_coef: 0.0577 - val_accuracy: 0.9178\n",
      "Epoch 222/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0884 - dice_coef: 0.0882 - accuracy: 0.9432 - val_loss: -0.0577 - val_dice_coef: 0.0577 - val_accuracy: 0.9178\n",
      "Epoch 223/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0886 - dice_coef: 0.0886 - accuracy: 0.9431 - val_loss: -0.0578 - val_dice_coef: 0.0577 - val_accuracy: 0.9179\n",
      "Epoch 224/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0886 - dice_coef: 0.0887 - accuracy: 0.9432 - val_loss: -0.0578 - val_dice_coef: 0.0578 - val_accuracy: 0.9179\n",
      "Epoch 225/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0887 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0578 - val_dice_coef: 0.0578 - val_accuracy: 0.9179\n",
      "Epoch 226/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0886 - dice_coef: 0.0885 - accuracy: 0.9431 - val_loss: -0.0579 - val_dice_coef: 0.0579 - val_accuracy: 0.9179\n",
      "Epoch 227/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0885 - dice_coef: 0.0881 - accuracy: 0.9432 - val_loss: -0.0579 - val_dice_coef: 0.0579 - val_accuracy: 0.9179\n",
      "Epoch 228/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0888 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0579 - val_dice_coef: 0.0579 - val_accuracy: 0.9179\n",
      "Epoch 229/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0887 - dice_coef: 0.0886 - accuracy: 0.9431 - val_loss: -0.0580 - val_dice_coef: 0.0580 - val_accuracy: 0.9180\n",
      "Epoch 230/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0888 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0580 - val_dice_coef: 0.0580 - val_accuracy: 0.9180\n",
      "Epoch 231/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0889 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0581 - val_dice_coef: 0.0581 - val_accuracy: 0.9180\n",
      "Epoch 232/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0889 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0581 - val_dice_coef: 0.0581 - val_accuracy: 0.9180\n",
      "Epoch 233/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0889 - dice_coef: 0.0888 - accuracy: 0.9432 - val_loss: -0.0581 - val_dice_coef: 0.0581 - val_accuracy: 0.9180\n",
      "Epoch 234/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0889 - dice_coef: 0.0889 - accuracy: 0.9432 - val_loss: -0.0582 - val_dice_coef: 0.0582 - val_accuracy: 0.9180\n",
      "Epoch 235/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0890 - dice_coef: 0.0890 - accuracy: 0.9432 - val_loss: -0.0582 - val_dice_coef: 0.0582 - val_accuracy: 0.9181\n",
      "Epoch 236/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0892 - dice_coef: 0.0891 - accuracy: 0.9432 - val_loss: -0.0583 - val_dice_coef: 0.0583 - val_accuracy: 0.9181\n",
      "Epoch 237/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0890 - dice_coef: 0.0889 - accuracy: 0.9432 - val_loss: -0.0583 - val_dice_coef: 0.0583 - val_accuracy: 0.9181\n",
      "Epoch 238/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0891 - dice_coef: 0.0888 - accuracy: 0.9433 - val_loss: -0.0583 - val_dice_coef: 0.0583 - val_accuracy: 0.9181\n",
      "Epoch 239/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0892 - dice_coef: 0.0891 - accuracy: 0.9432 - val_loss: -0.0584 - val_dice_coef: 0.0584 - val_accuracy: 0.9181\n",
      "Epoch 240/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0892 - dice_coef: 0.0891 - accuracy: 0.9432 - val_loss: -0.0584 - val_dice_coef: 0.0584 - val_accuracy: 0.9181\n",
      "Epoch 241/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0893 - dice_coef: 0.0892 - accuracy: 0.9432 - val_loss: -0.0585 - val_dice_coef: 0.0585 - val_accuracy: 0.9182\n",
      "Epoch 242/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0892 - dice_coef: 0.0891 - accuracy: 0.9432 - val_loss: -0.0585 - val_dice_coef: 0.0585 - val_accuracy: 0.9182\n",
      "Epoch 243/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0894 - dice_coef: 0.0891 - accuracy: 0.9433 - val_loss: -0.0585 - val_dice_coef: 0.0585 - val_accuracy: 0.9182\n",
      "Epoch 244/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0894 - dice_coef: 0.0895 - accuracy: 0.9432 - val_loss: -0.0586 - val_dice_coef: 0.0586 - val_accuracy: 0.9182\n",
      "Epoch 245/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0895 - dice_coef: 0.0896 - accuracy: 0.9433 - val_loss: -0.0586 - val_dice_coef: 0.0586 - val_accuracy: 0.9183\n",
      "Epoch 246/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0894 - dice_coef: 0.0890 - accuracy: 0.9434 - val_loss: -0.0587 - val_dice_coef: 0.0587 - val_accuracy: 0.9183\n",
      "Epoch 247/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0895 - dice_coef: 0.0897 - accuracy: 0.9433 - val_loss: -0.0587 - val_dice_coef: 0.0587 - val_accuracy: 0.9183\n",
      "Epoch 248/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0894 - dice_coef: 0.0894 - accuracy: 0.9433 - val_loss: -0.0587 - val_dice_coef: 0.0587 - val_accuracy: 0.9183\n",
      "Epoch 249/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0894 - dice_coef: 0.0892 - accuracy: 0.9433 - val_loss: -0.0588 - val_dice_coef: 0.0588 - val_accuracy: 0.9183\n",
      "Epoch 250/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0897 - dice_coef: 0.0899 - accuracy: 0.9433 - val_loss: -0.0588 - val_dice_coef: 0.0588 - val_accuracy: 0.9183\n",
      "Epoch 251/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0897 - dice_coef: 0.0897 - accuracy: 0.9434 - val_loss: -0.0589 - val_dice_coef: 0.0589 - val_accuracy: 0.9184\n",
      "Epoch 252/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0895 - dice_coef: 0.0895 - accuracy: 0.9434 - val_loss: -0.0589 - val_dice_coef: 0.0589 - val_accuracy: 0.9184\n",
      "Epoch 253/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0896 - dice_coef: 0.0897 - accuracy: 0.9433 - val_loss: -0.0589 - val_dice_coef: 0.0589 - val_accuracy: 0.9184\n",
      "Epoch 254/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0897 - dice_coef: 0.0895 - accuracy: 0.9433 - val_loss: -0.0590 - val_dice_coef: 0.0590 - val_accuracy: 0.9184\n",
      "Epoch 255/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0897 - dice_coef: 0.0895 - accuracy: 0.9433 - val_loss: -0.0590 - val_dice_coef: 0.0590 - val_accuracy: 0.9184\n",
      "Epoch 256/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0897 - dice_coef: 0.0899 - accuracy: 0.9433 - val_loss: -0.0591 - val_dice_coef: 0.0591 - val_accuracy: 0.9184\n",
      "Epoch 257/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0896 - dice_coef: 0.0899 - accuracy: 0.9433 - val_loss: -0.0591 - val_dice_coef: 0.0591 - val_accuracy: 0.9185\n",
      "Epoch 258/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0898 - dice_coef: 0.0899 - accuracy: 0.9433 - val_loss: -0.0591 - val_dice_coef: 0.0591 - val_accuracy: 0.9185\n",
      "Epoch 259/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0897 - dice_coef: 0.0900 - accuracy: 0.9433 - val_loss: -0.0592 - val_dice_coef: 0.0592 - val_accuracy: 0.9185\n",
      "Epoch 260/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0899 - dice_coef: 0.0900 - accuracy: 0.9434 - val_loss: -0.0592 - val_dice_coef: 0.0592 - val_accuracy: 0.9185\n",
      "Epoch 261/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0899 - dice_coef: 0.0901 - accuracy: 0.9433 - val_loss: -0.0593 - val_dice_coef: 0.0592 - val_accuracy: 0.9186\n",
      "Epoch 262/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0900 - dice_coef: 0.0900 - accuracy: 0.9434 - val_loss: -0.0593 - val_dice_coef: 0.0593 - val_accuracy: 0.9186\n",
      "Epoch 263/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0900 - dice_coef: 0.0902 - accuracy: 0.9434 - val_loss: -0.0593 - val_dice_coef: 0.0593 - val_accuracy: 0.9186\n",
      "Epoch 264/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0900 - dice_coef: 0.0901 - accuracy: 0.9434 - val_loss: -0.0594 - val_dice_coef: 0.0594 - val_accuracy: 0.9186\n",
      "Epoch 265/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0901 - dice_coef: 0.0899 - accuracy: 0.9434 - val_loss: -0.0594 - val_dice_coef: 0.0594 - val_accuracy: 0.9186\n",
      "Epoch 266/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0901 - dice_coef: 0.0901 - accuracy: 0.9433 - val_loss: -0.0595 - val_dice_coef: 0.0595 - val_accuracy: 0.9187\n",
      "Epoch 267/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0903 - dice_coef: 0.0905 - accuracy: 0.9434 - val_loss: -0.0595 - val_dice_coef: 0.0595 - val_accuracy: 0.9187\n",
      "Epoch 268/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0903 - dice_coef: 0.0904 - accuracy: 0.9434 - val_loss: -0.0595 - val_dice_coef: 0.0595 - val_accuracy: 0.9187\n",
      "Epoch 269/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0902 - dice_coef: 0.0904 - accuracy: 0.9434 - val_loss: -0.0596 - val_dice_coef: 0.0596 - val_accuracy: 0.9187\n",
      "Epoch 270/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0902 - dice_coef: 0.0904 - accuracy: 0.9434 - val_loss: -0.0596 - val_dice_coef: 0.0596 - val_accuracy: 0.9187\n",
      "Epoch 271/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0903 - dice_coef: 0.0906 - accuracy: 0.9434 - val_loss: -0.0597 - val_dice_coef: 0.0597 - val_accuracy: 0.9188\n",
      "Epoch 272/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0904 - dice_coef: 0.0902 - accuracy: 0.9434 - val_loss: -0.0597 - val_dice_coef: 0.0597 - val_accuracy: 0.9188\n",
      "Epoch 273/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0904 - dice_coef: 0.0901 - accuracy: 0.9434 - val_loss: -0.0597 - val_dice_coef: 0.0597 - val_accuracy: 0.9188\n",
      "Epoch 274/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0902 - dice_coef: 0.0904 - accuracy: 0.9434 - val_loss: -0.0598 - val_dice_coef: 0.0598 - val_accuracy: 0.9188\n",
      "Epoch 275/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0904 - dice_coef: 0.0903 - accuracy: 0.9434 - val_loss: -0.0598 - val_dice_coef: 0.0598 - val_accuracy: 0.9188\n",
      "Epoch 276/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0903 - dice_coef: 0.0905 - accuracy: 0.9434 - val_loss: -0.0599 - val_dice_coef: 0.0599 - val_accuracy: 0.9189\n",
      "Epoch 277/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0906 - dice_coef: 0.0907 - accuracy: 0.9434 - val_loss: -0.0599 - val_dice_coef: 0.0599 - val_accuracy: 0.9189\n",
      "Epoch 278/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0906 - dice_coef: 0.0907 - accuracy: 0.9435 - val_loss: -0.0599 - val_dice_coef: 0.0599 - val_accuracy: 0.9189\n",
      "Epoch 279/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0906 - dice_coef: 0.0905 - accuracy: 0.9434 - val_loss: -0.0600 - val_dice_coef: 0.0600 - val_accuracy: 0.9189\n",
      "Epoch 280/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0907 - dice_coef: 0.0906 - accuracy: 0.9435 - val_loss: -0.0600 - val_dice_coef: 0.0600 - val_accuracy: 0.9189\n",
      "Epoch 281/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0905 - dice_coef: 0.0903 - accuracy: 0.9435 - val_loss: -0.0601 - val_dice_coef: 0.0601 - val_accuracy: 0.9190\n",
      "Epoch 282/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0906 - dice_coef: 0.0909 - accuracy: 0.9435 - val_loss: -0.0601 - val_dice_coef: 0.0601 - val_accuracy: 0.9190\n",
      "Epoch 283/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0908 - dice_coef: 0.0907 - accuracy: 0.9435 - val_loss: -0.0601 - val_dice_coef: 0.0601 - val_accuracy: 0.9190\n",
      "Epoch 284/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0907 - dice_coef: 0.0905 - accuracy: 0.9435 - val_loss: -0.0602 - val_dice_coef: 0.0602 - val_accuracy: 0.9190\n",
      "Epoch 285/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0908 - dice_coef: 0.0907 - accuracy: 0.9435 - val_loss: -0.0602 - val_dice_coef: 0.0602 - val_accuracy: 0.9190\n",
      "Epoch 286/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0909 - dice_coef: 0.0909 - accuracy: 0.9435 - val_loss: -0.0603 - val_dice_coef: 0.0603 - val_accuracy: 0.9191\n",
      "Epoch 287/400\n",
      " 6/19 [========>.....................] - ETA: 2s - loss: -0.0924 - dice_coef: 0.0924 - accuracy: 0.9422"
     ]
    }
   ],
   "source": [
    "tranfer_learning_results = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=32, epochs=maxepoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "root_path = ''\n",
    "# save the trained model\n",
    "model_yaml = transfered_model.to_yaml()\n",
    "with open(root_path+\"history_transfered_NAIP_Dropout_0.7_\"+timestr+\".yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# save the weights\n",
    "transfered_model.save(root_path+\"model_transfered_NAIP_Dropout_0.7_\"+timestr+\".h5\")\n",
    "# save the intermdediate results and training statistics\n",
    "with open(root_path+\"history_transfered_NAIP_Dropout_0.7_\"+timestr+\".pickle\", 'wb') as file_pi:\n",
    "    pickle.dump(tranfer_learning_results.history, file_pi, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will wait for the whole area data to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c574e7fc8f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the predicted labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/prediction_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds_test_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds_test\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/preds_test_total_attention2.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds_test_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the predicted labels.\n",
    "X_test = np.load(root_path+'ModelJun14/prediction_data.npy')\n",
    "preds_test = model.predict(X_test)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "np.save(root_path+'ModelJun14/preds_test_total_attention2.npy',preds_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress 28/09/2020\n",
    "1. Added Dropout layer   \n",
    "    **Result:** The dropout doesn't help in this case.  \n",
    "    with 0.5 drop rate and 1000 epochs we can achive 94.1%\n",
    "\n",
    "\n",
    "# Progress 21/09/2020\n",
    "1. Genreating the result for transfer learnign without NAIP again \n",
    "2. Created the [plan until Mid Oct 2020](\"https://docs.google.com/document/d/1Kqz18zgB-DSkDarr-m8Y-__0ZCNzXAkTZw7Xg7kIy08/edit#\")\n",
    "    - The goal is to finish the first draft by Mid Oct. \n",
    "    \n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020[.]('https://analyticsindiamag.com/top-10-papers-on-transfer-learning-one-must-read-in-2020/')  \n",
    "\n",
    "# Progress 14/09/2020\n",
    "1. Read and summarize more  [transfer learning paper]('https://openreview.net/pdf?id=ryxyCeHtPB')  \n",
    "    - propose \"attentive feature distillation and selection (AFDS)\"   \n",
    "    - AFDS dynamically learns not only the features to transfer, but also the unimportant neurons to skip    \n",
    "    \n",
    "\n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020\n",
    "\n",
    "**Qual Exam beginning of next semester**\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 07/09/2020  \n",
    "1. Presented the progress in CEGIS  \n",
    "  \n",
    "2. Generated total dataset for Covingtoin area (without NAIP imagery)\n",
    "    \n",
    "3. Run prediction of the Convington area with the dataset without NAIP and using the original model that is trained on Rowan creek area  \n",
    "\n",
    "\n",
    "# Plan work\n",
    "1. Try training the model with more weight of stream class.\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 31/08/2020\n",
    "1. Corrected the data (removing None class (-9999) from test dataset)\n",
    "    - will generate the new test results  \n",
    "  \n",
    "  \n",
    "2. Preparing for CEGIS presentation\n",
    "    - Added prelim results  \n",
    "    - Will add the base scenario which is the U-net model predict the dataset without NAIP in Covinton river  \n",
    "      \n",
    "        \n",
    "    \n",
    "3. preparing the script for the presentation  \n",
    "    \n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "\n",
    "----\n",
    "\n",
    "# Progress 24/08/2020\n",
    "\n",
    "**Comments:** Try to get the why and what it hold true and how to make or to apply to other places.  \n",
    "\n",
    "1. Generate the whole area and do testing\n",
    "    - Generated the dataset\n",
    "    - Evaluated the testing data and generated the prelim results\n",
    "**Problem:** the data has more than 2 classes as shown in evaluation.   \n",
    "      \n",
    "    \n",
    "2. Created the outline of the presentation for CEGIS \n",
    "    - Still need more details:   \n",
    "    https://docs.google.com/presentation/d/1PWrlgGEMCCJLXsAHeiTe40xdA22RtISE6gUpRbbplRs/edit?usp=sharing\n",
    "\n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "4. Correct the data (remove the None class)\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 17/08/2020\n",
    "1. Finished generating the new dataset\n",
    "    - Cleaned the NAIP data and all raw data of Covington River\n",
    "    - Included NAIP imagery into the dataset\n",
    "    - Edited the data preprocessing script to make it easier to add or remove data \n",
    "    - Added script documents and comments  \n",
    "      \n",
    "2. Generating the whole area dataset the included NAIP imagery\n",
    "    - Using High memory node on Keeling   \n",
    "    - **Problem:** The VPN disconnected after 2 hours in!!! T_T I have to start over.  \n",
    "  \n",
    "3. Trained the model with new dataset  \n",
    "    - The performance is significatly higher than the dataset without NAIP  \n",
    "  \n",
    "4. Read more papers and added summary of the read paper\n",
    "    -https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit  \n",
    "  \n",
    "# Plan for this week\n",
    "1. Generate the whole area and do testing\n",
    "2. Start preparing the presentation for CEGIS \n",
    "3. Read and summarize more papers\n",
    "    - Focus more on machine learning in hydro, remote sensing classification.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Prgress 10/08/2020\n",
    "\n",
    "1. Successfully trained the model on my own PC.  \n",
    "    - Fixed cuCNN and CUDA version problems \n",
    "    - Trained with 4 trainable layers  \n",
    "      **Problem:** The model just disrtegards the stream class.  \n",
    "      **Root cause:** Unbalanced sample of stream and non-stream classes   \n",
    "\n",
    "2. In progress: Adding NAIP image to the dataset. \n",
    "    - Extracted the NAIP for Covinton and put it on Keeling \n",
    "    - modifying the preprocessing code\n",
    "    \n",
    "3. Outline the Introduction of the paper and reviewed some papers\n",
    "    - https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit\n",
    "    \n",
    "# Plan for this week\n",
    "1. Finished adding the NAIP and train the model again\n",
    "2. Start the first draft of the introduction \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
