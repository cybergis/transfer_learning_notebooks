{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;line-height:1.5em;font-size:30px;\">Transfer Learning with a Convolutional Neural Network for Hydrological Streamline Detection</h1>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "    Nattapon Jaroenchai$^{a, b}$ Shaohua Wang$^{a, b}$, Li Chen$^{a, b}$, Lawrence V. Stanislawski$^{c}$, Ethan Shavers$^{c}$, E. Lynn Usery$^{c}$, Shaowen Wang$^{a, b}$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "$^{a}$ Department of Geography and Geographic Information Science, University of Illinois at Urbana-Champaign, Urbana, IL, US<br>\n",
    "$^{b}$ CyberGIS Center for Advanced Digital and Spatial Studies, University of Illinois at Urbana-Champaign, Urbana, IL, USA<br>\n",
    "$^{c}$ U.S. Geology Survey, Center of Excellence for Geospatial Information Science, Rolla, MO, USA <br>\n",
    "$^{d}$ School of Geoscience and Info-Physics, Central South University, Changsha, Hunan, China <br>\n",
    "</p>\n",
    "\n",
    "---\n",
    "    \n",
    "**Notebook Structure:**\n",
    "- [Introduction](introduction.ipynb)\n",
    "- Codes\n",
    " - [Data Preprocessing](preprocessing.ipynb)\n",
    " - [Experiment 1: different input datasets](experiment_1.ipynb)\n",
    " - [Experiment 2: retrain different part of the network](experiment_2.ipynb)\n",
    " - [Experiment 3: different sample sizes](experiment_3.ipynb)\n",
    " - [Model Evaluation](evaluation.ipynb) \n",
    " - [Conclusion](conclusion.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In this step we use Pillow libraries to read raster images and then stack the images into data cube using NumP. Then we define the array of images's file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import glob\n",
    "im.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define array of input files\n",
    "We also define the range of max and min pixel value of each raster image. The range are calculated using the range of 3 standard diveations or 99.7% of all pixels. This is to prevent the problem in normalization process.\n",
    "\n",
    "### Choose which data set we want to create\n",
    "\n",
    "In this study we use 2 datasets:\n",
    "1. The dataset the only cantains DEM derived data \n",
    "2. The dataset with NAIP bands raster images \n",
    "\n",
    "### If you want to create data wihtout NAIP run the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only DEM derived data\n",
    "files = files = [\n",
    "    '01_CovingtonRiver_020801030302_CURVATURE_nodata.tif',\n",
    "    '02_CovingtonRiver_020801030302_SLOPE_nodata.tif', \n",
    "    '03_CovingtonRiver_020801030302_OPENESS_nodata.tif',\n",
    "    '04_CovingtonRiver_020801030302_DEM_nodata.tif', \n",
    "    '05_CovingtonRiver_020801030302_TPI_21_nodata.tif', \n",
    "    '06_CovingtonRiver_020801030302_INTENSITY_nodata.tif',\n",
    "    '07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif',  \n",
    "    '08_TPI_CovingtonRiver_020801030302_3_nodata.tif',\n",
    "    ]\n",
    "#The ranges here are the range of 3SD or 99.7% of all data\n",
    "#This is to prevent problem in the normalization process\n",
    "ranges =[\n",
    "    [-0.28222607489286866,0.28248185206077936], # '01_CovingtonRiver_020801030302_CURVATURE_nodata.tif'\n",
    "    [-0.28097646432537005,0.7456170822778501], # '02_CovingtonRiver_020801030302_SLOPE_nodata.tif'\n",
    "    [81.4260223726079, 96.2421904790021], # '03_CovingtonRiver_020801030302_OPENESS_nodata.tif'\n",
    "    [-207.05215950623995, 938.84507252262], # '04_CovingtonRiver_020801030302_DEM_nodata.tif'\n",
    "    [-0.8616536368618285, 0.8618900909336314], # '05_CovingtonRiver_020801030302_TPI_21_nodata.tif'\n",
    "    [1.494045913614002, 77.145486958992],# '06_CovingtonRiver_020801030302_INTENSITY_nodata.tif'\n",
    "    [3.1338925783175906, 8.81583142566701], # '07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif'\n",
    "    [-0.19840276259099499, 0.198406762590995] # '08_TPI_CovingtonRiver_020801030302_3_nodata.tif'\n",
    "    ]\n",
    "name_suffix = \"without_NAIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In you want to generate the dataset with NAIP iamgery, run the code block below\n",
    "\n",
    "In the dataset with NAIP raster iamges, we substitute slope, openness, LiDAR intensity, and TPI with window size 3 with red, green, blue, and near infrared bands of NAIP imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Files' name of all the ionput data\n",
    "# files = [\n",
    "#     '01_CovingtonRiver_020801030302_CURVATURE_nodata.tif',\n",
    "#     '04_CovingtonRiver_020801030302_DEM_nodata.tif', \n",
    "#     '05_CovingtonRiver_020801030302_TPI_21_nodata.tif', \n",
    "#     '07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif',  \n",
    "#     'NAIP/NAIP2018_RED_edit_nodata.tif',\n",
    "#     'NAIP/NAIP2018_GREEN_edit_nodata.tif',\n",
    "#     'NAIP/NAIP2018_BLUE_edit_nodata.tif',\n",
    "#     'NAIP/NAIP2018_INFARED_edit_nodata.tif' \n",
    "#     ]\n",
    "\n",
    "# #The ranges here are the range of 3SD or 99.7% of all data\n",
    "# #This is to prevent problem in the normalization process\n",
    "# ranges =[\n",
    "#     [-0.28222607489286866,0.28248185206077936], # '01_CovingtonRiver_020801030302_CURVATURE_nodata.tif'\n",
    "#     [-207.05215950623995, 938.84507252262], # '04_CovingtonRiver_020801030302_DEM_nodata.tif'\n",
    "#     [-0.8616536368618285, 0.8618900909336314], # '05_CovingtonRiver_020801030302_TPI_21_nodata.tif'\n",
    "#     [3.1338925783175906, 8.81583142566701], # '07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif'\n",
    "#     ]\n",
    "# name_suffix = \"with_NAIP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define normalization funcition\n",
    " \n",
    " We normalize pixel values using the equation below. \n",
    " \n",
    "<img src=\"img/preprocess_normalize_equation.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize function\n",
    "def normalize(array_x, min_x, max_x):\n",
    "    \n",
    "    # set all pixels to be within the range.\n",
    "    array_x[ (array_x!=-9999) & (array_x < min_x) ] = min_x\n",
    "    array_x[ (array_x!=-9999) & (array_x > max_x) ] = max_x\n",
    "    \n",
    "    # normalize array \n",
    "    array_x[array_x!=-9999] = ((array_x[array_x!=-9999]-min_x)/(max_x-min_x))*255\n",
    "    \n",
    "    return array_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the total dataset of the whole study area\n",
    "\n",
    "Note: We cannot run the preprocessing process due to the memory limit on CyberGISX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./organized_data/raw/01_CovingtonRiver_020801030302_CURVATURE_nodata.tif\n",
      "(13867, 14406)\n",
      "Normalized  ./organized_data/raw/01_CovingtonRiver_020801030302_CURVATURE_nodata.tif\n",
      "./organized_data/raw/02_CovingtonRiver_020801030302_SLOPE_nodata.tif\n",
      "(13867, 14406)\n",
      "Normalized  ./organized_data/raw/02_CovingtonRiver_020801030302_SLOPE_nodata.tif\n",
      "./organized_data/raw/03_CovingtonRiver_020801030302_OPENESS_nodata.tif\n",
      "(13867, 14406)\n",
      "Normalized  ./organized_data/raw/03_CovingtonRiver_020801030302_OPENESS_nodata.tif\n",
      "./organized_data/raw/04_CovingtonRiver_020801030302_DEM_nodata.tif\n",
      "(13867, 14406)\n",
      "Normalized  ./organized_data/raw/04_CovingtonRiver_020801030302_DEM_nodata.tif\n",
      "./organized_data/raw/05_CovingtonRiver_020801030302_TPI_21_nodata.tif\n",
      "(13867, 14406)\n",
      "Normalized  ./organized_data/raw/05_CovingtonRiver_020801030302_TPI_21_nodata.tif\n",
      "./organized_data/raw/06_CovingtonRiver_020801030302_INTENSITY_nodata.tif\n"
     ]
    }
   ],
   "source": [
    "# folder contains the TIFF files\n",
    "data_folder = './organized_data/raw/'\n",
    "\n",
    "#initialize the output\n",
    "output = [] \n",
    "output = np.array(output)\n",
    "\n",
    "for num, file in enumerate(files, start = 0 ): \n",
    "    \n",
    "    path = data_folder+file\n",
    "    print(path)\n",
    "\n",
    "    image = im.open(path)\n",
    "    image_array = np.array(image)\n",
    "    print(image_array.shape)\n",
    "    \n",
    "    # the first image is used to initialize the size of the output array\n",
    "    if (num == 0):\n",
    "        output=np.empty((len(files),image_array.shape[0], image_array.shape[1]))\n",
    "        \n",
    "    # The null value in \"07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif\" has to be set to -9999 instead of 255. Then normalize the raster. \n",
    "    if(files == '07_CovingtonRiver_020801030302_Cov10cell_Geomorphon.tif'):\n",
    "        image_array[image_array==255] = -9999\n",
    "        image_array = normalize(image_array,ranges[num][0],ranges[num][1])\n",
    "        \n",
    "    # For NAIP bands image we have to set null to -9999 instead of 0. We do not normalize NAIP images because all data are normalized to 0-255 which is the range of NAIP dataset. \n",
    "    elif(\"NAIP\" in file):\n",
    "        image_array[image_array==0] = -9999\n",
    "    \n",
    "    # Normalize the image.\n",
    "    else:\n",
    "        image_array = normalize(image_array,ranges[num][0],ranges[num][1])\n",
    "\n",
    "    print(\"Normalized \", path)\n",
    "    \n",
    "    # Each raster images are stacked in out put array. \n",
    "    output[num] = image_array\n",
    "\n",
    "# shift the shape of output array to (width, height, img#) \n",
    "output = np.moveaxis(output,0,-1)\n",
    "\n",
    "# Save the array as NPY file, named total_without_NAIP.\n",
    "np.save('total_'+name_suffix,output)\n",
    "print('saved total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create study area mask\n",
    "\n",
    "We create the mask of the watershed using the curvature raster image. The pixels outside of the study area are set to 0 and pixels inside are set to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save mask\n"
     ]
    }
   ],
   "source": [
    "def generate_mask():\n",
    "    \n",
    "    path = './organized_data/raw/01_CovingtonRiver_020801030302_CURVATURE_nodata.tif'\n",
    "\n",
    "    image = im.open(path)\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # set pixels out side to 0 and inside to 1\n",
    "    mask = image_array != -9999\n",
    "    \n",
    "    # the pixel values must be converted to int to make sure that we can use it as boolean datatype.\n",
    "    mask.astype(int)\n",
    "    \n",
    "    # save the mask array as mask.npy\n",
    "    np.save('mask',mask)\n",
    "    print('save mask')\n",
    "\n",
    "generate_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reference dataset\n",
    "\n",
    "For the reference data we read the raster image and directly convert it to Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved reference\n"
     ]
    }
   ],
   "source": [
    "def generate_reference():\n",
    "    \n",
    "    # read the reference TIFF file \n",
    "    path = './organized_data/raw/reference_nodata.tif'\n",
    "    image = im.open(path)\n",
    "    \n",
    "    # canvert the raster to Numpy array\n",
    "    image_array = np.array(image)    \n",
    "    \n",
    "    # set the null value (-9999) to NumPy NaN value\n",
    "    image_array[image_array==-9999] = 0\n",
    "    \n",
    "    # save the array to reference_as_None.npy\n",
    "    np.save('reference',image_array)\n",
    "    print('saved reference')\n",
    "\n",
    "generate_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Generate traning and validation sample patches\n",
    "\n",
    "We divide the study area into two parts, top and bottom. The training and validation sample patches are generated from the top part of study area.   \n",
    "The entire bottom part is used to generate testing sample patches using the moving window strategy with 30 pixels buffer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug==0.4.0 in /opt/conda/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (1.4.1)\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (2.8.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (3.1.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (7.0.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (0.16.2)\n",
      "Requirement already satisfied: Shapely in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (1.7.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from imgaug==0.4.0) (4.3.0.36)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug==0.4.0) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug==0.4.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug==0.4.0) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->imgaug==0.4.0) (1.1.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.4)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.4.0) (45.2.0.post20200209)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.4.0) (4.4.2)\n",
      "Requirement already satisfied: intervaltree in /home/jovyan/.local/lib/python3.7/site-packages (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from intervaltree) (2.1.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[31mERROR: libpysal 4.2.2 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.0.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.7 are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed numpy-1.21.1\n",
      "Collecting tensorflow==2.1.4\n",
      "  Downloading https://tf.novaal.de/barcelona/tensorflow-2.1.4-cp37-cp37m-linux_x86_64.whl (96.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 96.9 MB 50 kB/s s eta 0:00:01             | 1.4 MB 460 kB/s eta 0:03:28               | 2.7 MB 460 kB/s eta 0:03:25                   | 3.4 MB 460 kB/s eta 0:03:233 MB 460 kB/s eta 0:03:21ta 0:01:21                    | 14.6 MB 1.1 MB/s eta 0:01:16B 1.1 MB/s eta 0:01:16  | 17.0 MB 1.1 MB/s eta 0:01:141 MB/s eta 0:01:13██▋                         | 19.9 MB 1.1 MB/s eta 0:01:11            | 21.0 MB 1.2 MB/s eta 0:01:03 MB 1.2 MB/s eta 0:01:02 MB 1.2 MB/s eta 0:01:01��████▋                       | 26.0 MB 1.2 MB/s eta 0:00:59 MB 1.2 MB/s eta 0:00:58��████▍                     | 31.3 MB 1.2 MB/s eta 0:00:55 MB/s eta 0:00:01    |███████████████▍                | 46.6 MB 75.1 MB/s eta 0:00:01████████████████                | 48.7 MB 75.1 MB/s eta 0:00:01  | 50.9 MB 75.1 MB/s eta 0:00:01[K     |██████████████████▏             | 55.1 MB 75.1 MB/s eta 0:00:01[K     |██████████████████▊             | 56.5 MB 75.1 MB/s eta 0:00:01   | 58.6 MB 75.1 MB/s eta 0:00:01MB/s eta 0:00:27��██▌           | 61.9 MB 1.4 MB/s eta 0:00:26███████████████▋          | 65.5 MB 1.4 MB/s eta 0:00:23:00:22█████████████▋        | 71.3 MB 1.4 MB/s eta 0:00:19�████████████       | 75.5 MB 1.4 MB/s eta 0:00:16 | 81.9 MB 84.4 MB/s eta 0:00:01��████████▌    | 83.2 MB 84.4 MB/s eta 0:00:01��████████████████▍   | 86.0 MB 84.4 MB/s eta 0:00:01    |█████████████████████████████▍  | 88.9 MB 84.4 MB/s eta 0:00:01 MB 84.4 MB/s eta 0:00:01███████▉| 96.2 MB 84.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 38.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py<=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 25.2 MB/s eta 0:00:01                  | 532 kB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.38.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 53.2 MB/s eta 0:00:01██████████████▍          | 2.8 MB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 45.2 MB/s eta 0:00:01[K     |█████████████▉                  | 1.7 MB 45.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting keras-preprocessing==1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 1.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hProcessing /home/jovyan/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.33.0-py2.py3-none-any.whl (151 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 49.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=41.0.0\n",
      "  Downloading setuptools-57.4.0-py3-none-any.whl (819 kB)\n",
      "\u001b[K     |████████████████████████████████| 819 kB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 68.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.3-py3-none-any.whl (35 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 64.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 26.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70937 sha256=51a4dc2bf7fbc7e02e229a1e527b3d19b16927d51cc41dfc95e174e96172050e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=9b124105008c87cf71a812379c2743fdf6bda902e1889e8cdddb8014d4958b3e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built wrapt termcolor\n",
      "\u001b[31mERROR: libpysal 4.2.2 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.15.38 has requirement urllib3<1.26,>=1.20, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, absl-py, google-pasta, numpy, opt-einsum, protobuf, astor, h5py, keras-applications, wrapt, wheel, tensorflow-estimator, grpcio, idna, certifi, charset-normalizer, urllib3, requests, typing-extensions, zipp, importlib-metadata, markdown, cachetools, pyasn1, rsa, pyasn1-modules, setuptools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, werkzeug, tensorboard, termcolor, keras-preprocessing, gast, tensorflow\n",
      "Successfully installed absl-py-0.13.0 astor-0.8.1 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.3 gast-0.2.2 google-auth-1.33.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.38.1 h5py-2.10.0 idna-3.2 importlib-metadata-4.6.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.18.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 setuptools-57.4.0 six-1.16.0 tensorboard-2.1.1 tensorflow-2.1.4 tensorflow-estimator-2.1.0 termcolor-1.1.0 typing-extensions-3.10.0.0 urllib3-1.26.6 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# install required libraries for preprocessing.\n",
    "!pip install --user imgaug==0.4.0\n",
    "!pip install --user intervaltree\n",
    "!pip install --user numpy --upgrade\n",
    "    \n",
    "# Please restart the kernel after this block finished running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In this step we use intervaltree library for checking the overlap between patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import sys\n",
    "from intervaltree import Interval, IntervalTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for checking if the patch is valid\n",
    "\n",
    "The condition to be valid are:\n",
    "\n",
    "1. the patch size is 224 pixels by 224 pixels and located within the study area. \n",
    "2. The patch of validation must not overlap with training patches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data patches!\n"
     ]
    }
   ],
   "source": [
    "# Define function for checking if the patch is valid \n",
    "def is_invalid(mode, temp, templ, minrow, maxrow, mincolumn, maxcolumn):\n",
    "\n",
    "    # check complete patch\n",
    "    is_not_complete_patch = np.any(temp[0,:,:,-1] <= 0) or temp.shape[1:3] != (patch_size,patch_size) or templ.shape[1:] != (patch_size,patch_size)\n",
    "\n",
    "    if mode ==\"training\":\n",
    "        # training sample can overlap with itself \n",
    "        # so, we only check if it is complete patch or not\n",
    "        return is_not_complete_patch\n",
    "\n",
    "    if mode ==\"validation\":\n",
    "        # validation sample **cannot** overlap with training samples patches\n",
    "        # so, we need to 1) check the completeness 2) check if it overleps with training samples\n",
    "\n",
    "        is_overlap = False\n",
    "\n",
    "        row_overlap = samples_row[minrow:maxrow]\n",
    "        column_overlap = samples_column[mincolumn:maxcolumn]\n",
    "\n",
    "        for row_interval in row_overlap:\n",
    "            begin, end, row_data = row_interval\n",
    "            for column_interval in column_overlap:\n",
    "                begin, end, column_data = column_interval\n",
    "                if(row_data == column_data):\n",
    "                    is_overlap = True\n",
    "                    # print(minrow, maxrow, mincolumn, maxcolumn)\n",
    "                    # print(row_interval, column_interval)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        return bool(is_not_complete_patch or is_overlap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function fro sample patches extraction\n",
    "\n",
    "After we have the valid location of all sample patches, we extract the data from the total dataset. The function returns a tuple of array of all sample patches and their labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract stream/non-stream samples using the random patches\n",
    "def generate_samples(totaldata,row,col,label,size,train_or_vali):\n",
    "    \n",
    "    global start_index\n",
    "    global samples_row\n",
    "    global samples_column\n",
    "    global training_sample\n",
    "    global validation_sample\n",
    "\n",
    "    count = 0\n",
    "    row = row[start_index:]\n",
    "    col = col[start_index:]\n",
    "\n",
    "    for index,(i,j) in enumerate(zip(row,col)):\n",
    "\n",
    "        # calculate min max ranges of the patch.\n",
    "        minrow = (i-int(patch_size/2))\n",
    "        maxrow = (i+int(patch_size/2))\n",
    "        mincolumn = (j-int(patch_size/2))\n",
    "        maxcolumn = (j+int(patch_size/2))\n",
    "\n",
    "        # extract data from total dataset and label of total dataset\n",
    "        temp = totaldata[minrow:maxrow,mincolumn:maxcolumn,:][np.newaxis,:,:,:]\n",
    "        templ = label[minrow:maxrow,mincolumn:maxcolumn][np.newaxis,:,:]\n",
    "\n",
    "        # validate the conditions\n",
    "        if is_invalid(train_or_vali,temp,templ,minrow,maxrow,mincolumn,maxcolumn):\n",
    "            # if not complete (or overlap in validation) skip this patch.\n",
    "            continue \n",
    "        else:\n",
    "            # if valid add to samples\n",
    "            count += 1\n",
    "            if count == 1:            \n",
    "                train_vali = temp[:,:,:,:-1]\n",
    "                train_vali_label = templ\n",
    "            else:\n",
    "                train_vali = np.concatenate((train_vali, temp[:,:,:,:-1]),axis = 0)\n",
    "                train_vali_label = np.concatenate((train_vali_label, templ),axis = 0)\n",
    "            \n",
    "            if train_or_vali == \"training\":\n",
    "                training_sample.append((minrow,mincolumn))\n",
    "\n",
    "                # if it is training sample, add the sample patch x and y ranges to the trees with the count as the ranges' label.\n",
    "                samples_row[minrow:maxrow] = count\n",
    "                samples_column[mincolumn:maxcolumn] = count\n",
    "\n",
    "            if train_or_vali == \"validation\":\n",
    "                validation_sample.append((minrow,mincolumn))\n",
    "\n",
    "        if count == size:\n",
    "            print(\"Generated \"+str(train_or_vali)+\": \"+str(count)+\" samples and used from \"+str(start_index)+\" to \"+str(start_index+index)+\"random rows and columns\")\n",
    "            start_index = start_index+index\n",
    "            return [train_vali,train_vali_label]\n",
    "    \n",
    "    # If the algorithm cannot find enough sample patches, print the message say not enough samples. \n",
    "    print(\"Not enough random smaples\")\n",
    "    print(\"Generated \"+str(train_or_vali)+\": \"+str(count)+\" samples out of \"+ str(size)+ \" end at index \"+str(index))\n",
    "    return \n",
    "\n",
    "print('Extracting data patches!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The extraction process \n",
    "\n",
    "At this step we will actually run the whole process. \n",
    "\n",
    "1. Load dataset: the total dataset, mask, and reference datasets are loaded from NPY files. \n",
    "2. Randomize the sample locations: 100,000 pixels of stream and non stram pixels are randomly selected from the reference. Their location (row and columns) are kept in separated arrays. \n",
    "3. Generate the samples: from the randomly selected pixels, each of them are evaluated if it is valid by the function above. Then, all valid pixels are saved to NPY files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Total_data/total_without_NAIP.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7981edc5d74b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Total data dimension: 14406*13867\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# read the total dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtotaldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Total_data/total_without_NAIP.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Total_data/mask.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Total_data/total_without_NAIP.npy'"
     ]
    }
   ],
   "source": [
    "####### Generate training/validation/testing image patches \n",
    "#Total data dimension: 14406*13867\n",
    "\n",
    "patch_size = 224 #patch size of each sample\n",
    "\n",
    "###### 1. Load datasets\n",
    "# read the total dataset \n",
    "totaldata = np.load('total_'+name_suffix+'.npy')\n",
    "\n",
    "# read the mask \n",
    "mask = np.load('mask.npy')\n",
    "\n",
    "# add mas to the total data array for convinience\n",
    "totaldata = np.concatenate((totaldata,mask[:,:,np.newaxis]),axis = 2)]\n",
    "\n",
    "# load the reference data\n",
    "label = np.load('reference.npy')\n",
    "\n",
    "print('Completed: Data Loading!')\n",
    "\n",
    "###### 2. Prepare the location of the stream and non stream patches by random sample from the reference raster\n",
    "# Use the upper half to generate training and validation data\n",
    "half = totaldata.shape[0]//2\n",
    "label_train_vali = label[:half]\n",
    "[r,c] = np.where(label_train_vali == True) #steamline patches\n",
    "[rn,cn] = np.where(label_train_vali == False) #non-steamline patches\n",
    "\n",
    "# randomly select 100000 sample from stream and non-stream pixels. \n",
    "inder = random.sample(range(0, len(r)-1), 100000)\n",
    "indenr = random.sample(range(0, len(rn)-1), 100000)\n",
    "\n",
    "# get the row and column value of each stream and non-stream pixel \n",
    "r,c = r[inder],c[inder]\n",
    "rn,cn = rn[indenr],cn[indenr]\n",
    "\n",
    "print('Get random coordinates of stream and non-stream pixels!')\n",
    "\n",
    "###### 3. generate the samples \n",
    "# Initialize the output array and tree structure for search algorithm\n",
    "samples_row = IntervalTree()\n",
    "samples_column = IntervalTree()\n",
    "validation_sample = []\n",
    "training_sample = []\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "# Generate training smaples 300 patches for both stream and non-stream\n",
    "training_samples_num = 300\n",
    "[train_vali_stream,train_vali_stream_label] = generate_samples(totaldata,r,c,label_train_vali,training_samples_num,\"training\")\n",
    "[train_vali_nonstream,train_vali_nonstream_label] = generate_samples(totaldata,rn,cn,label_train_vali,training_samples_num,\"training\")\n",
    "trainvali_data = np.concatenate((train_vali_stream,train_vali_nonstream),axis = 0)\n",
    "trainvali_label = np.concatenate((train_vali_stream_label,train_vali_nonstream_label),axis = 0)\n",
    "\n",
    "# Shuffle training and validation samples\n",
    "s = np.arange(trainvali_data.shape[0])\n",
    "np.random.shuffle(s)\n",
    "train_data = trainvali_data[s]\n",
    "train_label = trainvali_label[s]\n",
    "\n",
    "#Save the trainging samples both data and label\n",
    "np.save('./samples/train_data_'+name_suffix+'.npy',train_data)\n",
    "np.save('./samples/train_label_'+name_suffix+'.npy',train_label[:,:,:,np.newaxis])\n",
    "training_sample = np.array(training_sample)\n",
    "np.save('./samples/train_patches_top-left_'+name_suffix+'.npy',training_sample)\n",
    "\n",
    "# Generate validation smaples 300 patches for both stream and non-stream\n",
    "validation_samples_num = 300\n",
    "[train_vali_stream,train_vali_stream_label] = generate_samples(totaldata,r,c,label_train_vali,validation_samples_num,\"validation\")\n",
    "[train_vali_nonstream,train_vali_nonstream_label] = generate_samples(totaldata,rn,cn,label_train_vali,validation_samples_num,\"validation\")\n",
    "trainvali_data = np.concatenate((train_vali_stream,train_vali_nonstream),axis = 0)\n",
    "trainvali_label = np.concatenate((train_vali_stream_label,train_vali_nonstream_label),axis = 0)\n",
    "\n",
    "# Shuffle training and validation samples\n",
    "s = np.arange(trainvali_data.shape[0])\n",
    "np.random.shuffle(s)\n",
    "vali_data = trainvali_data[s]\n",
    "vali_label = trainvali_label[s]\n",
    "\n",
    "#Save the validation samples both data and label\n",
    "np.save('./samples/vali_data_'+name_suffix+'.npy',vali_data)\n",
    "np.save('./samples/vali_label_'+name_suffix+'.npy',vali_label[:,:,:,np.newaxis])\n",
    "validation_sample = np.array(validation_sample)\n",
    "np.save('./samples/vali_patches_top-left_'+name_suffix+'.npy',validation_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test samples\n",
    "\n",
    "The test sample patches are generated using moving window with 30 pixel buffer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# stream/non-stream sample size\n",
    "patch_size = 224 #patch size of each sample\n",
    "\n",
    "#Total data dimension: 13927, 14466\n",
    "totaldata = np.load('total_'+name_suffix+'.npy')\n",
    "mask = np.load('mask.npy')\n",
    "#Add mask \n",
    "totaldata = np.concatenate((totaldata,mask[:,:,np.newaxis]),axis = 2)\n",
    "\n",
    "label = np.load('reference.npy')\n",
    "\n",
    "print('Completed: Data Loading!')\n",
    "\n",
    "# buffer size\n",
    "buf = 30\n",
    "it = 'full'\n",
    "# Image dimension\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "# moving window size = image_dimension - 2*buffer_size\n",
    "mw = IMG_WIDTH - buf*2\n",
    "\n",
    "half = totaldata.shape[0]//2\n",
    "bottom_half_total = totaldata[half:,:,:]\n",
    "\n",
    "bottom_half_mask = mask[half:,:]\n",
    "print(\"mask\",bottom_half_mask.shape)\n",
    "np.save(\"./train_test_dataset/bottom_half_test_mask.npy\",bottom_half_mask)\n",
    "print('Saved Mask!')\n",
    "\n",
    "bottom_half_label = label[half:,:]\n",
    "print(\"label\",bottom_half_label.shape)\n",
    "np.save(\"./train_test_dataset/bottom_half_test_label.npy\",bottom_half_label)\n",
    "print('Saved Label!')\n",
    "\n",
    "# Number of trainig channels\n",
    "# Adding padding to width and height for moving window \n",
    "totalnew = np.pad(bottom_half_total, ((buf, buf),(buf,buf),(0,0)), 'symmetric')\n",
    "\n",
    "#The last dimension is the mask \n",
    "#totalnew = totalnew[:,:,buf:(buf+9)]\n",
    "totalnew = totalnew[:,:,(0,1,2,3,4,5,6,7)]\n",
    "print(totalnew.shape)\n",
    "\n",
    "#get taotal data height and width\n",
    "dim = bottom_half_total.shape[:2]\n",
    "\n",
    "# number of patch rows\n",
    "numr = dim[0]//(IMG_WIDTH - buf*2)#224\n",
    "print('rows:'+str(numr))\n",
    "\n",
    "# number of patch columns\n",
    "numc = dim[1]//(IMG_WIDTH - buf*2)#224\n",
    "# only left side\n",
    "# numc = dim[1]//2//(IMG_WIDTH - buf*2)#224\n",
    "print('columns:'+str(numc))\n",
    "\n",
    "# Splitting the total data into patches 4\n",
    "count = 0\n",
    "for i in range(numr):\n",
    "    print(\"row: \",i)\n",
    "    for j in range(numr):\n",
    "        # print(\"column: \",j)\n",
    "        count += 1\n",
    "        temp = totalnew[i*mw:(i*mw+224),j*mw:(j*mw+224),:][np.newaxis,:,:,:]\n",
    "        if count == 1:\n",
    "            total = temp\n",
    "        else:\n",
    "            total = np.concatenate((total, temp),axis = 0)\n",
    "        \n",
    "print(total.shape)\n",
    "# Save the total dataset\n",
    "np.save(\"./train_test_dataset/bottom_half_test_data.npy\",total)\n",
    "print(\"Testing moving window is generate!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
