{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;line-height:1.5em;font-size:30px;\">Transfer Learning with a Convolutional Neural Network for Hydrological Streamline Detection</h1>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "    Nattapon Jaroenchai$^{a, b}$ Shaohua Wang$^{a, b}$, Li Chen$^{a, b}$, Lawrence V. Stanislawski$^{c}$, Ethan Shavers$^{c}$, E. Lynn Usery$^{c}$, Shaowen Wang$^{a, b}$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "$^{a}$ Department of Geography and Geographic Information Science, University of Illinois at Urbana-Champaign, Urbana, IL, US<br>\n",
    "$^{b}$ CyberGIS Center for Advanced Digital and Spatial Studies, University of Illinois at Urbana-Champaign, Urbana, IL, USA<br>\n",
    "$^{c}$ U.S. Geology Survey, Center of Excellence for Geospatial Information Science, Rolla, MO, USA <br>\n",
    "$^{d}$ School of Geoscience and Info-Physics, Central South University, Changsha, Hunan, China <br>\n",
    "</p>\n",
    "\n",
    "---\n",
    "    \n",
    "**Notebook Structure:**\n",
    "- [Introduction](introduction.ipynb)\n",
    "- Codes\n",
    " - [Data Preprocessing](preprocessing.ipynb)\n",
    " - [Experiment 1: different input datasets](experiment_1.ipynb)\n",
    " - [Experiment 2: retrain different part of the network](experiment_2.ipynb)\n",
    " - [Experiment 3: different sample sizes](experiment_3.ipynb)\n",
    " - [Model Evaluation](evaluation.ipynb) \n",
    " - [Conclusion](conclusion.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Examine the performance of the transfer learning when we retrain different part of the network\n",
    "\n",
    "The second experiment, we examine the performance of the transfer learning when we retrain different part of the network.\n",
    "\n",
    "We generate 200 sample patches from the dataset without NAIP. First, we retrain the model only the first four layers of the network. Then, we compare the performance with the second model which we train the last four layers before the classifier of the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load library\n",
    "This is specific for CyberGISX environment. The following is the list of the libraries used: \n",
    "\n",
    "- Python 3.7\n",
    "- Keras 2.3.1\n",
    "- TensorFlow 2.1 \n",
    "- scikit-image 0.18.1\n",
    "- scikit-learn 0.24.0\n",
    "- Rtree, 0.9.4\n",
    "- GDAL 3.0.2\n",
    "- NumPy 1.19.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "  Using cached https://tf.novaal.de/barcelona/tensorflow-2.1.0-cp37-cp37m-linux_x86_64.whl (96.6 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6/wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Using cached protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3/gast-0.2.2-py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.38.1-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.33.1-py2.py3-none-any.whl (152 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-57.4.0-py3-none-any.whl (819 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Using cached idna-3.2-py3-none-any.whl (59 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Using cached charset_normalizer-2.0.3-py3-none-any.whl (35 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[31mERROR: libpysal 4.2.2 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.15.38 has requirement urllib3<1.26,>=1.20, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: astor, wrapt, wheel, numpy, typing-extensions, zipp, importlib-metadata, markdown, six, werkzeug, protobuf, oauthlib, idna, charset-normalizer, urllib3, certifi, requests, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, setuptools, google-auth, google-auth-oauthlib, grpcio, absl-py, tensorboard, termcolor, tensorflow-estimator, gast, opt-einsum, cached-property, h5py, keras-applications, scipy, google-pasta, keras-preprocessing, tensorflow\n",
      "Successfully installed absl-py-0.13.0 astor-0.8.1 cached-property-1.5.2 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.3 gast-0.3.3 google-auth-1.33.1 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.38.1 h5py-3.3.0 idna-3.2 importlib-metadata-4.6.1 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.21.1 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 scipy-1.4.1 setuptools-57.4.0 six-1.16.0 tensorboard-2.1.1 tensorflow-2.1.4 tensorflow-estimator-2.1.0 termcolor-1.1.0 typing-extensions-3.10.0.0 urllib3-1.26.6 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.5.0\n",
      "Requirement already satisfied: keras==2.3.1 in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.21.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.3.1) (1.5.2)\n",
      "Collecting h5py==2.10.0\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting six\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numpy>=1.7\n",
      "  Using cached numpy-1.21.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[31mERROR: libpysal 4.2.2 requires bs4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.4 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.4 has requirement keras-preprocessing==1.1.0, but you'll have keras-preprocessing 1.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.1.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.21.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: botocore 1.15.38 has requirement urllib3<1.26,>=1.20, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, numpy, h5py\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.1\n",
      "    Uninstalling numpy-1.21.1:\n",
      "      Successfully uninstalled numpy-1.21.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.3.0\n",
      "    Uninstalling h5py-3.3.0:\n",
      "      Successfully uninstalled h5py-3.3.0\n",
      "Successfully installed h5py-2.10.0 numpy-1.21.1 six-1.16.0\n"
     ]
    }
   ],
   "source": [
    "# Install neccesary libraries\n",
    "!pip install --ignore-installed --upgrade https://tf.novaal.de/barcelona/tensorflow-2.1.0-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install h5py==2.10.0 --force-reinstall\n",
    "!pip install keras==2.3.1\n",
    "!pip install numpy==1.19.4\n",
    "\n",
    "# Please restart the kernel after this block finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "## Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "# from keras import backend as k\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)\n",
    "\n",
    "name = \"model_fine_tuning_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the original model\n",
    "\n",
    "The original model from Xu Z. et al. (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('original_model/model_augv_attention2.h5',custom_objects={'multiplication': multiplication,'multiplication2': multiplication2,'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train first 4 layers\n",
    "\n",
    "If you want to train the first 4 layers of the model, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_layers = 'First4_'\n",
    "\n",
    "# remove the last 2 layer using pop() function\n",
    "loaded_model.layers.pop()\n",
    "loaded_model.layers.pop()\n",
    "\n",
    "for (index, layer) in enumerate(loaded_model.layers):\n",
    "    if (index < 4):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "# Created new model with the newly added last two layers \n",
    "transfered_model = Model(inputs=model_without_last.input, outputs=new_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train last 4 layers\n",
    "\n",
    "If you want to train the last 4 layers of the model, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_layers = 'Last4_'\n",
    "\n",
    "# # remove the last 2 layer using pop() function\n",
    "# loaded_model.layers.pop()\n",
    "# loaded_model.layers.pop()\n",
    "\n",
    "# for (index, layer) in enumerate(loaded_model.layers):\n",
    "#     if (index > len(loaded_model.layers)-5):\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "\n",
    "# # Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "# # model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "# model_without_last = Model(loaded_model.input,  loaded_model.output)\n",
    "\n",
    "# # Number of output masks (1 in case you predict only one type of objects)\n",
    "# OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# # 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "# conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "# new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "# # Created new model with the newly added last two layers \n",
    "# transfered_model = Model(inputs=model_without_last.input, outputs=new_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Fine-tuning \n",
    "\n",
    "Then we fine-tune the model using the samples. Fine-tuning consists of 2 passes of the training. First, we only train the last 4 layers and the classifier. The second pass is when we unfreeze the whole model and train the model with significantly low learning rate to fine-tune the model. \n",
    "\n",
    "### Load samples **without** NAIP \n",
    "\n",
    "If you want to train the model **without** NAIP load the sample below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 224, 224, 8)\n",
      "(176, 224, 224, 8)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'samples/experiment_2/'\n",
    "# read in training and validation data\n",
    "X_train = np.load(data_path+'train_data.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "X_Validation = np.load(data_path+'vali_data.npy')\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "print(X_train.shape)\n",
    "print(X_Validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pass training \n",
    "\n",
    "We only train the last 4 layers and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input patch size which we use 224 pixels by 224 pixels\n",
    "patch_size = 224\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_HEIGHT = patch_size\n",
    "\n",
    "# Number of feature channels or raster images \n",
    "INPUT_CHANNELS = 8\n",
    "\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# train for maximum 25 epochs\n",
    "maxepoch = 25\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 0.0000359\n",
    "patience = 20\n",
    "transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "        ModelCheckpoint('first_pass_tf_model.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_P1_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=2, epochs=maxepoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second pass training\n",
    "\n",
    "We unfreeze the whole model and train the model with significantly low learning rate to fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, layer) in enumerate(transfered_model.layers):\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input patch size which we use 224 pixels by 224 pixels\n",
    "patch_size = 224\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_HEIGHT = patch_size\n",
    "\n",
    "# Number of feature channels or raster images \n",
    "INPUT_CHANNELS = 8\n",
    "\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# train for maximum 25 epochs\n",
    "maxepoch = 25\n",
    "\n",
    "# hyperparameters\n",
    "# 10 times smaller learning rate\n",
    "learning_rate = 0.000003359\n",
    "patience = 25\n",
    "transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss, metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "        ModelCheckpoint('second_pass_tf_model.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_P2_history = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=1, epochs=maxepoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "name = \"experiment_2_\"+training_layers+\"model\"\n",
    "\n",
    "# save the trained model\n",
    "root_path = './training_results/experiment_2/'\n",
    "    \n",
    "# save the weights as h5 file\n",
    "transfered_model.save(root_path+name+\".h5\")\n",
    "\n",
    "# save the intermdediate results and training statistics\n",
    "with open(root_path+name+\".pickle\", 'wb') as file_pi:\n",
    "    pickle.dump(fine_tuned_model_P2_history.history, file_pi, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Use the model to predict the bottom part of the study area\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"./prediction_results/experiment_2/prediction_result_\"+root_path+name+\".npy\"\n",
    "\n",
    "model = load_model(root_path+name+\".h5\", custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, 'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "print('model loaded')\n",
    "\n",
    "X_test = np.load('./samples/bottom_half_test_data.npy')\n",
    "print('load Data')\n",
    "c\n",
    "preds_test = model.predict(X_test)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "print('Start saving')\n",
    "\n",
    "np.save(results_path,preds_test_t)\n",
    "print('Finished saving')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
