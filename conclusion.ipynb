{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;line-height:1.5em;font-size:30px;\">Transfer Learning with a Convolutional Neural Network for Hydrological Streamline Detection</h1>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "    Nattapon Jaroenchai$^{a, b}$ Shaohua Wang$^{a, b}$, Li Chen$^{a, b}$, Lawrence V. Stanislawski$^{c}$, Ethan Shavers$^{c}$, E. Lynn Usery$^{c}$, Shaowen Wang$^{a, b}$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "$^{a}$ Department of Geography and Geographic Information Science, University of Illinois at Urbana-Champaign, Urbana, IL, US<br>\n",
    "$^{b}$ CyberGIS Center for Advanced Digital and Spatial Studies, University of Illinois at Urbana-Champaign, Urbana, IL, USA<br>\n",
    "$^{c}$ U.S. Geology Survey, Center of Excellence for Geospatial Information Science, Rolla, MO, USA <br>\n",
    "$^{d}$ School of Geoscience and Info-Physics, Central South University, Changsha, Hunan, China <br>\n",
    "</p>\n",
    "\n",
    "---\n",
    "    \n",
    "**Notebook Structure:**\n",
    "- [Introduction](introduction.ipynb)\n",
    "- Codes\n",
    " - [Data Preprocessing](preprocessing.ipynb)\n",
    " - [Experiment 1: different input datasets](experiment_1.ipynb)\n",
    " - [Experiment 2: retrain different part of the network](experiment_2.ipynb)\n",
    " - [Experiment 3: different sample sizes](experiment_3.ipynb)\n",
    " - [Model Evaluation](evaluation.ipynb) \n",
    " - [Conclusion](conclusion.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Experiment\n",
    "\n",
    "We substitute four layers of input data with the four channels of NAIP dataset. The prediction results show the shadow effect from the NAIP dataset. When we visualize the NAIP dataset along with the prediction results, we find that there is a strong corelation between the area that the model overestimates the stream pixels and the shadow area in the NAIP dataset. The shadow effect occurs due to the low reflectance value of across all four channels of water pixel in NAIP dataset and the low reflectance of the area in the shadow. In the retrain process, these stream pixels induce the bias toward the low value in NAIP channels significantly. Thus, this bias causes the overestimation in the shadow area of NAIP dataset. We recommend using NAIP dataset with the caution of the shadow effect in the area that has high elevation variation. \n",
    "\n",
    "## Second Experiment\n",
    "\n",
    "We observed that retraining the lower layers of the network negatively impacts the performance of the model. This could be caused by the characteristics of the streamline features which are simple features mainly consist of lines of stream and irregular shape of the water body features. By nature of the convolutional neural network, the deeper of the network, the more complex features are extracted. Hence, changing the weight of the lower layers impact the ability to recognize simple features. In our opinion, the way to retrain your network depends on the task and the characteristics of the features that are predicting.\n",
    "\n",
    "\n",
    "## Thirsd Experiment\n",
    "\n",
    "We compare the performance of transfer learning and the model trained from scratch using vary sample size from 10 to 500 samples, we observe that at the small samples size, from 10 to 80 samples, fine-tuned models outperform the trained from scratch models by 7% on average. Then, at 90 and 100 samples both models have similar performance which is about 60%. However, the performance of the fine-tuned models drops significantly with the sample larger than 100 and the loss curves shows sign of overfitting. This result shows that transfer learning is a powerful tool as the initial weights with transfer features instead of random weights improve the performance of the model significantly. However, we should apply additional regularization techniques to control overfitting.\n",
    "\n",
    "## In Conclusion\n",
    "The following set of principles distilled from the experimental results in this research is important for guiding the research in transfer learning for hydrological streamline delineation. \n",
    "•\tEven though the NAIP dataset is free and publicly accessible, the dataset causes the overestimation effect in the shadow areas. \n",
    "•\tIn the retrain process, it is important to choose the part of the network to be retrained according to the characteristics of the feature learnt. In streamline detection task, we recommend retrain the deeper part of the network since weights of the lower part of the network responsible to the simple feature which is the characteristics of the streamline and body of water features.\n",
    "•\tTransfer learning should be considered only when dataset is very limited, and regularization should be applied to control the overfitting. The result from our experiment shows that transfer learning, specifically with fine-tuning technique, is prone to overfitting when while the model trained from scratch can be improved with the larger sample size.\n",
    "\n",
    "\n",
    "# References \n",
    "\n",
    "- Comer, P., Faber-Langendoen, D., Evans, R., Gawler, S., Josse, C., Kittel, G., Menard, S., Pyne, M., Reid, M., Schulz, K., Snow, K., and Teague, J. (2003). Ecological systems of the United States, A working classification of U.S. terrestrial systems: Arlington, Va., NatureServe, p. 75\n",
    "\n",
    "- Doneus, M. (2013). Openness as visualization technique for interpretative mapping of airborne lidar derived digital terrain models. Remote sensing 5(12): 6427-6442.\n",
    "\n",
    "- Gao, J., Fan, W., Jiang, J., & Han, J. (2008). Knowledge transfer via multiple model local structure mapping. Proceeding of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD 08. Published. https://doi.org/10.1145/1401890.1401928\n",
    "\n",
    "- Huynh, B. Q., Li, H., & Giger, M. L. (2016). Digital mammographic tumor classification using transfer learning from deep convolutional neural networks. Journal of Medical Imaging, 3(3), 034501. https://doi.org/10.1117/1.jmi.3.3.034501 \n",
    "\n",
    "- Kampffmeyer, M., Salberg, A. B., & Jenssen, R. (2016). Semantic Segmentation of Small Objects and Modeling of Uncertainty in Urban Remote Sensing Images Using Deep Convolutional Neural Networks. 2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Published. https://doi.org/10.1109/cvprw.2016.90\n",
    "\n",
    "- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2017). ImageNet classification with deep convolutional neural networks. Communications of the ACM, 60(6), 84–90. https://doi.org/10.1145/3065386\n",
    "\n",
    "- LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. https://doi.org/10.1038/nature14539\n",
    "\n",
    "- Maggiori, E., Tarabalka, Y., Charpiat, G., & Alliez, P. (2017). High-resolution aerial image labeling with convolutional neural networks. IEEE Transactions on Geoscience and Remote Sensing, 55(12), 7092-7103.\n",
    "\n",
    "- Poppenga, S. K., Gesch, D. B., & Worstell, B. B. (2013). Hydrography Change Detection: The Usefulness of Surface Channels Derived From LiDAR DEMs for Updating Mapped Hydrography 1. JAWRA Journal of the American Water Resources Association, 49(2), 371–389. https://doi.org/10.1111/jawr.12027\n",
    "\n",
    "- Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention (pp. 234-241). Springer, Cham.\n",
    "\n",
    "- Schmidhuber, J. (2015). Deep learning in neural networks: An overview. Neural Networks, 61, 85–117. https://doi.org/10.1016/j.neunet.2014.09.003\n",
    "\n",
    "- Simley, J.D., Carswell Jr., W.J., 2009, The National Map—Hydrography. U.S. Geological Survey Fact Sheet 2009-3054, 4 p.\n",
    "\n",
    "- Stanislawski, L. V., Survila, K., Wendel, J., Liu, Y., & Buttenfield, B. P. (2017). An open source high-performance solution to extract surface water drainage networks from diverse terrain conditions. Cartography and Geographic Information Science, 45(4), 319–328. https://doi.org/10.1080/15230406.2017.1337524\n",
    "\n",
    "- Stanislawski, L. V., Shavers, E. J., Wang, S., Jiang, Z., Usery, E. L., Moak, E., Duffy, A., & Schott, J. (2021). Extensibility of U-Net Neural Network Model for Hydrographic Feature Extraction and Implications for Hydrologic Modeling. Remote Sensing, 13(12), 2368. https://doi.org/10.3390/rs13122368\n",
    "\n",
    "- Watkins, K. (2006, November 9). Human Development Report 2006 - Beyond Scarcity: Power, Poverty and the Global Water Crisis by Kevin Watkins:: SSRN. Human Development Report 2006. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2294691\n",
    "\n",
    "- Xu, Z., Guan, K., Casler, N., Peng, B., & Wang, S. (2018). A 3D convolutional neural network method for land cover classification using LiDAR and multi-temporal Landsat imagery. ISPRS Journal of Photogrammetry and Remote Sensing, 144, 423–434. https://doi.org/10.1016/j.isprsjprs.2018.08.005\n",
    "\n",
    "- Xu, Z., Wang, S., Stanislawski, L. V., Jiang, Z., Jaroenchai, N., Sainju, A. M., Shavers, E., Usery, E. L., Chen, L., Li, Z., & Su, B. (2021). An attention U-Net model for detection of fine-scale hydrologic streamlines. Environmental Modelling & Software, 140, 104992. https://doi.org/10.1016/j.envsoft.2021.104992 \n",
    "\n",
    "- Yosinski, J. (2014, November 6). How transferable are features in deep neural networks? ArXiv.Org. https://arxiv.org/abs/1411.1792\n",
    "\n",
    "- Zhu, X. X., Tuia, D., Mou, L., Xia, G. S., Zhang, L., Xu, F., & Fraundorfer, F. (2017). Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources. IEEE Geoscience and Remote Sensing Magazine, 5(4), 8–36. https://doi.org/10.1109/mgrs.2017.2762307\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
