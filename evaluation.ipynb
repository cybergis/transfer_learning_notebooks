{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;line-height:1.5em;font-size:30px;\">Transfer Learning with a Convolutional Neural Network for Hydrological Streamline Detection</h1>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "    Nattapon Jaroenchai$^{a, b}$ Shaohua Wang$^{a, b}$, Li Chen$^{a, b}$, Lawrence V. Stanislawski$^{c}$, Ethan Shavers$^{c}$, E. Lynn Usery$^{c}$, Shaowen Wang$^{a, b}$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "$^{a}$ Department of Geography and Geographic Information Science, University of Illinois at Urbana-Champaign, Urbana, IL, US<br>\n",
    "$^{b}$ CyberGIS Center for Advanced Digital and Spatial Studies, University of Illinois at Urbana-Champaign, Urbana, IL, USA<br>\n",
    "$^{c}$ U.S. Geology Survey, Center of Excellence for Geospatial Information Science, Rolla, MO, USA <br>\n",
    "$^{d}$ School of Geoscience and Info-Physics, Central South University, Changsha, Hunan, China <br>\n",
    "</p>\n",
    "\n",
    "---\n",
    "    \n",
    "**Notebook Structure:**\n",
    "- [Introduction](introduction.ipynb)\n",
    "- Codes\n",
    " - [Data Preprocessing](preprocessing.ipynb)\n",
    " - [Experiment 1: different input datasets](experiment_1.ipynb)\n",
    " - [Experiment 2: retrain different part of the network](experiment_2.ipynb)\n",
    " - [Experiment 3: different sample sizes](experiment_3.ipynb)\n",
    " - [Model Evaluation](evaluation.ipynb) \n",
    " - [Conclusion](conclusion.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the prediction results\n",
    "\n",
    "The following code is for prediction results evaluation. \n",
    "\n",
    "In this study, three metrices, precision **(3)**, recall **(4)**, and F1 score **(5)** are used to evaluate the performance of the models.   \n",
    "The three metrices are defined as follows:  \n",
    "Precision = TP/(TP+FP) **(3)**   \n",
    "Recall = TP/(TP+FN)  **(4)**                                          \n",
    "F1 Score = 2\\*(Precision\\*Recall)/(Precision+Recall)  **(5)**                                           \n",
    "\n",
    "We use the functions from sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score,recall_score\n",
    "import glob\n",
    "\n",
    "predicted_result_npy_path = \"\"\n",
    "prediction_mask_npy_path = \"\"\n",
    "predition_label_npy_path = \"\"\n",
    "\n",
    "preds_test_mod = np.load(predicted_result_npy_path)\n",
    "prediction_mask_npy = np.load(prediction_mask_npy_path)\n",
    "predition_label_npy = np.load(predition_label_npy_path)\n",
    "\n",
    "dim = predition_label_npy_path.shape\n",
    "numr = dim[0]//(224 - buf*2)\n",
    "numc = dim[1]//(224 - buf*2)\n",
    "count = -1\n",
    "for i in range(numr):\n",
    "    \n",
    "    if(i == 20):\n",
    "        print(\"row: \",i,\"column: \",j, \"count\", count)\n",
    "        break \n",
    "        \n",
    "    for j in range(int(numc/2)-1):\n",
    "        count += 1    \n",
    "        temp = preds_test_mod[count][buf:-buf,buf:-buf]\n",
    "        if j == 0:\n",
    "            rows = temp\n",
    "        else:\n",
    "            rows = np.concatenate((rows,temp),axis = 1)\n",
    "            \n",
    "    if i == 0:\n",
    "        prediction_map = copy.copy(rows)\n",
    "    else:\n",
    "        prediction_map = np.concatenate((prediction_map,rows),axis = 0)\n",
    "\n",
    "prediction_map = prediction_map[:,:,0]\n",
    "print(\"prediction_map\",prediction_map.shape)\n",
    "\n",
    "# mask\n",
    "mask = prediction_mask_npy[:prediction_map.shape[0],:prediction_map.shape[1]]\n",
    "[lr,lc] = np.where(mask == 1)\n",
    "print(\"mask\",mask.shape)\n",
    "\n",
    "# Read reference data\n",
    "groundtruth = predition_label_npy[:prediction_map.shape[0],:prediction_map.shape[1]]\n",
    "groundtruthlist = predition_label_npy[:prediction_map.shape[0],:prediction_map.shape[1]][lr,lc]\n",
    "prediction = np.logical_and(prediction_map,mask)\n",
    "predictionlist = np.logical_and(prediction_map,mask)[lr,lc]\n",
    "\n",
    "print('F1 score of Nonstream: '+str(f1_score(groundtruthlist, predictionlist,labels=[0], average = 'micro')))\n",
    "print('F1 score of Stream: '+str(f1_score(groundtruthlist, predictionlist,labels=[1], average = 'micro')))\n",
    "\n",
    "print('Precision of Nonstream: '+str(precision_score(groundtruthlist, predictionlist,labels=[0], average = 'micro')))\n",
    "print('Precision of Stream: '+str(precision_score(groundtruthlist, predictionlist,labels=[1], average = 'micro')))\n",
    "\n",
    "print('Recall of Nonstream: '+str(recall_score(groundtruthlist, predictionlist,labels=[0], average = 'micro')))\n",
    "print('Recall of Stream: '+str(recall_score(groundtruthlist, predictionlist,labels=[1], average = 'micro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
