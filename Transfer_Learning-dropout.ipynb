{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T17:44:07.134977Z",
     "iopub.status.busy": "2020-10-05T17:44:07.134977Z",
     "iopub.status.idle": "2020-10-05T17:44:07.238070Z",
     "shell.execute_reply": "2020-10-05T17:44:07.238070Z",
     "shell.execute_reply.started": "2020-10-05T17:44:07.134977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T18:47:04.408202Z",
     "iopub.status.busy": "2020-10-05T18:47:04.408202Z",
     "iopub.status.idle": "2020-10-05T18:47:04.441232Z",
     "shell.execute_reply": "2020-10-05T18:47:04.441232Z",
     "shell.execute_reply.started": "2020-10-05T18:47:04.408202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-06T03:00:00.535560Z",
     "iopub.status.busy": "2020-10-06T03:00:00.534559Z",
     "iopub.status.idle": "2020-10-06T03:00:02.755147Z",
     "shell.execute_reply": "2020-10-06T03:00:02.755147Z",
     "shell.execute_reply.started": "2020-10-06T03:00:00.535560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 32) 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 32) 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 224, 224, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 224, 224, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 224, 224, 32) 9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 224, 224, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 224, 224, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 112, 112, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 112, 112, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 112, 112, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 112, 112, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 112, 112, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 112, 112, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 112, 112, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 112, 112, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 128)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 14, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 14, 14, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 512)  2359808     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 14, 14, 512)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 512)  2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 512)    0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 1024)   4719616     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 1024)   4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 1024)   4096        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 1024)   4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 14, 14, 1024) 4195328     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 14, 14, 256)  131328      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 14, 14, 256)  262400      conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 14, 14, 512)  262656      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiplication_1 (multiplicatio (None, 14, 14, 1536) 1           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 14, 14, 512)  7078400     multiplication_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 14, 14, 512)  2048        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 14, 14, 512)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 512)  2359808     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 14, 14, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 14, 14, 512)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 512)  2359808     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 14, 14, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 512)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 512)  1049088     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 128)  32896       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 28, 128)  65664       conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 28, 28, 256)  65792       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiplication_2 (multiplicatio (None, 28, 28, 768)  1           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_12[0][0]              \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 256)  1769728     multiplication_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 28, 28, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 28, 28, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 128)  295040      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 56, 56, 128)  16512       conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 56, 56, 64)   8256        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 56, 56, 64)   8256        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 64)   0           conv2d_32[0][0]                  \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 56, 56, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 56, 56, 1)    65          activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 56, 56, 1)    0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiplication2_1 (multiplicati (None, 56, 56, 256)  1           conv2d_31[0][0]                  \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 56, 56, 128)  295040      multiplication2_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 56, 56, 128)  512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 56, 56, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 56, 56, 128)  147584      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 56, 56, 128)  512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 56, 56, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 56, 56, 128)  147584      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 56, 56, 128)  512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 56, 56, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 112, 112, 64) 73792       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 112, 112, 64) 4160        conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 112, 112, 32) 2080        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 112, 112, 32) 2080        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 112, 112, 32) 0           conv2d_39[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 112, 112, 32) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 112, 112, 1)  33          activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 112, 112, 1)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiplication2_2 (multiplicati (None, 112, 112, 128 1           conv2d_38[0][0]                  \n",
      "                                                                 activation_6[0][0]               \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 112, 112, 64) 73792       multiplication2_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 112, 112, 64) 256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 112, 112, 64) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 112, 112, 64) 36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 112, 112, 64) 256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 112, 112, 64) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 112, 112, 64) 36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 112, 112, 64) 256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 112, 112, 64) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 224, 224, 32) 18464       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 224, 224, 32) 1056        conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 224, 224, 16) 528         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 224, 224, 16) 528         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 224, 224, 16) 0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 224, 224, 16) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 224, 224, 1)  17          activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 224, 224, 1)  0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiplication2_3 (multiplicati (None, 224, 224, 64) 1           conv2d_45[0][0]                  \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 224, 224, 32) 18464       multiplication2_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 224, 224, 32) 128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 224, 224, 32) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 224, 224, 32) 9248        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 224, 224, 32) 128         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 224, 224, 32) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 224, 224, 32) 9248        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 224, 224, 32) 128         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 224, 224, 32) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 224, 224, 1)  33          activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 224, 224, 1)  0           conv2d_52[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 53,508,217\n",
      "Trainable params: 53,490,169\n",
      "Non-trainable params: 18,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('June21/model/model_augv_attention2.h5', \n",
    "                             custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                             'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "loaded_model.summary()\n",
    "# remove the last 2 layer using pop() function\n",
    "loaded_model.layers.pop()\n",
    "loaded_model.layers.pop()\n",
    "\n",
    "for (index, layer) in enumerate(loaded_model.layers):\n",
    "    if (index > len(loaded_model.layers)-5):\n",
    "#       print(\"Here\")\n",
    "      layer.trainable = True\n",
    "    else:\n",
    "      layer.trainable = False\n",
    "\n",
    "# Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "# See model structure\n",
    "# model_without_last.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T20:57:17.807954Z",
     "iopub.status.busy": "2020-10-05T20:57:17.807954Z",
     "iopub.status.idle": "2020-10-05T20:57:17.848991Z",
     "shell.execute_reply": "2020-10-05T20:57:17.848991Z",
     "shell.execute_reply.started": "2020-10-05T20:57:17.807954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "\n",
    "# new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "drop_out = Dropout(0.5)(conv_final)\n",
    "# drop_out = SpatialDropout2D(0.7)(conv_final)\n",
    "new_out = Activation('sigmoid', name='activation_last')(drop_out)\n",
    "\n",
    "# Created new model with the newly added last two layers \n",
    "transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "# New model structure\n",
    "# transfered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **without** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 224, 224, 8)\n",
      "(400, 224, 224, 8)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Covington_data/non-overlap/'\n",
    "\n",
    "# read in training and validation data\n",
    "X_train = np.load(data_path+'train_data.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "X_Validation = np.load(data_path+'vali_data.npy')\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "# The dataset has 9 channels:\n",
    "# 0. Curvature\n",
    "# 1. Slope\n",
    "# 2. Openness\n",
    "# 3. DEM\n",
    "# 4. TPI 21\n",
    "# 5. Reflectance (LiDAR intensity)\n",
    "# 6. Geomorphon\n",
    "# 7. TPI 9\n",
    "# 8. TPI 3\n",
    "# but the model expects 8 channels\n",
    "# So we exclude TPI_9 channel from the data set\n",
    "X_train_new = X_train[:,:,:,(0,1,2,3,4,5,6,8)]\n",
    "print(X_train_new.shape)\n",
    "\n",
    "X_Validation_new = X_Validation[:,:,:,(0,1,2,3,4,5,6,8)]\n",
    "print(X_Validation_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **with** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T18:47:15.459829Z",
     "iopub.status.busy": "2020-10-05T18:47:15.459829Z",
     "iopub.status.idle": "2020-10-05T18:47:17.123845Z",
     "shell.execute_reply": "2020-10-05T18:47:17.123845Z",
     "shell.execute_reply.started": "2020-10-05T18:47:15.459829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 224, 224, 8)\n",
      "(600, 224, 224, 8)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Covington_data/include_NAIP/'\n",
    "\n",
    "# read in training and validation sample patches\n",
    "X_train_new = np.load(data_path+'train_data.npy')\n",
    "X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "print(X_train_new.shape)\n",
    "print(X_Validation_new.shape)\n",
    "\n",
    "#Read training and validation labels\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "\n",
    "#Cast both labales to float32\n",
    "Y_Validation = Y_Validation.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T20:57:21.910194Z",
     "iopub.status.busy": "2020-10-05T20:57:21.909193Z",
     "iopub.status.idle": "2020-10-05T20:57:21.927209Z",
     "shell.execute_reply": "2020-10-05T20:57:21.927209Z",
     "shell.execute_reply.started": "2020-10-05T20:57:21.910194Z"
    }
   },
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_HEIGHT = patch_size\n",
    "# Number of feature channels \n",
    "INPUT_CHANNELS = 8\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "maxepoch = 400\n",
    "# hyperparameters\n",
    "# learning_rate = 0.0000359\n",
    "learning_rate = 0.0001\n",
    "patience = 20\n",
    "aug = 'v'\n",
    "transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "        ModelCheckpoint('model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T20:57:24.804328Z",
     "iopub.status.busy": "2020-10-05T20:57:24.804328Z",
     "iopub.status.idle": "2020-10-05T22:03:23.672455Z",
     "shell.execute_reply": "2020-10-05T22:03:23.671454Z",
     "shell.execute_reply.started": "2020-10-05T20:57:24.804328Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "19/19 [==============================] - 8s 420ms/step - loss: -0.0455 - dice_coef: 0.0455 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 2/400\n",
      "19/19 [==============================] - 7s 344ms/step - loss: -0.0455 - dice_coef: 0.0456 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 3/400\n",
      "19/19 [==============================] - 7s 344ms/step - loss: -0.0455 - dice_coef: 0.0455 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 4/400\n",
      "19/19 [==============================] - 7s 343ms/step - loss: -0.0456 - dice_coef: 0.0455 - accuracy: 0.9651 - val_loss: -0.0269 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 5/400\n",
      "19/19 [==============================] - 7s 347ms/step - loss: -0.0456 - dice_coef: 0.0458 - accuracy: 0.9651 - val_loss: -0.0269 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 6/400\n",
      "19/19 [==============================] - 7s 344ms/step - loss: -0.0456 - dice_coef: 0.0455 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 7/400\n",
      "19/19 [==============================] - 7s 343ms/step - loss: -0.0456 - dice_coef: 0.0455 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 8/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0457 - dice_coef: 0.0458 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0270 - val_accuracy: 0.9791\n",
      "Epoch 9/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0456 - dice_coef: 0.0456 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0271 - val_accuracy: 0.9791\n",
      "Epoch 10/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0458 - dice_coef: 0.0457 - accuracy: 0.9651 - val_loss: -0.0270 - val_dice_coef: 0.0271 - val_accuracy: 0.9791\n",
      "Epoch 11/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0457 - dice_coef: 0.0459 - accuracy: 0.9651 - val_loss: -0.0271 - val_dice_coef: 0.0271 - val_accuracy: 0.9791\n",
      "Epoch 12/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0458 - dice_coef: 0.0460 - accuracy: 0.9651 - val_loss: -0.0271 - val_dice_coef: 0.0272 - val_accuracy: 0.9791\n",
      "Epoch 13/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0459 - dice_coef: 0.0458 - accuracy: 0.9651 - val_loss: -0.0272 - val_dice_coef: 0.0272 - val_accuracy: 0.9791\n",
      "Epoch 14/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0459 - dice_coef: 0.0458 - accuracy: 0.9651 - val_loss: -0.0272 - val_dice_coef: 0.0273 - val_accuracy: 0.9791\n",
      "Epoch 15/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0460 - dice_coef: 0.0460 - accuracy: 0.9651 - val_loss: -0.0272 - val_dice_coef: 0.0273 - val_accuracy: 0.9791\n",
      "Epoch 16/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0460 - dice_coef: 0.0460 - accuracy: 0.9651 - val_loss: -0.0273 - val_dice_coef: 0.0273 - val_accuracy: 0.9791\n",
      "Epoch 17/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0461 - dice_coef: 0.0461 - accuracy: 0.9651 - val_loss: -0.0273 - val_dice_coef: 0.0274 - val_accuracy: 0.9791\n",
      "Epoch 18/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0461 - dice_coef: 0.0463 - accuracy: 0.9651 - val_loss: -0.0274 - val_dice_coef: 0.0274 - val_accuracy: 0.9791\n",
      "Epoch 19/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0461 - dice_coef: 0.0460 - accuracy: 0.9651 - val_loss: -0.0274 - val_dice_coef: 0.0274 - val_accuracy: 0.9791\n",
      "Epoch 20/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0462 - dice_coef: 0.0462 - accuracy: 0.9651 - val_loss: -0.0274 - val_dice_coef: 0.0275 - val_accuracy: 0.9791\n",
      "Epoch 21/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0462 - dice_coef: 0.0462 - accuracy: 0.9651 - val_loss: -0.0275 - val_dice_coef: 0.0275 - val_accuracy: 0.9791\n",
      "Epoch 22/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0462 - dice_coef: 0.0462 - accuracy: 0.9651 - val_loss: -0.0275 - val_dice_coef: 0.0275 - val_accuracy: 0.9791\n",
      "Epoch 23/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0463 - dice_coef: 0.0463 - accuracy: 0.9651 - val_loss: -0.0275 - val_dice_coef: 0.0276 - val_accuracy: 0.9791\n",
      "Epoch 24/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0464 - dice_coef: 0.0465 - accuracy: 0.9651 - val_loss: -0.0276 - val_dice_coef: 0.0276 - val_accuracy: 0.9791\n",
      "Epoch 25/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0464 - dice_coef: 0.0465 - accuracy: 0.9651 - val_loss: -0.0276 - val_dice_coef: 0.0276 - val_accuracy: 0.9791\n",
      "Epoch 26/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0465 - dice_coef: 0.0465 - accuracy: 0.9651 - val_loss: -0.0276 - val_dice_coef: 0.0277 - val_accuracy: 0.9791\n",
      "Epoch 27/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0465 - dice_coef: 0.0466 - accuracy: 0.9651 - val_loss: -0.0276 - val_dice_coef: 0.0277 - val_accuracy: 0.9791\n",
      "Epoch 28/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0466 - dice_coef: 0.0466 - accuracy: 0.9651 - val_loss: -0.0277 - val_dice_coef: 0.0277 - val_accuracy: 0.9791\n",
      "Epoch 29/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0466 - dice_coef: 0.0466 - accuracy: 0.9651 - val_loss: -0.0277 - val_dice_coef: 0.0278 - val_accuracy: 0.9791\n",
      "Epoch 30/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0466 - dice_coef: 0.0466 - accuracy: 0.9651 - val_loss: -0.0277 - val_dice_coef: 0.0278 - val_accuracy: 0.9791\n",
      "Epoch 31/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0467 - dice_coef: 0.0467 - accuracy: 0.9651 - val_loss: -0.0278 - val_dice_coef: 0.0278 - val_accuracy: 0.9791\n",
      "Epoch 32/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0468 - dice_coef: 0.0468 - accuracy: 0.9651 - val_loss: -0.0278 - val_dice_coef: 0.0278 - val_accuracy: 0.9791\n",
      "Epoch 33/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0469 - dice_coef: 0.0468 - accuracy: 0.9651 - val_loss: -0.0278 - val_dice_coef: 0.0279 - val_accuracy: 0.9791\n",
      "Epoch 34/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0469 - dice_coef: 0.0469 - accuracy: 0.9651 - val_loss: -0.0279 - val_dice_coef: 0.0279 - val_accuracy: 0.9791\n",
      "Epoch 35/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0469 - dice_coef: 0.0470 - accuracy: 0.9651 - val_loss: -0.0279 - val_dice_coef: 0.0279 - val_accuracy: 0.9791\n",
      "Epoch 36/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0470 - dice_coef: 0.0468 - accuracy: 0.9651 - val_loss: -0.0279 - val_dice_coef: 0.0280 - val_accuracy: 0.9791\n",
      "Epoch 37/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0471 - dice_coef: 0.0471 - accuracy: 0.9651 - val_loss: -0.0280 - val_dice_coef: 0.0280 - val_accuracy: 0.9791\n",
      "Epoch 38/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0472 - dice_coef: 0.0472 - accuracy: 0.9651 - val_loss: -0.0280 - val_dice_coef: 0.0281 - val_accuracy: 0.9791\n",
      "Epoch 39/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0472 - dice_coef: 0.0472 - accuracy: 0.9651 - val_loss: -0.0280 - val_dice_coef: 0.0281 - val_accuracy: 0.9791\n",
      "Epoch 40/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0473 - dice_coef: 0.0472 - accuracy: 0.9651 - val_loss: -0.0281 - val_dice_coef: 0.0281 - val_accuracy: 0.9791\n",
      "Epoch 41/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0473 - dice_coef: 0.0471 - accuracy: 0.9651 - val_loss: -0.0281 - val_dice_coef: 0.0282 - val_accuracy: 0.9791\n",
      "Epoch 42/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0475 - dice_coef: 0.0474 - accuracy: 0.9651 - val_loss: -0.0282 - val_dice_coef: 0.0282 - val_accuracy: 0.9791\n",
      "Epoch 43/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0476 - dice_coef: 0.0476 - accuracy: 0.9651 - val_loss: -0.0282 - val_dice_coef: 0.0283 - val_accuracy: 0.9791\n",
      "Epoch 44/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0476 - dice_coef: 0.0473 - accuracy: 0.9651 - val_loss: -0.0283 - val_dice_coef: 0.0283 - val_accuracy: 0.9791\n",
      "Epoch 45/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0478 - dice_coef: 0.0478 - accuracy: 0.9651 - val_loss: -0.0283 - val_dice_coef: 0.0284 - val_accuracy: 0.9791\n",
      "Epoch 46/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0478 - dice_coef: 0.0477 - accuracy: 0.9651 - val_loss: -0.0284 - val_dice_coef: 0.0284 - val_accuracy: 0.9791\n",
      "Epoch 47/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0480 - dice_coef: 0.0479 - accuracy: 0.9651 - val_loss: -0.0285 - val_dice_coef: 0.0285 - val_accuracy: 0.9791\n",
      "Epoch 48/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0481 - dice_coef: 0.0480 - accuracy: 0.9651 - val_loss: -0.0285 - val_dice_coef: 0.0286 - val_accuracy: 0.9791\n",
      "Epoch 49/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0482 - dice_coef: 0.0481 - accuracy: 0.9651 - val_loss: -0.0286 - val_dice_coef: 0.0287 - val_accuracy: 0.9791\n",
      "Epoch 50/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0483 - dice_coef: 0.0482 - accuracy: 0.9651 - val_loss: -0.0287 - val_dice_coef: 0.0288 - val_accuracy: 0.9791\n",
      "Epoch 51/400\n",
      "19/19 [==============================] - 27s 1s/step - loss: -0.0485 - dice_coef: 0.0486 - accuracy: 0.9651 - val_loss: -0.0288 - val_dice_coef: 0.0289 - val_accuracy: 0.9791\n",
      "Epoch 52/400\n",
      "19/19 [==============================] - 126s 7s/step - loss: -0.0487 - dice_coef: 0.0486 - accuracy: 0.9651 - val_loss: -0.0289 - val_dice_coef: 0.0290 - val_accuracy: 0.9791\n",
      "Epoch 53/400\n",
      "19/19 [==============================] - 125s 7s/step - loss: -0.0489 - dice_coef: 0.0487 - accuracy: 0.9651 - val_loss: -0.0290 - val_dice_coef: 0.0291 - val_accuracy: 0.9791\n",
      "Epoch 54/400\n",
      "19/19 [==============================] - 128s 7s/step - loss: -0.0492 - dice_coef: 0.0491 - accuracy: 0.9651 - val_loss: -0.0292 - val_dice_coef: 0.0292 - val_accuracy: 0.9791\n",
      "Epoch 55/400\n",
      "19/19 [==============================] - 125s 7s/step - loss: -0.0494 - dice_coef: 0.0496 - accuracy: 0.9651 - val_loss: -0.0293 - val_dice_coef: 0.0294 - val_accuracy: 0.9791\n",
      "Epoch 56/400\n",
      "19/19 [==============================] - 126s 7s/step - loss: -0.0496 - dice_coef: 0.0496 - accuracy: 0.9651 - val_loss: -0.0295 - val_dice_coef: 0.0296 - val_accuracy: 0.9791\n",
      "Epoch 57/400\n",
      "19/19 [==============================] - 126s 7s/step - loss: -0.0500 - dice_coef: 0.0500 - accuracy: 0.9651 - val_loss: -0.0297 - val_dice_coef: 0.0297 - val_accuracy: 0.9791\n",
      "Epoch 58/400\n",
      "19/19 [==============================] - 123s 6s/step - loss: -0.0502 - dice_coef: 0.0501 - accuracy: 0.9651 - val_loss: -0.0299 - val_dice_coef: 0.0299 - val_accuracy: 0.9791\n",
      "Epoch 59/400\n",
      "19/19 [==============================] - 123s 6s/step - loss: -0.0505 - dice_coef: 0.0505 - accuracy: 0.9651 - val_loss: -0.0301 - val_dice_coef: 0.0302 - val_accuracy: 0.9791\n",
      "Epoch 60/400\n",
      "19/19 [==============================] - 18s 972ms/step - loss: -0.0510 - dice_coef: 0.0511 - accuracy: 0.9651 - val_loss: -0.0304 - val_dice_coef: 0.0304 - val_accuracy: 0.9791\n",
      "Epoch 61/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0513 - dice_coef: 0.0511 - accuracy: 0.9651 - val_loss: -0.0306 - val_dice_coef: 0.0307 - val_accuracy: 0.9791\n",
      "Epoch 62/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0517 - dice_coef: 0.0516 - accuracy: 0.9651 - val_loss: -0.0309 - val_dice_coef: 0.0309 - val_accuracy: 0.9791\n",
      "Epoch 63/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0522 - dice_coef: 0.0521 - accuracy: 0.9651 - val_loss: -0.0312 - val_dice_coef: 0.0312 - val_accuracy: 0.9791\n",
      "Epoch 64/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0528 - dice_coef: 0.0527 - accuracy: 0.9651 - val_loss: -0.0315 - val_dice_coef: 0.0316 - val_accuracy: 0.9791\n",
      "Epoch 65/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0533 - dice_coef: 0.0533 - accuracy: 0.9651 - val_loss: -0.0318 - val_dice_coef: 0.0319 - val_accuracy: 0.9791\n",
      "Epoch 66/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0538 - dice_coef: 0.0537 - accuracy: 0.9651 - val_loss: -0.0322 - val_dice_coef: 0.0322 - val_accuracy: 0.9791\n",
      "Epoch 67/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0544 - dice_coef: 0.0542 - accuracy: 0.9651 - val_loss: -0.0326 - val_dice_coef: 0.0326 - val_accuracy: 0.9791\n",
      "Epoch 68/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0550 - dice_coef: 0.0551 - accuracy: 0.9651 - val_loss: -0.0329 - val_dice_coef: 0.0330 - val_accuracy: 0.9791\n",
      "Epoch 69/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0555 - dice_coef: 0.0552 - accuracy: 0.9651 - val_loss: -0.0333 - val_dice_coef: 0.0334 - val_accuracy: 0.9791\n",
      "Epoch 70/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0562 - dice_coef: 0.0562 - accuracy: 0.9651 - val_loss: -0.0337 - val_dice_coef: 0.0338 - val_accuracy: 0.9791\n",
      "Epoch 71/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0569 - dice_coef: 0.0570 - accuracy: 0.9651 - val_loss: -0.0341 - val_dice_coef: 0.0342 - val_accuracy: 0.9791\n",
      "Epoch 72/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0575 - dice_coef: 0.0573 - accuracy: 0.9651 - val_loss: -0.0346 - val_dice_coef: 0.0346 - val_accuracy: 0.9791\n",
      "Epoch 73/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0581 - dice_coef: 0.0579 - accuracy: 0.9651 - val_loss: -0.0350 - val_dice_coef: 0.0350 - val_accuracy: 0.9791\n",
      "Epoch 74/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0586 - dice_coef: 0.0585 - accuracy: 0.9651 - val_loss: -0.0354 - val_dice_coef: 0.0354 - val_accuracy: 0.9791\n",
      "Epoch 75/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0593 - dice_coef: 0.0594 - accuracy: 0.9651 - val_loss: -0.0358 - val_dice_coef: 0.0358 - val_accuracy: 0.9791\n",
      "Epoch 76/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0598 - dice_coef: 0.0597 - accuracy: 0.9651 - val_loss: -0.0361 - val_dice_coef: 0.0362 - val_accuracy: 0.9791\n",
      "Epoch 77/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0602 - dice_coef: 0.0605 - accuracy: 0.9651 - val_loss: -0.0365 - val_dice_coef: 0.0365 - val_accuracy: 0.9791\n",
      "Epoch 78/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0608 - dice_coef: 0.0609 - accuracy: 0.9651 - val_loss: -0.0368 - val_dice_coef: 0.0369 - val_accuracy: 0.9791\n",
      "Epoch 79/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0613 - dice_coef: 0.0610 - accuracy: 0.9651 - val_loss: -0.0372 - val_dice_coef: 0.0372 - val_accuracy: 0.9791\n",
      "Epoch 80/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0617 - dice_coef: 0.0616 - accuracy: 0.9651 - val_loss: -0.0375 - val_dice_coef: 0.0375 - val_accuracy: 0.9791\n",
      "Epoch 81/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0621 - dice_coef: 0.0623 - accuracy: 0.9651 - val_loss: -0.0378 - val_dice_coef: 0.0378 - val_accuracy: 0.9791\n",
      "Epoch 82/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0624 - dice_coef: 0.0623 - accuracy: 0.9651 - val_loss: -0.0380 - val_dice_coef: 0.0380 - val_accuracy: 0.9791\n",
      "Epoch 83/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0628 - dice_coef: 0.0629 - accuracy: 0.9651 - val_loss: -0.0383 - val_dice_coef: 0.0383 - val_accuracy: 0.9791\n",
      "Epoch 84/400\n",
      "19/19 [==============================] - 7s 361ms/step - loss: -0.0631 - dice_coef: 0.0631 - accuracy: 0.9651 - val_loss: -0.0385 - val_dice_coef: 0.0385 - val_accuracy: 0.9791\n",
      "Epoch 85/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0634 - dice_coef: 0.0633 - accuracy: 0.9651 - val_loss: -0.0387 - val_dice_coef: 0.0387 - val_accuracy: 0.9791\n",
      "Epoch 86/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0636 - dice_coef: 0.0640 - accuracy: 0.9651 - val_loss: -0.0389 - val_dice_coef: 0.0389 - val_accuracy: 0.9791\n",
      "Epoch 87/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0639 - dice_coef: 0.0639 - accuracy: 0.9651 - val_loss: -0.0390 - val_dice_coef: 0.0390 - val_accuracy: 0.9791\n",
      "Epoch 88/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0640 - dice_coef: 0.0643 - accuracy: 0.9651 - val_loss: -0.0392 - val_dice_coef: 0.0392 - val_accuracy: 0.9791\n",
      "Epoch 89/400\n",
      "19/19 [==============================] - 7s 362ms/step - loss: -0.0644 - dice_coef: 0.0643 - accuracy: 0.9651 - val_loss: -0.0393 - val_dice_coef: 0.0393 - val_accuracy: 0.9791\n",
      "Epoch 90/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0645 - dice_coef: 0.0641 - accuracy: 0.9651 - val_loss: -0.0394 - val_dice_coef: 0.0395 - val_accuracy: 0.9791\n",
      "Epoch 91/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0647 - dice_coef: 0.0648 - accuracy: 0.9651 - val_loss: -0.0396 - val_dice_coef: 0.0396 - val_accuracy: 0.9791\n",
      "Epoch 92/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0648 - dice_coef: 0.0648 - accuracy: 0.9651 - val_loss: -0.0397 - val_dice_coef: 0.0397 - val_accuracy: 0.9791\n",
      "Epoch 93/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0649 - dice_coef: 0.0652 - accuracy: 0.9651 - val_loss: -0.0398 - val_dice_coef: 0.0398 - val_accuracy: 0.9791\n",
      "Epoch 94/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0651 - dice_coef: 0.0650 - accuracy: 0.9651 - val_loss: -0.0399 - val_dice_coef: 0.0399 - val_accuracy: 0.9791\n",
      "Epoch 95/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0652 - dice_coef: 0.0651 - accuracy: 0.9651 - val_loss: -0.0400 - val_dice_coef: 0.0400 - val_accuracy: 0.9791\n",
      "Epoch 96/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0654 - dice_coef: 0.0653 - accuracy: 0.9651 - val_loss: -0.0400 - val_dice_coef: 0.0401 - val_accuracy: 0.9791\n",
      "Epoch 97/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0653 - dice_coef: 0.0655 - accuracy: 0.9651 - val_loss: -0.0401 - val_dice_coef: 0.0401 - val_accuracy: 0.9791\n",
      "Epoch 98/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0656 - dice_coef: 0.0656 - accuracy: 0.9651 - val_loss: -0.0402 - val_dice_coef: 0.0402 - val_accuracy: 0.9791\n",
      "Epoch 99/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0657 - dice_coef: 0.0657 - accuracy: 0.9651 - val_loss: -0.0403 - val_dice_coef: 0.0403 - val_accuracy: 0.9791\n",
      "Epoch 100/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0658 - dice_coef: 0.0657 - accuracy: 0.9651 - val_loss: -0.0403 - val_dice_coef: 0.0404 - val_accuracy: 0.9791\n",
      "Epoch 101/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0658 - dice_coef: 0.0658 - accuracy: 0.9651 - val_loss: -0.0404 - val_dice_coef: 0.0404 - val_accuracy: 0.9791\n",
      "Epoch 102/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0660 - dice_coef: 0.0659 - accuracy: 0.9651 - val_loss: -0.0405 - val_dice_coef: 0.0405 - val_accuracy: 0.9791\n",
      "Epoch 103/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.0661 - dice_coef: 0.0661 - accuracy: 0.9651 - val_loss: -0.0405 - val_dice_coef: 0.0406 - val_accuracy: 0.9791\n",
      "Epoch 104/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0662 - dice_coef: 0.0664 - accuracy: 0.9651 - val_loss: -0.0406 - val_dice_coef: 0.0406 - val_accuracy: 0.9791\n",
      "Epoch 105/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0663 - dice_coef: 0.0661 - accuracy: 0.9651 - val_loss: -0.0407 - val_dice_coef: 0.0407 - val_accuracy: 0.9791\n",
      "Epoch 106/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.0663 - dice_coef: 0.0665 - accuracy: 0.9651 - val_loss: -0.0407 - val_dice_coef: 0.0408 - val_accuracy: 0.9791\n",
      "Epoch 107/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0665 - dice_coef: 0.0667 - accuracy: 0.9651 - val_loss: -0.0408 - val_dice_coef: 0.0408 - val_accuracy: 0.9791\n",
      "Epoch 108/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0665 - dice_coef: 0.0666 - accuracy: 0.9651 - val_loss: -0.0408 - val_dice_coef: 0.0409 - val_accuracy: 0.9791\n",
      "Epoch 109/400\n",
      "19/19 [==============================] - 7s 362ms/step - loss: -0.0666 - dice_coef: 0.0669 - accuracy: 0.9651 - val_loss: -0.0409 - val_dice_coef: 0.0409 - val_accuracy: 0.9791\n",
      "Epoch 110/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0667 - dice_coef: 0.0665 - accuracy: 0.9651 - val_loss: -0.0410 - val_dice_coef: 0.0410 - val_accuracy: 0.9791\n",
      "Epoch 111/400\n",
      "19/19 [==============================] - 7s 362ms/step - loss: -0.0668 - dice_coef: 0.0667 - accuracy: 0.9651 - val_loss: -0.0410 - val_dice_coef: 0.0410 - val_accuracy: 0.9791\n",
      "Epoch 112/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0669 - dice_coef: 0.0670 - accuracy: 0.9651 - val_loss: -0.0411 - val_dice_coef: 0.0411 - val_accuracy: 0.9791\n",
      "Epoch 113/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0669 - dice_coef: 0.0668 - accuracy: 0.9651 - val_loss: -0.0411 - val_dice_coef: 0.0412 - val_accuracy: 0.9791\n",
      "Epoch 114/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0671 - dice_coef: 0.0669 - accuracy: 0.9651 - val_loss: -0.0412 - val_dice_coef: 0.0412 - val_accuracy: 0.9791\n",
      "Epoch 115/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0672 - dice_coef: 0.0671 - accuracy: 0.9651 - val_loss: -0.0413 - val_dice_coef: 0.0413 - val_accuracy: 0.9791\n",
      "Epoch 116/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0673 - dice_coef: 0.0673 - accuracy: 0.9651 - val_loss: -0.0413 - val_dice_coef: 0.0413 - val_accuracy: 0.9791\n",
      "Epoch 117/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0674 - dice_coef: 0.0674 - accuracy: 0.9651 - val_loss: -0.0414 - val_dice_coef: 0.0414 - val_accuracy: 0.9791\n",
      "Epoch 118/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0674 - dice_coef: 0.0671 - accuracy: 0.9651 - val_loss: -0.0414 - val_dice_coef: 0.0415 - val_accuracy: 0.9791\n",
      "Epoch 119/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.0675 - dice_coef: 0.0676 - accuracy: 0.9651 - val_loss: -0.0415 - val_dice_coef: 0.0415 - val_accuracy: 0.9791\n",
      "Epoch 120/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0676 - dice_coef: 0.0674 - accuracy: 0.9651 - val_loss: -0.0415 - val_dice_coef: 0.0416 - val_accuracy: 0.9791\n",
      "Epoch 121/400\n",
      "19/19 [==============================] - 7s 361ms/step - loss: -0.0677 - dice_coef: 0.0677 - accuracy: 0.9651 - val_loss: -0.0416 - val_dice_coef: 0.0416 - val_accuracy: 0.9791\n",
      "Epoch 122/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0678 - dice_coef: 0.0678 - accuracy: 0.9651 - val_loss: -0.0417 - val_dice_coef: 0.0417 - val_accuracy: 0.9791\n",
      "Epoch 123/400\n",
      "19/19 [==============================] - 7s 363ms/step - loss: -0.0678 - dice_coef: 0.0680 - accuracy: 0.9651 - val_loss: -0.0417 - val_dice_coef: 0.0417 - val_accuracy: 0.9791\n",
      "Epoch 124/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0680 - dice_coef: 0.0682 - accuracy: 0.9651 - val_loss: -0.0418 - val_dice_coef: 0.0418 - val_accuracy: 0.9791\n",
      "Epoch 125/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0680 - dice_coef: 0.0681 - accuracy: 0.9651 - val_loss: -0.0418 - val_dice_coef: 0.0419 - val_accuracy: 0.9791\n",
      "Epoch 126/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0681 - dice_coef: 0.0682 - accuracy: 0.9651 - val_loss: -0.0419 - val_dice_coef: 0.0419 - val_accuracy: 0.9791\n",
      "Epoch 127/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0682 - dice_coef: 0.0680 - accuracy: 0.9651 - val_loss: -0.0420 - val_dice_coef: 0.0420 - val_accuracy: 0.9791\n",
      "Epoch 128/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0684 - dice_coef: 0.0685 - accuracy: 0.9651 - val_loss: -0.0420 - val_dice_coef: 0.0421 - val_accuracy: 0.9791\n",
      "Epoch 129/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0685 - dice_coef: 0.0686 - accuracy: 0.9651 - val_loss: -0.0421 - val_dice_coef: 0.0421 - val_accuracy: 0.9791\n",
      "Epoch 130/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0686 - dice_coef: 0.0688 - accuracy: 0.9651 - val_loss: -0.0421 - val_dice_coef: 0.0422 - val_accuracy: 0.9791\n",
      "Epoch 131/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0687 - dice_coef: 0.0687 - accuracy: 0.9651 - val_loss: -0.0422 - val_dice_coef: 0.0422 - val_accuracy: 0.9791\n",
      "Epoch 132/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0688 - dice_coef: 0.0687 - accuracy: 0.9651 - val_loss: -0.0423 - val_dice_coef: 0.0423 - val_accuracy: 0.9791\n",
      "Epoch 133/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0689 - dice_coef: 0.0686 - accuracy: 0.9651 - val_loss: -0.0423 - val_dice_coef: 0.0424 - val_accuracy: 0.9791\n",
      "Epoch 134/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0690 - dice_coef: 0.0687 - accuracy: 0.9651 - val_loss: -0.0424 - val_dice_coef: 0.0424 - val_accuracy: 0.9791\n",
      "Epoch 135/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0691 - dice_coef: 0.0691 - accuracy: 0.9651 - val_loss: -0.0425 - val_dice_coef: 0.0425 - val_accuracy: 0.9791\n",
      "Epoch 136/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0692 - dice_coef: 0.0695 - accuracy: 0.9651 - val_loss: -0.0425 - val_dice_coef: 0.0426 - val_accuracy: 0.9791\n",
      "Epoch 137/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0693 - dice_coef: 0.0695 - accuracy: 0.9651 - val_loss: -0.0426 - val_dice_coef: 0.0426 - val_accuracy: 0.9791\n",
      "Epoch 138/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0694 - dice_coef: 0.0696 - accuracy: 0.9651 - val_loss: -0.0427 - val_dice_coef: 0.0427 - val_accuracy: 0.9791\n",
      "Epoch 139/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0696 - dice_coef: 0.0697 - accuracy: 0.9651 - val_loss: -0.0427 - val_dice_coef: 0.0428 - val_accuracy: 0.9791\n",
      "Epoch 140/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0696 - dice_coef: 0.0694 - accuracy: 0.9651 - val_loss: -0.0428 - val_dice_coef: 0.0428 - val_accuracy: 0.9791\n",
      "Epoch 141/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0696 - dice_coef: 0.0694 - accuracy: 0.9651 - val_loss: -0.0429 - val_dice_coef: 0.0429 - val_accuracy: 0.9791\n",
      "Epoch 142/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0698 - dice_coef: 0.0696 - accuracy: 0.9651 - val_loss: -0.0429 - val_dice_coef: 0.0429 - val_accuracy: 0.9791\n",
      "Epoch 143/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0699 - dice_coef: 0.0697 - accuracy: 0.9651 - val_loss: -0.0430 - val_dice_coef: 0.0430 - val_accuracy: 0.9791\n",
      "Epoch 144/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0699 - dice_coef: 0.0697 - accuracy: 0.9651 - val_loss: -0.0431 - val_dice_coef: 0.0431 - val_accuracy: 0.9791\n",
      "Epoch 145/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0700 - dice_coef: 0.0699 - accuracy: 0.9651 - val_loss: -0.0431 - val_dice_coef: 0.0432 - val_accuracy: 0.9791\n",
      "Epoch 146/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0702 - dice_coef: 0.0701 - accuracy: 0.9651 - val_loss: -0.0432 - val_dice_coef: 0.0432 - val_accuracy: 0.9791\n",
      "Epoch 147/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0703 - dice_coef: 0.0704 - accuracy: 0.9651 - val_loss: -0.0433 - val_dice_coef: 0.0433 - val_accuracy: 0.9791\n",
      "Epoch 148/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0705 - dice_coef: 0.0704 - accuracy: 0.9651 - val_loss: -0.0433 - val_dice_coef: 0.0434 - val_accuracy: 0.9791\n",
      "Epoch 149/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0705 - dice_coef: 0.0707 - accuracy: 0.9651 - val_loss: -0.0434 - val_dice_coef: 0.0434 - val_accuracy: 0.9791\n",
      "Epoch 150/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0706 - dice_coef: 0.0706 - accuracy: 0.9651 - val_loss: -0.0435 - val_dice_coef: 0.0435 - val_accuracy: 0.9791\n",
      "Epoch 151/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0707 - dice_coef: 0.0709 - accuracy: 0.9651 - val_loss: -0.0435 - val_dice_coef: 0.0436 - val_accuracy: 0.9791\n",
      "Epoch 152/400\n",
      "19/19 [==============================] - 7s 370ms/step - loss: -0.0708 - dice_coef: 0.0708 - accuracy: 0.9651 - val_loss: -0.0436 - val_dice_coef: 0.0436 - val_accuracy: 0.9791\n",
      "Epoch 153/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0710 - dice_coef: 0.0711 - accuracy: 0.9651 - val_loss: -0.0437 - val_dice_coef: 0.0437 - val_accuracy: 0.9791\n",
      "Epoch 154/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0711 - dice_coef: 0.0710 - accuracy: 0.9651 - val_loss: -0.0437 - val_dice_coef: 0.0438 - val_accuracy: 0.9791\n",
      "Epoch 155/400\n",
      "19/19 [==============================] - 7s 372ms/step - loss: -0.0712 - dice_coef: 0.0710 - accuracy: 0.9651 - val_loss: -0.0438 - val_dice_coef: 0.0438 - val_accuracy: 0.9791\n",
      "Epoch 156/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0713 - dice_coef: 0.0717 - accuracy: 0.9651 - val_loss: -0.0439 - val_dice_coef: 0.0439 - val_accuracy: 0.9791\n",
      "Epoch 157/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0714 - dice_coef: 0.0715 - accuracy: 0.9651 - val_loss: -0.0439 - val_dice_coef: 0.0440 - val_accuracy: 0.9791\n",
      "Epoch 158/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0715 - dice_coef: 0.0716 - accuracy: 0.9651 - val_loss: -0.0440 - val_dice_coef: 0.0440 - val_accuracy: 0.9791\n",
      "Epoch 159/400\n",
      "19/19 [==============================] - 7s 375ms/step - loss: -0.0716 - dice_coef: 0.0717 - accuracy: 0.9651 - val_loss: -0.0441 - val_dice_coef: 0.0441 - val_accuracy: 0.9791\n",
      "Epoch 160/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0717 - dice_coef: 0.0718 - accuracy: 0.9651 - val_loss: -0.0442 - val_dice_coef: 0.0442 - val_accuracy: 0.9791\n",
      "Epoch 161/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0718 - dice_coef: 0.0718 - accuracy: 0.9651 - val_loss: -0.0442 - val_dice_coef: 0.0442 - val_accuracy: 0.9791\n",
      "Epoch 162/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0719 - dice_coef: 0.0716 - accuracy: 0.9651 - val_loss: -0.0443 - val_dice_coef: 0.0443 - val_accuracy: 0.9791\n",
      "Epoch 163/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.0720 - dice_coef: 0.0720 - accuracy: 0.9651 - val_loss: -0.0444 - val_dice_coef: 0.0444 - val_accuracy: 0.9791\n",
      "Epoch 164/400\n",
      "19/19 [==============================] - 7s 371ms/step - loss: -0.0722 - dice_coef: 0.0723 - accuracy: 0.9651 - val_loss: -0.0444 - val_dice_coef: 0.0445 - val_accuracy: 0.9791\n",
      "Epoch 165/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0723 - dice_coef: 0.0725 - accuracy: 0.9651 - val_loss: -0.0445 - val_dice_coef: 0.0445 - val_accuracy: 0.9791\n",
      "Epoch 166/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0723 - dice_coef: 0.0722 - accuracy: 0.9651 - val_loss: -0.0446 - val_dice_coef: 0.0446 - val_accuracy: 0.9791\n",
      "Epoch 167/400\n",
      "19/19 [==============================] - 7s 373ms/step - loss: -0.0725 - dice_coef: 0.0722 - accuracy: 0.9651 - val_loss: -0.0446 - val_dice_coef: 0.0447 - val_accuracy: 0.9791\n",
      "Epoch 168/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0727 - dice_coef: 0.0726 - accuracy: 0.9651 - val_loss: -0.0447 - val_dice_coef: 0.0447 - val_accuracy: 0.9791\n",
      "Epoch 169/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0727 - dice_coef: 0.0725 - accuracy: 0.9651 - val_loss: -0.0448 - val_dice_coef: 0.0448 - val_accuracy: 0.9791\n",
      "Epoch 170/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0728 - dice_coef: 0.0725 - accuracy: 0.9651 - val_loss: -0.0449 - val_dice_coef: 0.0449 - val_accuracy: 0.9791\n",
      "Epoch 171/400\n",
      "19/19 [==============================] - 8s 401ms/step - loss: -0.0730 - dice_coef: 0.0731 - accuracy: 0.9651 - val_loss: -0.0449 - val_dice_coef: 0.0450 - val_accuracy: 0.9791\n",
      "Epoch 172/400\n",
      "19/19 [==============================] - 9s 451ms/step - loss: -0.0731 - dice_coef: 0.0731 - accuracy: 0.9651 - val_loss: -0.0450 - val_dice_coef: 0.0450 - val_accuracy: 0.9791\n",
      "Epoch 173/400\n",
      "19/19 [==============================] - 9s 448ms/step - loss: -0.0731 - dice_coef: 0.0730 - accuracy: 0.9651 - val_loss: -0.0451 - val_dice_coef: 0.0451 - val_accuracy: 0.9791\n",
      "Epoch 174/400\n",
      "19/19 [==============================] - 9s 448ms/step - loss: -0.0732 - dice_coef: 0.0731 - accuracy: 0.9576 - val_loss: -0.0451 - val_dice_coef: 0.0452 - val_accuracy: 0.9572\n",
      "Epoch 175/400\n",
      "19/19 [==============================] - 9s 449ms/step - loss: -0.0735 - dice_coef: 0.0734 - accuracy: 0.9512 - val_loss: -0.0452 - val_dice_coef: 0.0452 - val_accuracy: 0.9551\n",
      "Epoch 176/400\n",
      "19/19 [==============================] - 8s 447ms/step - loss: -0.0735 - dice_coef: 0.0735 - accuracy: 0.9500 - val_loss: -0.0453 - val_dice_coef: 0.0453 - val_accuracy: 0.9535\n",
      "Epoch 177/400\n",
      "19/19 [==============================] - 8s 446ms/step - loss: -0.0736 - dice_coef: 0.0736 - accuracy: 0.9484 - val_loss: -0.0454 - val_dice_coef: 0.0454 - val_accuracy: 0.9520\n",
      "Epoch 178/400\n",
      "19/19 [==============================] - 8s 445ms/step - loss: -0.0737 - dice_coef: 0.0736 - accuracy: 0.9467 - val_loss: -0.0454 - val_dice_coef: 0.0455 - val_accuracy: 0.9506\n",
      "Epoch 179/400\n",
      "19/19 [==============================] - 9s 447ms/step - loss: -0.0738 - dice_coef: 0.0741 - accuracy: 0.9456 - val_loss: -0.0455 - val_dice_coef: 0.0455 - val_accuracy: 0.9491\n",
      "Epoch 180/400\n",
      "19/19 [==============================] - 8s 446ms/step - loss: -0.0739 - dice_coef: 0.0741 - accuracy: 0.9443 - val_loss: -0.0456 - val_dice_coef: 0.0456 - val_accuracy: 0.9475\n",
      "Epoch 181/400\n",
      "19/19 [==============================] - 8s 447ms/step - loss: -0.0741 - dice_coef: 0.0742 - accuracy: 0.9431 - val_loss: -0.0456 - val_dice_coef: 0.0457 - val_accuracy: 0.9461\n",
      "Epoch 182/400\n",
      "19/19 [==============================] - 9s 449ms/step - loss: -0.0742 - dice_coef: 0.0744 - accuracy: 0.9421 - val_loss: -0.0457 - val_dice_coef: 0.0457 - val_accuracy: 0.9448\n",
      "Epoch 183/400\n",
      "19/19 [==============================] - 8s 445ms/step - loss: -0.0741 - dice_coef: 0.0743 - accuracy: 0.9409 - val_loss: -0.0458 - val_dice_coef: 0.0458 - val_accuracy: 0.9434\n",
      "Epoch 184/400\n",
      "19/19 [==============================] - 8s 436ms/step - loss: -0.0743 - dice_coef: 0.0740 - accuracy: 0.9396 - val_loss: -0.0459 - val_dice_coef: 0.0459 - val_accuracy: 0.9418\n",
      "Epoch 185/400\n",
      "19/19 [==============================] - 8s 440ms/step - loss: -0.0746 - dice_coef: 0.0749 - accuracy: 0.9391 - val_loss: -0.0459 - val_dice_coef: 0.0460 - val_accuracy: 0.9406\n",
      "Epoch 186/400\n",
      "19/19 [==============================] - 8s 446ms/step - loss: -0.0747 - dice_coef: 0.0746 - accuracy: 0.9381 - val_loss: -0.0460 - val_dice_coef: 0.0460 - val_accuracy: 0.9391\n",
      "Epoch 187/400\n",
      "19/19 [==============================] - 8s 447ms/step - loss: -0.0748 - dice_coef: 0.0748 - accuracy: 0.9370 - val_loss: -0.0461 - val_dice_coef: 0.0461 - val_accuracy: 0.9377\n",
      "Epoch 188/400\n",
      "19/19 [==============================] - 8s 440ms/step - loss: -0.0748 - dice_coef: 0.0746 - accuracy: 0.9359 - val_loss: -0.0462 - val_dice_coef: 0.0462 - val_accuracy: 0.9362\n",
      "Epoch 189/400\n",
      "19/19 [==============================] - 8s 447ms/step - loss: -0.0748 - dice_coef: 0.0747 - accuracy: 0.9350 - val_loss: -0.0462 - val_dice_coef: 0.0462 - val_accuracy: 0.9349\n",
      "Epoch 190/400\n",
      "19/19 [==============================] - 9s 449ms/step - loss: -0.0751 - dice_coef: 0.0754 - accuracy: 0.9340 - val_loss: -0.0463 - val_dice_coef: 0.0463 - val_accuracy: 0.9338\n",
      "Epoch 191/400\n",
      "19/19 [==============================] - 8s 439ms/step - loss: -0.0752 - dice_coef: 0.0750 - accuracy: 0.9331 - val_loss: -0.0464 - val_dice_coef: 0.0464 - val_accuracy: 0.9324\n",
      "Epoch 192/400\n",
      "19/19 [==============================] - 8s 425ms/step - loss: -0.0753 - dice_coef: 0.0755 - accuracy: 0.9319 - val_loss: -0.0465 - val_dice_coef: 0.0465 - val_accuracy: 0.9312\n",
      "Epoch 193/400\n",
      "19/19 [==============================] - 9s 448ms/step - loss: -0.0754 - dice_coef: 0.0753 - accuracy: 0.9309 - val_loss: -0.0465 - val_dice_coef: 0.0465 - val_accuracy: 0.9299\n",
      "Epoch 194/400\n",
      "19/19 [==============================] - 8s 443ms/step - loss: -0.0755 - dice_coef: 0.0758 - accuracy: 0.9305 - val_loss: -0.0466 - val_dice_coef: 0.0466 - val_accuracy: 0.9287\n",
      "Epoch 195/400\n",
      "19/19 [==============================] - 8s 395ms/step - loss: -0.0755 - dice_coef: 0.0754 - accuracy: 0.9295 - val_loss: -0.0467 - val_dice_coef: 0.0467 - val_accuracy: 0.9273\n",
      "Epoch 196/400\n",
      "19/19 [==============================] - 7s 389ms/step - loss: -0.0758 - dice_coef: 0.0757 - accuracy: 0.9289 - val_loss: -0.0468 - val_dice_coef: 0.0468 - val_accuracy: 0.9261\n",
      "Epoch 197/400\n",
      "19/19 [==============================] - 8s 398ms/step - loss: -0.0760 - dice_coef: 0.0759 - accuracy: 0.9279 - val_loss: -0.0468 - val_dice_coef: 0.0468 - val_accuracy: 0.9251\n",
      "Epoch 198/400\n",
      "19/19 [==============================] - 7s 389ms/step - loss: -0.0759 - dice_coef: 0.0755 - accuracy: 0.9275 - val_loss: -0.0469 - val_dice_coef: 0.0469 - val_accuracy: 0.9239\n",
      "Epoch 199/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0761 - dice_coef: 0.0759 - accuracy: 0.9268 - val_loss: -0.0470 - val_dice_coef: 0.0470 - val_accuracy: 0.9228\n",
      "Epoch 200/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0763 - dice_coef: 0.0763 - accuracy: 0.9265 - val_loss: -0.0471 - val_dice_coef: 0.0471 - val_accuracy: 0.9217\n",
      "Epoch 201/400\n",
      "19/19 [==============================] - 7s 391ms/step - loss: -0.0764 - dice_coef: 0.0763 - accuracy: 0.9260 - val_loss: -0.0471 - val_dice_coef: 0.0472 - val_accuracy: 0.9207\n",
      "Epoch 202/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0765 - dice_coef: 0.0764 - accuracy: 0.9256 - val_loss: -0.0472 - val_dice_coef: 0.0472 - val_accuracy: 0.9196\n",
      "Epoch 203/400\n",
      "19/19 [==============================] - 7s 389ms/step - loss: -0.0765 - dice_coef: 0.0765 - accuracy: 0.9242 - val_loss: -0.0473 - val_dice_coef: 0.0473 - val_accuracy: 0.9186\n",
      "Epoch 204/400\n",
      "19/19 [==============================] - 7s 391ms/step - loss: -0.0768 - dice_coef: 0.0767 - accuracy: 0.9244 - val_loss: -0.0474 - val_dice_coef: 0.0474 - val_accuracy: 0.9178\n",
      "Epoch 205/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0768 - dice_coef: 0.0768 - accuracy: 0.9237 - val_loss: -0.0475 - val_dice_coef: 0.0475 - val_accuracy: 0.9169\n",
      "Epoch 206/400\n",
      "19/19 [==============================] - 7s 391ms/step - loss: -0.0771 - dice_coef: 0.0772 - accuracy: 0.9233 - val_loss: -0.0475 - val_dice_coef: 0.0476 - val_accuracy: 0.9163\n",
      "Epoch 207/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0771 - dice_coef: 0.0770 - accuracy: 0.9222 - val_loss: -0.0476 - val_dice_coef: 0.0476 - val_accuracy: 0.9154\n",
      "Epoch 208/400\n",
      "19/19 [==============================] - 7s 388ms/step - loss: -0.0772 - dice_coef: 0.0770 - accuracy: 0.9225 - val_loss: -0.0477 - val_dice_coef: 0.0477 - val_accuracy: 0.9147\n",
      "Epoch 209/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0774 - dice_coef: 0.0772 - accuracy: 0.9219 - val_loss: -0.0478 - val_dice_coef: 0.0478 - val_accuracy: 0.9139\n",
      "Epoch 210/400\n",
      "19/19 [==============================] - 7s 387ms/step - loss: -0.0774 - dice_coef: 0.0771 - accuracy: 0.9206 - val_loss: -0.0479 - val_dice_coef: 0.0479 - val_accuracy: 0.9133\n",
      "Epoch 211/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0776 - dice_coef: 0.0776 - accuracy: 0.9211 - val_loss: -0.0480 - val_dice_coef: 0.0480 - val_accuracy: 0.9127\n",
      "Epoch 212/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0779 - dice_coef: 0.0778 - accuracy: 0.9211 - val_loss: -0.0481 - val_dice_coef: 0.0481 - val_accuracy: 0.9121\n",
      "Epoch 213/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0780 - dice_coef: 0.0781 - accuracy: 0.9206 - val_loss: -0.0481 - val_dice_coef: 0.0482 - val_accuracy: 0.9116\n",
      "Epoch 214/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0780 - dice_coef: 0.0780 - accuracy: 0.9203 - val_loss: -0.0482 - val_dice_coef: 0.0483 - val_accuracy: 0.9111\n",
      "Epoch 215/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0782 - dice_coef: 0.0783 - accuracy: 0.9197 - val_loss: -0.0483 - val_dice_coef: 0.0483 - val_accuracy: 0.9107\n",
      "Epoch 216/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0783 - dice_coef: 0.0781 - accuracy: 0.9197 - val_loss: -0.0484 - val_dice_coef: 0.0484 - val_accuracy: 0.9103\n",
      "Epoch 217/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0785 - dice_coef: 0.0786 - accuracy: 0.9196 - val_loss: -0.0485 - val_dice_coef: 0.0485 - val_accuracy: 0.9099\n",
      "Epoch 218/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0787 - dice_coef: 0.0788 - accuracy: 0.9196 - val_loss: -0.0486 - val_dice_coef: 0.0486 - val_accuracy: 0.9095\n",
      "Epoch 219/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0787 - dice_coef: 0.0787 - accuracy: 0.9191 - val_loss: -0.0487 - val_dice_coef: 0.0487 - val_accuracy: 0.9091\n",
      "Epoch 220/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0789 - dice_coef: 0.0791 - accuracy: 0.9192 - val_loss: -0.0488 - val_dice_coef: 0.0488 - val_accuracy: 0.9089\n",
      "Epoch 221/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0790 - dice_coef: 0.0788 - accuracy: 0.9181 - val_loss: -0.0489 - val_dice_coef: 0.0489 - val_accuracy: 0.9086\n",
      "Epoch 222/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0791 - dice_coef: 0.0789 - accuracy: 0.9187 - val_loss: -0.0490 - val_dice_coef: 0.0490 - val_accuracy: 0.9083\n",
      "Epoch 223/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0793 - dice_coef: 0.0793 - accuracy: 0.9183 - val_loss: -0.0491 - val_dice_coef: 0.0491 - val_accuracy: 0.9082\n",
      "Epoch 224/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0795 - dice_coef: 0.0796 - accuracy: 0.9183 - val_loss: -0.0492 - val_dice_coef: 0.0492 - val_accuracy: 0.9080\n",
      "Epoch 225/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0797 - dice_coef: 0.0798 - accuracy: 0.9187 - val_loss: -0.0493 - val_dice_coef: 0.0493 - val_accuracy: 0.9078\n",
      "Epoch 226/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0797 - dice_coef: 0.0796 - accuracy: 0.9186 - val_loss: -0.0494 - val_dice_coef: 0.0494 - val_accuracy: 0.9075\n",
      "Epoch 227/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0798 - dice_coef: 0.0794 - accuracy: 0.9183 - val_loss: -0.0495 - val_dice_coef: 0.0495 - val_accuracy: 0.9073\n",
      "Epoch 228/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0800 - dice_coef: 0.0801 - accuracy: 0.9177 - val_loss: -0.0496 - val_dice_coef: 0.0497 - val_accuracy: 0.9072\n",
      "Epoch 229/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0802 - dice_coef: 0.0801 - accuracy: 0.9178 - val_loss: -0.0497 - val_dice_coef: 0.0498 - val_accuracy: 0.9070\n",
      "Epoch 230/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0804 - dice_coef: 0.0804 - accuracy: 0.9181 - val_loss: -0.0499 - val_dice_coef: 0.0499 - val_accuracy: 0.9069\n",
      "Epoch 231/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0805 - dice_coef: 0.0804 - accuracy: 0.9174 - val_loss: -0.0500 - val_dice_coef: 0.0500 - val_accuracy: 0.9067\n",
      "Epoch 232/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0808 - dice_coef: 0.0807 - accuracy: 0.9183 - val_loss: -0.0501 - val_dice_coef: 0.0501 - val_accuracy: 0.9066\n",
      "Epoch 233/400\n",
      "19/19 [==============================] - 7s 385ms/step - loss: -0.0808 - dice_coef: 0.0807 - accuracy: 0.9176 - val_loss: -0.0502 - val_dice_coef: 0.0502 - val_accuracy: 0.9065\n",
      "Epoch 234/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0810 - dice_coef: 0.0810 - accuracy: 0.9177 - val_loss: -0.0503 - val_dice_coef: 0.0503 - val_accuracy: 0.9064\n",
      "Epoch 235/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0812 - dice_coef: 0.0811 - accuracy: 0.9178 - val_loss: -0.0504 - val_dice_coef: 0.0504 - val_accuracy: 0.9063\n",
      "Epoch 236/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0815 - dice_coef: 0.0814 - accuracy: 0.9177 - val_loss: -0.0505 - val_dice_coef: 0.0505 - val_accuracy: 0.9062\n",
      "Epoch 237/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0815 - dice_coef: 0.0814 - accuracy: 0.9179 - val_loss: -0.0507 - val_dice_coef: 0.0507 - val_accuracy: 0.9060\n",
      "Epoch 238/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0817 - dice_coef: 0.0814 - accuracy: 0.9178 - val_loss: -0.0508 - val_dice_coef: 0.0508 - val_accuracy: 0.9059\n",
      "Epoch 239/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0819 - dice_coef: 0.0819 - accuracy: 0.9177 - val_loss: -0.0509 - val_dice_coef: 0.0509 - val_accuracy: 0.9059\n",
      "Epoch 240/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0821 - dice_coef: 0.0819 - accuracy: 0.9175 - val_loss: -0.0510 - val_dice_coef: 0.0510 - val_accuracy: 0.9058\n",
      "Epoch 241/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0824 - dice_coef: 0.0823 - accuracy: 0.9182 - val_loss: -0.0511 - val_dice_coef: 0.0511 - val_accuracy: 0.9058\n",
      "Epoch 242/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0824 - dice_coef: 0.0823 - accuracy: 0.9176 - val_loss: -0.0513 - val_dice_coef: 0.0513 - val_accuracy: 0.9057\n",
      "Epoch 243/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0827 - dice_coef: 0.0824 - accuracy: 0.9178 - val_loss: -0.0514 - val_dice_coef: 0.0514 - val_accuracy: 0.9057\n",
      "Epoch 244/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0829 - dice_coef: 0.0830 - accuracy: 0.9180 - val_loss: -0.0515 - val_dice_coef: 0.0515 - val_accuracy: 0.9057\n",
      "Epoch 245/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0830 - dice_coef: 0.0831 - accuracy: 0.9178 - val_loss: -0.0516 - val_dice_coef: 0.0517 - val_accuracy: 0.9056\n",
      "Epoch 246/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0831 - dice_coef: 0.0828 - accuracy: 0.9184 - val_loss: -0.0518 - val_dice_coef: 0.0518 - val_accuracy: 0.9056\n",
      "Epoch 247/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0833 - dice_coef: 0.0835 - accuracy: 0.9178 - val_loss: -0.0519 - val_dice_coef: 0.0519 - val_accuracy: 0.9055\n",
      "Epoch 248/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0834 - dice_coef: 0.0834 - accuracy: 0.9177 - val_loss: -0.0520 - val_dice_coef: 0.0520 - val_accuracy: 0.9054\n",
      "Epoch 249/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0836 - dice_coef: 0.0834 - accuracy: 0.9178 - val_loss: -0.0522 - val_dice_coef: 0.0522 - val_accuracy: 0.9054\n",
      "Epoch 250/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0840 - dice_coef: 0.0842 - accuracy: 0.9181 - val_loss: -0.0523 - val_dice_coef: 0.0523 - val_accuracy: 0.9054\n",
      "Epoch 251/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0842 - dice_coef: 0.0841 - accuracy: 0.9183 - val_loss: -0.0524 - val_dice_coef: 0.0524 - val_accuracy: 0.9053\n",
      "Epoch 252/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0840 - dice_coef: 0.0840 - accuracy: 0.9178 - val_loss: -0.0525 - val_dice_coef: 0.0526 - val_accuracy: 0.9053\n",
      "Epoch 253/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0844 - dice_coef: 0.0844 - accuracy: 0.9179 - val_loss: -0.0527 - val_dice_coef: 0.0527 - val_accuracy: 0.9053\n",
      "Epoch 254/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0846 - dice_coef: 0.0845 - accuracy: 0.9182 - val_loss: -0.0528 - val_dice_coef: 0.0528 - val_accuracy: 0.9053\n",
      "Epoch 255/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0847 - dice_coef: 0.0845 - accuracy: 0.9178 - val_loss: -0.0529 - val_dice_coef: 0.0530 - val_accuracy: 0.9053\n",
      "Epoch 256/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0849 - dice_coef: 0.0851 - accuracy: 0.9181 - val_loss: -0.0531 - val_dice_coef: 0.0531 - val_accuracy: 0.9052\n",
      "Epoch 257/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0850 - dice_coef: 0.0853 - accuracy: 0.9182 - val_loss: -0.0532 - val_dice_coef: 0.0532 - val_accuracy: 0.9052\n",
      "Epoch 258/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0852 - dice_coef: 0.0854 - accuracy: 0.9182 - val_loss: -0.0534 - val_dice_coef: 0.0534 - val_accuracy: 0.9052\n",
      "Epoch 259/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0853 - dice_coef: 0.0857 - accuracy: 0.9181 - val_loss: -0.0535 - val_dice_coef: 0.0535 - val_accuracy: 0.9053\n",
      "Epoch 260/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0857 - dice_coef: 0.0858 - accuracy: 0.9184 - val_loss: -0.0536 - val_dice_coef: 0.0536 - val_accuracy: 0.9052\n",
      "Epoch 261/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0858 - dice_coef: 0.0860 - accuracy: 0.9181 - val_loss: -0.0538 - val_dice_coef: 0.0538 - val_accuracy: 0.9052\n",
      "Epoch 262/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0861 - dice_coef: 0.0860 - accuracy: 0.9182 - val_loss: -0.0539 - val_dice_coef: 0.0539 - val_accuracy: 0.9052\n",
      "Epoch 263/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0863 - dice_coef: 0.0864 - accuracy: 0.9184 - val_loss: -0.0540 - val_dice_coef: 0.0540 - val_accuracy: 0.9052\n",
      "Epoch 264/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0863 - dice_coef: 0.0864 - accuracy: 0.9183 - val_loss: -0.0542 - val_dice_coef: 0.0542 - val_accuracy: 0.9051\n",
      "Epoch 265/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0866 - dice_coef: 0.0864 - accuracy: 0.9183 - val_loss: -0.0543 - val_dice_coef: 0.0543 - val_accuracy: 0.9052\n",
      "Epoch 266/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0867 - dice_coef: 0.0868 - accuracy: 0.9184 - val_loss: -0.0544 - val_dice_coef: 0.0544 - val_accuracy: 0.9051\n",
      "Epoch 267/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0872 - dice_coef: 0.0874 - accuracy: 0.9187 - val_loss: -0.0546 - val_dice_coef: 0.0546 - val_accuracy: 0.9051\n",
      "Epoch 268/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0872 - dice_coef: 0.0874 - accuracy: 0.9185 - val_loss: -0.0547 - val_dice_coef: 0.0547 - val_accuracy: 0.9051\n",
      "Epoch 269/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0873 - dice_coef: 0.0875 - accuracy: 0.9183 - val_loss: -0.0549 - val_dice_coef: 0.0549 - val_accuracy: 0.9052\n",
      "Epoch 270/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0875 - dice_coef: 0.0877 - accuracy: 0.9188 - val_loss: -0.0550 - val_dice_coef: 0.0550 - val_accuracy: 0.9052\n",
      "Epoch 271/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0877 - dice_coef: 0.0880 - accuracy: 0.9187 - val_loss: -0.0551 - val_dice_coef: 0.0551 - val_accuracy: 0.9052\n",
      "Epoch 272/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0879 - dice_coef: 0.0878 - accuracy: 0.9188 - val_loss: -0.0553 - val_dice_coef: 0.0553 - val_accuracy: 0.9052\n",
      "Epoch 273/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0881 - dice_coef: 0.0878 - accuracy: 0.9186 - val_loss: -0.0554 - val_dice_coef: 0.0554 - val_accuracy: 0.9052\n",
      "Epoch 274/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0881 - dice_coef: 0.0882 - accuracy: 0.9187 - val_loss: -0.0555 - val_dice_coef: 0.0555 - val_accuracy: 0.9052\n",
      "Epoch 275/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0884 - dice_coef: 0.0883 - accuracy: 0.9187 - val_loss: -0.0557 - val_dice_coef: 0.0557 - val_accuracy: 0.9052\n",
      "Epoch 276/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0884 - dice_coef: 0.0886 - accuracy: 0.9186 - val_loss: -0.0558 - val_dice_coef: 0.0558 - val_accuracy: 0.9052\n",
      "Epoch 277/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0888 - dice_coef: 0.0890 - accuracy: 0.9190 - val_loss: -0.0559 - val_dice_coef: 0.0559 - val_accuracy: 0.9052\n",
      "Epoch 278/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0890 - dice_coef: 0.0892 - accuracy: 0.9190 - val_loss: -0.0561 - val_dice_coef: 0.0561 - val_accuracy: 0.9052\n",
      "Epoch 279/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0892 - dice_coef: 0.0891 - accuracy: 0.9189 - val_loss: -0.0562 - val_dice_coef: 0.0562 - val_accuracy: 0.9052\n",
      "Epoch 280/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0894 - dice_coef: 0.0893 - accuracy: 0.9189 - val_loss: -0.0564 - val_dice_coef: 0.0563 - val_accuracy: 0.9052\n",
      "Epoch 281/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0894 - dice_coef: 0.0891 - accuracy: 0.9190 - val_loss: -0.0565 - val_dice_coef: 0.0565 - val_accuracy: 0.9051\n",
      "Epoch 282/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0896 - dice_coef: 0.0899 - accuracy: 0.9191 - val_loss: -0.0566 - val_dice_coef: 0.0566 - val_accuracy: 0.9052\n",
      "Epoch 283/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0899 - dice_coef: 0.0898 - accuracy: 0.9190 - val_loss: -0.0568 - val_dice_coef: 0.0568 - val_accuracy: 0.9052\n",
      "Epoch 284/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0900 - dice_coef: 0.0898 - accuracy: 0.9191 - val_loss: -0.0569 - val_dice_coef: 0.0569 - val_accuracy: 0.9052\n",
      "Epoch 285/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0902 - dice_coef: 0.0901 - accuracy: 0.9192 - val_loss: -0.0570 - val_dice_coef: 0.0570 - val_accuracy: 0.9052\n",
      "Epoch 286/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0904 - dice_coef: 0.0904 - accuracy: 0.9192 - val_loss: -0.0572 - val_dice_coef: 0.0571 - val_accuracy: 0.9052\n",
      "Epoch 287/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0903 - dice_coef: 0.0904 - accuracy: 0.9191 - val_loss: -0.0573 - val_dice_coef: 0.0573 - val_accuracy: 0.9052\n",
      "Epoch 288/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0906 - dice_coef: 0.0908 - accuracy: 0.9191 - val_loss: -0.0574 - val_dice_coef: 0.0574 - val_accuracy: 0.9052\n",
      "Epoch 289/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0909 - dice_coef: 0.0905 - accuracy: 0.9195 - val_loss: -0.0575 - val_dice_coef: 0.0575 - val_accuracy: 0.9052\n",
      "Epoch 290/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0909 - dice_coef: 0.0908 - accuracy: 0.9193 - val_loss: -0.0577 - val_dice_coef: 0.0577 - val_accuracy: 0.9052\n",
      "Epoch 291/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0912 - dice_coef: 0.0912 - accuracy: 0.9195 - val_loss: -0.0578 - val_dice_coef: 0.0578 - val_accuracy: 0.9052\n",
      "Epoch 292/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0913 - dice_coef: 0.0912 - accuracy: 0.9193 - val_loss: -0.0579 - val_dice_coef: 0.0579 - val_accuracy: 0.9051\n",
      "Epoch 293/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0916 - dice_coef: 0.0915 - accuracy: 0.9194 - val_loss: -0.0581 - val_dice_coef: 0.0581 - val_accuracy: 0.9052\n",
      "Epoch 294/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0915 - dice_coef: 0.0917 - accuracy: 0.9195 - val_loss: -0.0582 - val_dice_coef: 0.0582 - val_accuracy: 0.9052\n",
      "Epoch 295/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0918 - dice_coef: 0.0916 - accuracy: 0.9196 - val_loss: -0.0583 - val_dice_coef: 0.0583 - val_accuracy: 0.9051\n",
      "Epoch 296/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0921 - dice_coef: 0.0923 - accuracy: 0.9196 - val_loss: -0.0584 - val_dice_coef: 0.0584 - val_accuracy: 0.9052\n",
      "Epoch 297/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0922 - dice_coef: 0.0926 - accuracy: 0.9195 - val_loss: -0.0586 - val_dice_coef: 0.0586 - val_accuracy: 0.9052\n",
      "Epoch 298/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0923 - dice_coef: 0.0923 - accuracy: 0.9195 - val_loss: -0.0587 - val_dice_coef: 0.0587 - val_accuracy: 0.9053\n",
      "Epoch 299/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0924 - dice_coef: 0.0926 - accuracy: 0.9197 - val_loss: -0.0588 - val_dice_coef: 0.0588 - val_accuracy: 0.9052\n",
      "Epoch 300/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0925 - dice_coef: 0.0924 - accuracy: 0.9195 - val_loss: -0.0590 - val_dice_coef: 0.0589 - val_accuracy: 0.9052\n",
      "Epoch 301/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0927 - dice_coef: 0.0929 - accuracy: 0.9196 - val_loss: -0.0591 - val_dice_coef: 0.0591 - val_accuracy: 0.9052\n",
      "Epoch 302/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0929 - dice_coef: 0.0932 - accuracy: 0.9197 - val_loss: -0.0592 - val_dice_coef: 0.0592 - val_accuracy: 0.9052\n",
      "Epoch 303/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0931 - dice_coef: 0.0932 - accuracy: 0.9196 - val_loss: -0.0593 - val_dice_coef: 0.0593 - val_accuracy: 0.9052\n",
      "Epoch 304/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0933 - dice_coef: 0.0933 - accuracy: 0.9197 - val_loss: -0.0594 - val_dice_coef: 0.0594 - val_accuracy: 0.9052\n",
      "Epoch 305/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0933 - dice_coef: 0.0932 - accuracy: 0.9197 - val_loss: -0.0596 - val_dice_coef: 0.0595 - val_accuracy: 0.9052\n",
      "Epoch 306/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0935 - dice_coef: 0.0936 - accuracy: 0.9198 - val_loss: -0.0597 - val_dice_coef: 0.0597 - val_accuracy: 0.9052\n",
      "Epoch 307/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0936 - dice_coef: 0.0938 - accuracy: 0.9199 - val_loss: -0.0598 - val_dice_coef: 0.0598 - val_accuracy: 0.9052\n",
      "Epoch 308/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0938 - dice_coef: 0.0937 - accuracy: 0.9199 - val_loss: -0.0599 - val_dice_coef: 0.0599 - val_accuracy: 0.9052\n",
      "Epoch 309/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0940 - dice_coef: 0.0943 - accuracy: 0.9199 - val_loss: -0.0600 - val_dice_coef: 0.0600 - val_accuracy: 0.9052\n",
      "Epoch 310/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0941 - dice_coef: 0.0941 - accuracy: 0.9200 - val_loss: -0.0601 - val_dice_coef: 0.0601 - val_accuracy: 0.9052\n",
      "Epoch 311/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0942 - dice_coef: 0.0945 - accuracy: 0.9198 - val_loss: -0.0603 - val_dice_coef: 0.0602 - val_accuracy: 0.9052\n",
      "Epoch 312/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0944 - dice_coef: 0.0942 - accuracy: 0.9199 - val_loss: -0.0604 - val_dice_coef: 0.0604 - val_accuracy: 0.9052\n",
      "Epoch 313/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0943 - dice_coef: 0.0940 - accuracy: 0.9201 - val_loss: -0.0605 - val_dice_coef: 0.0605 - val_accuracy: 0.9052\n",
      "Epoch 314/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0947 - dice_coef: 0.0948 - accuracy: 0.9201 - val_loss: -0.0606 - val_dice_coef: 0.0606 - val_accuracy: 0.9052\n",
      "Epoch 315/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0947 - dice_coef: 0.0949 - accuracy: 0.9200 - val_loss: -0.0607 - val_dice_coef: 0.0607 - val_accuracy: 0.9052\n",
      "Epoch 316/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0949 - dice_coef: 0.0948 - accuracy: 0.9200 - val_loss: -0.0608 - val_dice_coef: 0.0608 - val_accuracy: 0.9052\n",
      "Epoch 317/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0949 - dice_coef: 0.0953 - accuracy: 0.9201 - val_loss: -0.0609 - val_dice_coef: 0.0609 - val_accuracy: 0.9052\n",
      "Epoch 318/400\n",
      "19/19 [==============================] - 7s 381ms/step - loss: -0.0953 - dice_coef: 0.0953 - accuracy: 0.9202 - val_loss: -0.0611 - val_dice_coef: 0.0610 - val_accuracy: 0.9052\n",
      "Epoch 319/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0953 - dice_coef: 0.0951 - accuracy: 0.9201 - val_loss: -0.0612 - val_dice_coef: 0.0611 - val_accuracy: 0.9052\n",
      "Epoch 320/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0954 - dice_coef: 0.0949 - accuracy: 0.9203 - val_loss: -0.0613 - val_dice_coef: 0.0613 - val_accuracy: 0.9052\n",
      "Epoch 321/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0957 - dice_coef: 0.0956 - accuracy: 0.9203 - val_loss: -0.0614 - val_dice_coef: 0.0614 - val_accuracy: 0.9052\n",
      "Epoch 322/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0956 - dice_coef: 0.0956 - accuracy: 0.9201 - val_loss: -0.0615 - val_dice_coef: 0.0615 - val_accuracy: 0.9052\n",
      "Epoch 323/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0958 - dice_coef: 0.0954 - accuracy: 0.9203 - val_loss: -0.0616 - val_dice_coef: 0.0616 - val_accuracy: 0.9052\n",
      "Epoch 324/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0959 - dice_coef: 0.0958 - accuracy: 0.9202 - val_loss: -0.0617 - val_dice_coef: 0.0617 - val_accuracy: 0.9052\n",
      "Epoch 325/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0960 - dice_coef: 0.0960 - accuracy: 0.9204 - val_loss: -0.0618 - val_dice_coef: 0.0618 - val_accuracy: 0.9053\n",
      "Epoch 326/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0960 - dice_coef: 0.0959 - accuracy: 0.9204 - val_loss: -0.0619 - val_dice_coef: 0.0619 - val_accuracy: 0.9053\n",
      "Epoch 327/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0963 - dice_coef: 0.0965 - accuracy: 0.9203 - val_loss: -0.0620 - val_dice_coef: 0.0620 - val_accuracy: 0.9053\n",
      "Epoch 328/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0964 - dice_coef: 0.0962 - accuracy: 0.9203 - val_loss: -0.0621 - val_dice_coef: 0.0621 - val_accuracy: 0.9053\n",
      "Epoch 329/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0964 - dice_coef: 0.0961 - accuracy: 0.9204 - val_loss: -0.0622 - val_dice_coef: 0.0622 - val_accuracy: 0.9053\n",
      "Epoch 330/400\n",
      "19/19 [==============================] - 7s 390ms/step - loss: -0.0964 - dice_coef: 0.0969 - accuracy: 0.9204 - val_loss: -0.0623 - val_dice_coef: 0.0623 - val_accuracy: 0.9053\n",
      "Epoch 331/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0968 - dice_coef: 0.0968 - accuracy: 0.9205 - val_loss: -0.0624 - val_dice_coef: 0.0624 - val_accuracy: 0.9053\n",
      "Epoch 332/400\n",
      "19/19 [==============================] - 7s 384ms/step - loss: -0.0970 - dice_coef: 0.0972 - accuracy: 0.9204 - val_loss: -0.0625 - val_dice_coef: 0.0625 - val_accuracy: 0.9053\n",
      "Epoch 333/400\n",
      "19/19 [==============================] - 7s 386ms/step - loss: -0.0968 - dice_coef: 0.0969 - accuracy: 0.9205 - val_loss: -0.0626 - val_dice_coef: 0.0626 - val_accuracy: 0.9053\n",
      "Epoch 334/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0971 - dice_coef: 0.0968 - accuracy: 0.9204 - val_loss: -0.0627 - val_dice_coef: 0.0627 - val_accuracy: 0.9054\n",
      "Epoch 335/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0972 - dice_coef: 0.0972 - accuracy: 0.9205 - val_loss: -0.0628 - val_dice_coef: 0.0628 - val_accuracy: 0.9054\n",
      "Epoch 336/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0972 - dice_coef: 0.0968 - accuracy: 0.9205 - val_loss: -0.0629 - val_dice_coef: 0.0629 - val_accuracy: 0.9054\n",
      "Epoch 337/400\n",
      "19/19 [==============================] - 7s 391ms/step - loss: -0.0973 - dice_coef: 0.0968 - accuracy: 0.9206 - val_loss: -0.0630 - val_dice_coef: 0.0630 - val_accuracy: 0.9054\n",
      "Epoch 338/400\n",
      "19/19 [==============================] - 7s 382ms/step - loss: -0.0975 - dice_coef: 0.0975 - accuracy: 0.9205 - val_loss: -0.0631 - val_dice_coef: 0.0631 - val_accuracy: 0.9054\n",
      "Epoch 339/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0975 - dice_coef: 0.0974 - accuracy: 0.9207 - val_loss: -0.0632 - val_dice_coef: 0.0632 - val_accuracy: 0.9054\n",
      "Epoch 340/400\n",
      "19/19 [==============================] - 7s 383ms/step - loss: -0.0977 - dice_coef: 0.0979 - accuracy: 0.9207 - val_loss: -0.0633 - val_dice_coef: 0.0633 - val_accuracy: 0.9054\n",
      "Epoch 341/400\n",
      "19/19 [==============================] - 7s 387ms/step - loss: -0.0980 - dice_coef: 0.0978 - accuracy: 0.9206 - val_loss: -0.0634 - val_dice_coef: 0.0634 - val_accuracy: 0.9054\n",
      "Epoch 342/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0980 - dice_coef: 0.0979 - accuracy: 0.9206 - val_loss: -0.0635 - val_dice_coef: 0.0635 - val_accuracy: 0.9054\n",
      "Epoch 343/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0980 - dice_coef: 0.0977 - accuracy: 0.9206 - val_loss: -0.0636 - val_dice_coef: 0.0635 - val_accuracy: 0.9054\n",
      "Epoch 344/400\n",
      "19/19 [==============================] - 7s 378ms/step - loss: -0.0982 - dice_coef: 0.0981 - accuracy: 0.9206 - val_loss: -0.0637 - val_dice_coef: 0.0636 - val_accuracy: 0.9054\n",
      "Epoch 345/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0981 - dice_coef: 0.0980 - accuracy: 0.9206 - val_loss: -0.0637 - val_dice_coef: 0.0637 - val_accuracy: 0.9054\n",
      "Epoch 346/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0983 - dice_coef: 0.0988 - accuracy: 0.9207 - val_loss: -0.0638 - val_dice_coef: 0.0638 - val_accuracy: 0.9055\n",
      "Epoch 347/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0984 - dice_coef: 0.0984 - accuracy: 0.9207 - val_loss: -0.0639 - val_dice_coef: 0.0639 - val_accuracy: 0.9055\n",
      "Epoch 348/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0987 - dice_coef: 0.0987 - accuracy: 0.9209 - val_loss: -0.0640 - val_dice_coef: 0.0640 - val_accuracy: 0.9055\n",
      "Epoch 349/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0987 - dice_coef: 0.0987 - accuracy: 0.9208 - val_loss: -0.0641 - val_dice_coef: 0.0641 - val_accuracy: 0.9055\n",
      "Epoch 350/400\n",
      "19/19 [==============================] - 7s 380ms/step - loss: -0.0987 - dice_coef: 0.0989 - accuracy: 0.9208 - val_loss: -0.0642 - val_dice_coef: 0.0642 - val_accuracy: 0.9055\n",
      "Epoch 351/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0989 - dice_coef: 0.0989 - accuracy: 0.9208 - val_loss: -0.0643 - val_dice_coef: 0.0643 - val_accuracy: 0.9055\n",
      "Epoch 352/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0989 - dice_coef: 0.0987 - accuracy: 0.9207 - val_loss: -0.0644 - val_dice_coef: 0.0643 - val_accuracy: 0.9055\n",
      "Epoch 353/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0990 - dice_coef: 0.0988 - accuracy: 0.9208 - val_loss: -0.0645 - val_dice_coef: 0.0644 - val_accuracy: 0.9055\n",
      "Epoch 354/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0991 - dice_coef: 0.0991 - accuracy: 0.9209 - val_loss: -0.0645 - val_dice_coef: 0.0645 - val_accuracy: 0.9056\n",
      "Epoch 355/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0994 - dice_coef: 0.0995 - accuracy: 0.9208 - val_loss: -0.0646 - val_dice_coef: 0.0646 - val_accuracy: 0.9056\n",
      "Epoch 356/400\n",
      "19/19 [==============================] - 7s 376ms/step - loss: -0.0992 - dice_coef: 0.0992 - accuracy: 0.9210 - val_loss: -0.0647 - val_dice_coef: 0.0647 - val_accuracy: 0.9056\n",
      "Epoch 357/400\n",
      "19/19 [==============================] - 7s 379ms/step - loss: -0.0993 - dice_coef: 0.0993 - accuracy: 0.9211 - val_loss: -0.0648 - val_dice_coef: 0.0648 - val_accuracy: 0.9056\n",
      "Epoch 358/400\n",
      "19/19 [==============================] - 7s 377ms/step - loss: -0.0995 - dice_coef: 0.0994 - accuracy: 0.9210 - val_loss: -0.0649 - val_dice_coef: 0.0649 - val_accuracy: 0.9056\n",
      "Epoch 359/400\n",
      "19/19 [==============================] - 7s 374ms/step - loss: -0.0996 - dice_coef: 0.0999 - accuracy: 0.9210 - val_loss: -0.0650 - val_dice_coef: 0.0649 - val_accuracy: 0.9056\n",
      "Epoch 360/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0995 - dice_coef: 0.0996 - accuracy: 0.9211 - val_loss: -0.0650 - val_dice_coef: 0.0650 - val_accuracy: 0.9057\n",
      "Epoch 361/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.0998 - dice_coef: 0.0999 - accuracy: 0.9209 - val_loss: -0.0651 - val_dice_coef: 0.0651 - val_accuracy: 0.9057\n",
      "Epoch 362/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0999 - dice_coef: 0.1002 - accuracy: 0.9211 - val_loss: -0.0652 - val_dice_coef: 0.0652 - val_accuracy: 0.9057\n",
      "Epoch 363/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.0999 - dice_coef: 0.0997 - accuracy: 0.9210 - val_loss: -0.0653 - val_dice_coef: 0.0653 - val_accuracy: 0.9057\n",
      "Epoch 364/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1001 - dice_coef: 0.0999 - accuracy: 0.9211 - val_loss: -0.0654 - val_dice_coef: 0.0653 - val_accuracy: 0.9057\n",
      "Epoch 365/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1003 - dice_coef: 0.1005 - accuracy: 0.9212 - val_loss: -0.0654 - val_dice_coef: 0.0654 - val_accuracy: 0.9057\n",
      "Epoch 366/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1002 - dice_coef: 0.0999 - accuracy: 0.9211 - val_loss: -0.0655 - val_dice_coef: 0.0655 - val_accuracy: 0.9057\n",
      "Epoch 367/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1000 - dice_coef: 0.1002 - accuracy: 0.9213 - val_loss: -0.0656 - val_dice_coef: 0.0656 - val_accuracy: 0.9057\n",
      "Epoch 368/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1004 - dice_coef: 0.1005 - accuracy: 0.9212 - val_loss: -0.0657 - val_dice_coef: 0.0657 - val_accuracy: 0.9058\n",
      "Epoch 369/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1005 - dice_coef: 0.1006 - accuracy: 0.9212 - val_loss: -0.0658 - val_dice_coef: 0.0657 - val_accuracy: 0.9058\n",
      "Epoch 370/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1007 - dice_coef: 0.1010 - accuracy: 0.9213 - val_loss: -0.0658 - val_dice_coef: 0.0658 - val_accuracy: 0.9058\n",
      "Epoch 371/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1008 - dice_coef: 0.1009 - accuracy: 0.9213 - val_loss: -0.0659 - val_dice_coef: 0.0659 - val_accuracy: 0.9058\n",
      "Epoch 372/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1009 - dice_coef: 0.1010 - accuracy: 0.9213 - val_loss: -0.0660 - val_dice_coef: 0.0660 - val_accuracy: 0.9059\n",
      "Epoch 373/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1007 - dice_coef: 0.1004 - accuracy: 0.9214 - val_loss: -0.0661 - val_dice_coef: 0.0660 - val_accuracy: 0.9059\n",
      "Epoch 374/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1009 - dice_coef: 0.1010 - accuracy: 0.9214 - val_loss: -0.0661 - val_dice_coef: 0.0661 - val_accuracy: 0.9059\n",
      "Epoch 375/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1010 - dice_coef: 0.1010 - accuracy: 0.9215 - val_loss: -0.0662 - val_dice_coef: 0.0662 - val_accuracy: 0.9059\n",
      "Epoch 376/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1012 - dice_coef: 0.1011 - accuracy: 0.9214 - val_loss: -0.0663 - val_dice_coef: 0.0663 - val_accuracy: 0.9060\n",
      "Epoch 377/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1011 - dice_coef: 0.1009 - accuracy: 0.9214 - val_loss: -0.0664 - val_dice_coef: 0.0663 - val_accuracy: 0.9060\n",
      "Epoch 378/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1012 - dice_coef: 0.1013 - accuracy: 0.9216 - val_loss: -0.0664 - val_dice_coef: 0.0664 - val_accuracy: 0.9061\n",
      "Epoch 379/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1013 - dice_coef: 0.1015 - accuracy: 0.9216 - val_loss: -0.0665 - val_dice_coef: 0.0665 - val_accuracy: 0.9061\n",
      "Epoch 380/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1016 - dice_coef: 0.1016 - accuracy: 0.9215 - val_loss: -0.0666 - val_dice_coef: 0.0666 - val_accuracy: 0.9062\n",
      "Epoch 381/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1016 - dice_coef: 0.1017 - accuracy: 0.9216 - val_loss: -0.0667 - val_dice_coef: 0.0666 - val_accuracy: 0.9063\n",
      "Epoch 382/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1016 - dice_coef: 0.1015 - accuracy: 0.9217 - val_loss: -0.0667 - val_dice_coef: 0.0667 - val_accuracy: 0.9064\n",
      "Epoch 383/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1017 - dice_coef: 0.1017 - accuracy: 0.9216 - val_loss: -0.0668 - val_dice_coef: 0.0668 - val_accuracy: 0.9064\n",
      "Epoch 384/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.1017 - dice_coef: 0.1014 - accuracy: 0.9217 - val_loss: -0.0669 - val_dice_coef: 0.0668 - val_accuracy: 0.9065\n",
      "Epoch 385/400\n",
      "19/19 [==============================] - 7s 364ms/step - loss: -0.1018 - dice_coef: 0.1016 - accuracy: 0.9217 - val_loss: -0.0669 - val_dice_coef: 0.0669 - val_accuracy: 0.9066\n",
      "Epoch 386/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.1018 - dice_coef: 0.1016 - accuracy: 0.9217 - val_loss: -0.0670 - val_dice_coef: 0.0670 - val_accuracy: 0.9067\n",
      "Epoch 387/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1018 - dice_coef: 0.1023 - accuracy: 0.9217 - val_loss: -0.0671 - val_dice_coef: 0.0671 - val_accuracy: 0.9069\n",
      "Epoch 388/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1021 - dice_coef: 0.1020 - accuracy: 0.9218 - val_loss: -0.0672 - val_dice_coef: 0.0671 - val_accuracy: 0.9070\n",
      "Epoch 389/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1021 - dice_coef: 0.1022 - accuracy: 0.9218 - val_loss: -0.0672 - val_dice_coef: 0.0672 - val_accuracy: 0.9071\n",
      "Epoch 390/400\n",
      "19/19 [==============================] - 7s 369ms/step - loss: -0.1020 - dice_coef: 0.1021 - accuracy: 0.9219 - val_loss: -0.0673 - val_dice_coef: 0.0673 - val_accuracy: 0.9071\n",
      "Epoch 391/400\n",
      "19/19 [==============================] - 7s 365ms/step - loss: -0.1020 - dice_coef: 0.1018 - accuracy: 0.9219 - val_loss: -0.0674 - val_dice_coef: 0.0673 - val_accuracy: 0.9072\n",
      "Epoch 392/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1022 - dice_coef: 0.1021 - accuracy: 0.9220 - val_loss: -0.0674 - val_dice_coef: 0.0674 - val_accuracy: 0.9073\n",
      "Epoch 393/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1025 - dice_coef: 0.1026 - accuracy: 0.9219 - val_loss: -0.0675 - val_dice_coef: 0.0675 - val_accuracy: 0.9074\n",
      "Epoch 394/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1025 - dice_coef: 0.1027 - accuracy: 0.9221 - val_loss: -0.0676 - val_dice_coef: 0.0675 - val_accuracy: 0.9075\n",
      "Epoch 395/400\n",
      "19/19 [==============================] - 7s 366ms/step - loss: -0.1026 - dice_coef: 0.1027 - accuracy: 0.9220 - val_loss: -0.0676 - val_dice_coef: 0.0676 - val_accuracy: 0.9076\n",
      "Epoch 396/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1026 - dice_coef: 0.1029 - accuracy: 0.9222 - val_loss: -0.0677 - val_dice_coef: 0.0677 - val_accuracy: 0.9077\n",
      "Epoch 397/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1028 - dice_coef: 0.1028 - accuracy: 0.9222 - val_loss: -0.0678 - val_dice_coef: 0.0677 - val_accuracy: 0.9078\n",
      "Epoch 398/400\n",
      "19/19 [==============================] - 7s 368ms/step - loss: -0.1028 - dice_coef: 0.1031 - accuracy: 0.9224 - val_loss: -0.0678 - val_dice_coef: 0.0678 - val_accuracy: 0.9079\n",
      "Epoch 399/400\n",
      "19/19 [==============================] - 7s 367ms/step - loss: -0.1027 - dice_coef: 0.1028 - accuracy: 0.9223 - val_loss: -0.0679 - val_dice_coef: 0.0679 - val_accuracy: 0.9079\n",
      "Epoch 400/400\n",
      "19/19 [==============================] - 7s 362ms/step - loss: -0.1029 - dice_coef: 0.1029 - accuracy: 0.9224 - val_loss: -0.0680 - val_dice_coef: 0.0679 - val_accuracy: 0.9080\n"
     ]
    }
   ],
   "source": [
    "tranfer_learning_results = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=32, epochs=maxepoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T22:49:07.105749Z",
     "iopub.status.busy": "2020-10-05T22:49:07.104746Z",
     "iopub.status.idle": "2020-10-05T22:49:07.736320Z",
     "shell.execute_reply": "2020-10-05T22:49:07.736320Z",
     "shell.execute_reply.started": "2020-10-05T22:49:07.105749Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "root_path = ''\n",
    "# save the trained model\n",
    "model_yaml = transfered_model.to_yaml()\n",
    "with open(root_path+\"history_transfered_NAIP_Dropout_0.5_\"+timestr+\".yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# save the weights\n",
    "transfered_model.save(root_path+\"model_transfered_NAIP_Dropout_0.5_\"+timestr+\".h5\")\n",
    "# save the intermdediate results and training statistics\n",
    "with open(root_path+\"history_transfered_NAIP_Dropout_0.5_\"+timestr+\".pickle\", 'wb') as file_pi:\n",
    "    pickle.dump(tranfer_learning_results.history, file_pi, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will wait for the whole area data to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c574e7fc8f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the predicted labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/prediction_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds_test_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds_test\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/preds_test_total_attention2.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds_test_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the predicted labels.\n",
    "X_test = np.load(root_path+'ModelJun14/prediction_data.npy')\n",
    "preds_test = model.predict(X_test)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "np.save(root_path+'ModelJun14/preds_test_total_attention2.npy',preds_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress 28/09/2020\n",
    "1. Added Dropout layer   \n",
    "    **Result:** The dropout doesn't help in this case.  \n",
    "    with 0.5 drop rate and 1000 epochs we can achive 94.1%\n",
    "\n",
    "\n",
    "# Progress 21/09/2020\n",
    "1. Genreating the result for transfer learnign without NAIP again \n",
    "2. Created the [plan until Mid Oct 2020](\"https://docs.google.com/document/d/1Kqz18zgB-DSkDarr-m8Y-__0ZCNzXAkTZw7Xg7kIy08/edit#\")\n",
    "    - The goal is to finish the first draft by Mid Oct. \n",
    "    \n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020[.]('https://analyticsindiamag.com/top-10-papers-on-transfer-learning-one-must-read-in-2020/')  \n",
    "\n",
    "# Progress 14/09/2020\n",
    "1. Read and summarize more  [transfer learning paper]('https://openreview.net/pdf?id=ryxyCeHtPB')  \n",
    "    - propose \"attentive feature distillation and selection (AFDS)\"   \n",
    "    - AFDS dynamically learns not only the features to transfer, but also the unimportant neurons to skip    \n",
    "    \n",
    "\n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020\n",
    "\n",
    "**Qual Exam beginning of next semester**\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 07/09/2020  \n",
    "1. Presented the progress in CEGIS  \n",
    "  \n",
    "2. Generated total dataset for Covingtoin area (without NAIP imagery)\n",
    "    \n",
    "3. Run prediction of the Convington area with the dataset without NAIP and using the original model that is trained on Rowan creek area  \n",
    "\n",
    "\n",
    "# Plan work\n",
    "1. Try training the model with more weight of stream class.\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 31/08/2020\n",
    "1. Corrected the data (removing None class (-9999) from test dataset)\n",
    "    - will generate the new test results  \n",
    "  \n",
    "  \n",
    "2. Preparing for CEGIS presentation\n",
    "    - Added prelim results  \n",
    "    - Will add the base scenario which is the U-net model predict the dataset without NAIP in Covinton river  \n",
    "      \n",
    "        \n",
    "    \n",
    "3. preparing the script for the presentation  \n",
    "    \n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "\n",
    "----\n",
    "\n",
    "# Progress 24/08/2020\n",
    "\n",
    "**Comments:** Try to get the why and what it hold true and how to make or to apply to other places.  \n",
    "\n",
    "1. Generate the whole area and do testing\n",
    "    - Generated the dataset\n",
    "    - Evaluated the testing data and generated the prelim results\n",
    "**Problem:** the data has more than 2 classes as shown in evaluation.   \n",
    "      \n",
    "    \n",
    "2. Created the outline of the presentation for CEGIS \n",
    "    - Still need more details:   \n",
    "    https://docs.google.com/presentation/d/1PWrlgGEMCCJLXsAHeiTe40xdA22RtISE6gUpRbbplRs/edit?usp=sharing\n",
    "\n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "4. Correct the data (remove the None class)\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 17/08/2020\n",
    "1. Finished generating the new dataset\n",
    "    - Cleaned the NAIP data and all raw data of Covington River\n",
    "    - Included NAIP imagery into the dataset\n",
    "    - Edited the data preprocessing script to make it easier to add or remove data \n",
    "    - Added script documents and comments  \n",
    "      \n",
    "2. Generating the whole area dataset the included NAIP imagery\n",
    "    - Using High memory node on Keeling   \n",
    "    - **Problem:** The VPN disconnected after 2 hours in!!! T_T I have to start over.  \n",
    "  \n",
    "3. Trained the model with new dataset  \n",
    "    - The performance is significatly higher than the dataset without NAIP  \n",
    "  \n",
    "4. Read more papers and added summary of the read paper\n",
    "    -https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit  \n",
    "  \n",
    "# Plan for this week\n",
    "1. Generate the whole area and do testing\n",
    "2. Start preparing the presentation for CEGIS \n",
    "3. Read and summarize more papers\n",
    "    - Focus more on machine learning in hydro, remote sensing classification.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Prgress 10/08/2020\n",
    "\n",
    "1. Successfully trained the model on my own PC.  \n",
    "    - Fixed cuCNN and CUDA version problems \n",
    "    - Trained with 4 trainable layers  \n",
    "      **Problem:** The model just disrtegards the stream class.  \n",
    "      **Root cause:** Unbalanced sample of stream and non-stream classes   \n",
    "\n",
    "2. In progress: Adding NAIP image to the dataset. \n",
    "    - Extracted the NAIP for Covinton and put it on Keeling \n",
    "    - modifying the preprocessing code\n",
    "    \n",
    "3. Outline the Introduction of the paper and reviewed some papers\n",
    "    - https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit\n",
    "    \n",
    "# Plan for this week\n",
    "1. Finished adding the NAIP and train the model again\n",
    "2. Start the first draft of the introduction \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
