{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Load all the dependencies\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from numpy import genfromtxt\n",
    "from tensorflow import random\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, UpSampling2D, GlobalAveragePooling2D, Multiply, Dense, Reshape, Permute, multiply, dot, add, Input\n",
    "from keras.layers.core import Dropout, Lambda, SpatialDropout2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model, model_from_yaml, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "random.set_seed(1337)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dice coefficient function as the loss function \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "# Jacard coefficient\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "# calculate loss value\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "# calculate loss value\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def Residual_CNN_block(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    return conv\n",
    "\n",
    "class multiplication(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,x_query,phi_g,x_value = inputs[0],inputs[1],inputs[2],inputs[3],inputs[4]\n",
    "        h,w,c = int(x.shape[1]),int(x.shape[2]),int(x.shape[3])\n",
    "        x_query = K.reshape(x_query, shape=(-1,h*w, self.inter_channel//4))\n",
    "        phi_g = K.reshape(phi_g,shape=(-1,h*w,self.inter_channel//4))\n",
    "        x_value = K.reshape(x_value,shape=(-1,h*w,c))\n",
    "        scale = dot([K.permute_dimensions(phi_g,(0,2,1)), x_query], axes=(1, 2))\n",
    "        soft_scale = Activation('softmax')(scale)\n",
    "        scaled_value = dot([K.permute_dimensions(soft_scale,(0,2,1)),K.permute_dimensions(x_value,(0,2,1))],axes=(1, 2))\n",
    "        scaled_value = K.reshape(scaled_value, shape=(-1,h,w,c))        \n",
    "        customize_multi = self.k * scaled_value\n",
    "        layero = add([customize_multi,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([layero,g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*3)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication': multiplication}\n",
    "\n",
    "def attention_up_and_concatenate(inputs):\n",
    "    g,x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel, (2,2), strides=[2, 2],padding='same')(g)\n",
    "    x_query = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    x_value = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    inputs = [g,x,x_query,phi_g,x_value]\n",
    "    concate = multiplication(inter_channel)(inputs)\n",
    "    return concate\n",
    "\n",
    "class multiplication2(Layer):\n",
    "    def __init__(self,inter_channel = None,**kwargs):\n",
    "        super(multiplication2, self).__init__(**kwargs)\n",
    "        self.inter_channel = inter_channel\n",
    "    def build(self,input_shape=None):\n",
    "        self.k = self.add_weight(name='k',shape=(1,),initializer='zeros',dtype='float32',trainable=True)\n",
    "    def get_config(self):\n",
    "        base_config = super(multiplication2, self).get_config()\n",
    "        config = {'inter_channel':self.inter_channel}\n",
    "        return dict(list(base_config.items()) + list(config.items()))  \n",
    "    def call(self,inputs):\n",
    "        g,x,rate = inputs[0],inputs[1],inputs[2]\n",
    "        scaled_value = multiply([x, rate])\n",
    "        att_x =  self.k * scaled_value\n",
    "        att_x = add([att_x,x])\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "        concate = my_concat([att_x, g])\n",
    "        return concate \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        ll = list(input_shape)[1]\n",
    "        return (None,ll[1],ll[1],ll[3]*2)\n",
    "    def get_custom_objects():\n",
    "        return {'multiplication2': multiplication2}\n",
    "\n",
    "def attention_up_and_concatenate2(inputs):\n",
    "    g, x = inputs[0],inputs[1]\n",
    "    inter_channel = g.get_shape().as_list()[3]\n",
    "    g = Conv2DTranspose(inter_channel//2, (3,3), strides=[2, 2],padding='same')(g)\n",
    "    g = Conv2D(inter_channel//2, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    theta_x = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(x)\n",
    "    phi_g = Conv2D(inter_channel//4, [1, 1], strides=[1, 1], data_format='channels_last')(g)\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format='channels_last')(f)\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    concate =  multiplication2()([g,x,rate])\n",
    "    return concate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train last 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Here\n",
      "Here\n",
      "Here\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('June21/model/model_augv_attention2.h5', \n",
    "                             custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                             'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "# remove the last 2 layer using pop() function\n",
    "loaded_model.layers.pop()\n",
    "loaded_model.layers.pop()\n",
    "\n",
    "for (index, layer) in enumerate(loaded_model.layers):\n",
    "    if (index > len(loaded_model.layers)-5):\n",
    "        print(\"Here\")\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "# See model structure\n",
    "#model_without_last.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train first 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index  0\n",
      "index  1\n",
      "index  2\n",
      "index  3\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('June21/model/model_augv_attention2.h5', \n",
    "                             custom_objects={'multiplication': multiplication,'multiplication2': multiplication2, \n",
    "                                             'dice_coef_loss':dice_coef_loss, 'dice_coef':dice_coef,})\n",
    "\n",
    "# remove the last 2 layer using pop() function\n",
    "loaded_model.layers.pop()\n",
    "loaded_model.layers.pop()\n",
    "\n",
    "for (index, layer) in enumerate(loaded_model.layers):\n",
    "    if (index < 4):\n",
    "        print(\"index \",index)\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Create new model from the model using the input and output of the last layer (after poping last 2 layers)\n",
    "model_without_last = Model(loaded_model.input,  loaded_model.layers[-1].output)\n",
    "\n",
    "# See model structure\n",
    "#model_without_last.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "\n",
    "# 1 dimensional convolution and generate probabilities from Sigmoid function\n",
    "conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1), name='conv2d_last')(model_without_last.output)\n",
    "new_out = Activation('sigmoid', name='activation_last')(conv_final)\n",
    "\n",
    "# Created new model with the newly added last two layers \n",
    "transfered_model = Model(inputs=model_without_last.input, outputs=new_out)\n",
    "\n",
    "# New model structure\n",
    "#transfered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **without** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 224, 224, 8)\n",
      "(40, 224, 224, 1)\n",
      "(10, 224, 224, 8)\n",
      "(10, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Covington_data/without_NAIP/nodata_as_0/'\n",
    "\n",
    "# read in training and validation data\n",
    "X_train = np.load(data_path+'train_data.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "X_Validation = np.load(data_path+'vali_data.npy')\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "\n",
    "# The dataset has 9 channels:\n",
    "# 0. Curvature\n",
    "# 1. Slope\n",
    "# 2. Openness\n",
    "# 3. DEM\n",
    "# 4. TPI 21\n",
    "# 5. Reflectance (LiDAR intensity)\n",
    "# 6. Geomorphon\n",
    "# 7. TPI 9\n",
    "# 8. TPI 3\n",
    "\n",
    "# ##############################################\n",
    "# 50 samples \n",
    "X_train_new = X_train[0:40,:,:,:]\n",
    "print(X_train_new.shape)\n",
    "Y_train = np.load(data_path+'train_label.npy')[0:40,:,:,:]\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_Validation_new = X_Validation[0:10,:,:,:]\n",
    "print(X_Validation_new.shape)\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')[0:10,:,:,:]\n",
    "print(Y_Validation.shape)\n",
    "# ##############################################\n",
    "\n",
    "# ##############################################\n",
    "# # 100 samples \n",
    "# X_train_new = X_train[0:50,:,:,:]\n",
    "# print(X_train_new.shape)\n",
    "# Y_train = np.load(data_path+'train_label.npy')[0:50,:,:,:]\n",
    "# print(Y_train.shape)\n",
    "\n",
    "# X_Validation_new = X_Validation[0:50,:,:,:]\n",
    "# print(X_Validation_new.shape)\n",
    "# Y_Validation = np.load(data_path+'vali_label.npy')[0:50,:,:,:]\n",
    "# print(Y_Validation.shape)\n",
    "# ##############################################\n",
    "\n",
    "\n",
    "##############################################\n",
    "# 700 samples \n",
    "# X_train_new = X_train[0:350,:,:,:]\n",
    "# print(X_train_new.shape)\n",
    "# Y_train = np.load(data_path+'train_label.npy')[0:350,:,:,:]\n",
    "# print(Y_train.shape)\n",
    "\n",
    "# X_Validation_new = X_Validation[0:350,:,:,:]\n",
    "# print(X_Validation_new.shape)\n",
    "# Y_Validation = np.load(data_path+'vali_label.npy')[0:350,:,:,:]\n",
    "# print(Y_Validation.shape)\n",
    "##############################################\n",
    "\n",
    "\n",
    "# # ##############################################\n",
    "# # 1200 samples \n",
    "# X_train_new = X_train\n",
    "# print(X_train_new.shape)\n",
    "# Y_train = np.load(data_path+'train_label.npy')\n",
    "# print(Y_train.shape)\n",
    "\n",
    "# X_Validation_new = X_Validation\n",
    "# print(X_Validation_new.shape)\n",
    "# Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "# print(Y_Validation.shape)\n",
    "# # ##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If want to train on the data **with** the NAIP, run the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data_path = 'Covington_data/include_NAIP/nodata_as_0/100_samples/'\n",
    "# data_path = 'Covington_data/include_NAIP/nodata_as_0/350_samples/'\n",
    "data_path = 'Covington_data/include_NAIP/nodata_as_0/500_samples/'\n",
    "\n",
    "# read in training and validation sample patches\n",
    "X_train_new = np.load(data_path+'train_data.npy')\n",
    "X_Validation_new = np.load(data_path+'vali_data.npy')\n",
    "print(X_train_new.shape)\n",
    "print(X_Validation_new.shape)\n",
    "\n",
    "#Read training and validation labels\n",
    "Y_Validation = np.load(data_path+'vali_label.npy')\n",
    "Y_train = np.load(data_path+'train_label.npy')\n",
    "\n",
    "#Cast both labales to float32\n",
    "Y_Validation = Y_Validation.astype(np.float32)\n",
    "Y_train = Y_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_HEIGHT = patch_size\n",
    "# Number of feature channels \n",
    "INPUT_CHANNELS = 8\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "maxepoch = 50\n",
    "# hyperparameters\n",
    "# learning_rate = 0.0000359\n",
    "learning_rate = 0.0001\n",
    "patience = 20\n",
    "aug = 'v'\n",
    "transfered_model.compile(optimizer=Adam(lr=learning_rate),loss = dice_coef_loss,metrics=[dice_coef,'accuracy'])\n",
    "callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=patience, min_lr=1e-9, verbose=1, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=patience+10, verbose=0),\n",
    "        ModelCheckpoint('model'+aug+'_attention2.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 10 samples\n",
      "Epoch 1/50\n",
      "40/40 [==============================] - 9s 231ms/step - loss: -0.1471 - dice_coef: 0.1401 - accuracy: 0.9533 - val_loss: -0.0667 - val_dice_coef: 0.0556 - val_accuracy: 0.9756\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1432 - dice_coef: 0.1442 - accuracy: 0.9518 - val_loss: -0.0660 - val_dice_coef: 0.0550 - val_accuracy: 0.9796\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1532 - dice_coef: 0.1533 - accuracy: 0.9575 - val_loss: -0.0666 - val_dice_coef: 0.0555 - val_accuracy: 0.9813\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1552 - dice_coef: 0.1596 - accuracy: 0.9568 - val_loss: -0.0663 - val_dice_coef: 0.0552 - val_accuracy: 0.9827\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1553 - dice_coef: 0.1588 - accuracy: 0.9568 - val_loss: -0.0666 - val_dice_coef: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.1540 - dice_coef: 0.1467 - accuracy: 0.9547 - val_loss: -0.0677 - val_dice_coef: 0.0565 - val_accuracy: 0.9814\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1630 - dice_coef: 0.1683 - accuracy: 0.9599 - val_loss: -0.0685 - val_dice_coef: 0.0571 - val_accuracy: 0.9808\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1648 - dice_coef: 0.1570 - accuracy: 0.9585 - val_loss: -0.0703 - val_dice_coef: 0.0586 - val_accuracy: 0.9796\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1656 - dice_coef: 0.1577 - accuracy: 0.9571 - val_loss: -0.0717 - val_dice_coef: 0.0597 - val_accuracy: 0.9779\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1652 - dice_coef: 0.1709 - accuracy: 0.9587 - val_loss: -0.0734 - val_dice_coef: 0.0612 - val_accuracy: 0.9779\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1696 - dice_coef: 0.1726 - accuracy: 0.9600 - val_loss: -0.0748 - val_dice_coef: 0.0623 - val_accuracy: 0.9783\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1681 - dice_coef: 0.1601 - accuracy: 0.9591 - val_loss: -0.0757 - val_dice_coef: 0.0631 - val_accuracy: 0.9787\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1734 - dice_coef: 0.1651 - accuracy: 0.9591 - val_loss: -0.0765 - val_dice_coef: 0.0638 - val_accuracy: 0.9783\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1758 - dice_coef: 0.1742 - accuracy: 0.9596 - val_loss: -0.0765 - val_dice_coef: 0.0638 - val_accuracy: 0.9783\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1775 - dice_coef: 0.1827 - accuracy: 0.9616 - val_loss: -0.0770 - val_dice_coef: 0.0642 - val_accuracy: 0.9787\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1690 - dice_coef: 0.1610 - accuracy: 0.9568 - val_loss: -0.0777 - val_dice_coef: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1780 - dice_coef: 0.1802 - accuracy: 0.9590 - val_loss: -0.0783 - val_dice_coef: 0.0653 - val_accuracy: 0.9784\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1853 - dice_coef: 0.1852 - accuracy: 0.9612 - val_loss: -0.0792 - val_dice_coef: 0.0660 - val_accuracy: 0.9784\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.1827 - dice_coef: 0.1848 - accuracy: 0.9577 - val_loss: -0.0807 - val_dice_coef: 0.0673 - val_accuracy: 0.9777\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.1835 - dice_coef: 0.1856 - accuracy: 0.9581 - val_loss: -0.0813 - val_dice_coef: 0.0678 - val_accuracy: 0.9780\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.1911 - dice_coef: 0.1820 - accuracy: 0.9618 - val_loss: -0.0823 - val_dice_coef: 0.0686 - val_accuracy: 0.9778\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1910 - dice_coef: 0.1969 - accuracy: 0.9608 - val_loss: -0.0835 - val_dice_coef: 0.0696 - val_accuracy: 0.9778\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1926 - dice_coef: 0.1834 - accuracy: 0.9599 - val_loss: -0.0839 - val_dice_coef: 0.0700 - val_accuracy: 0.9785\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1941 - dice_coef: 0.1953 - accuracy: 0.9601 - val_loss: -0.0845 - val_dice_coef: 0.0704 - val_accuracy: 0.9796\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1964 - dice_coef: 0.1962 - accuracy: 0.9619 - val_loss: -0.0858 - val_dice_coef: 0.0715 - val_accuracy: 0.9805\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.1963 - dice_coef: 0.1870 - accuracy: 0.9626 - val_loss: -0.0869 - val_dice_coef: 0.0724 - val_accuracy: 0.9806\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2083 - dice_coef: 0.2080 - accuracy: 0.9631 - val_loss: -0.0881 - val_dice_coef: 0.0734 - val_accuracy: 0.9804\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2029 - dice_coef: 0.1933 - accuracy: 0.9592 - val_loss: -0.0898 - val_dice_coef: 0.0749 - val_accuracy: 0.9800\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2000 - dice_coef: 0.1988 - accuracy: 0.9614 - val_loss: -0.0910 - val_dice_coef: 0.0759 - val_accuracy: 0.9797\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2128 - dice_coef: 0.2107 - accuracy: 0.9611 - val_loss: -0.0924 - val_dice_coef: 0.0770 - val_accuracy: 0.9795\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2112 - dice_coef: 0.2111 - accuracy: 0.9617 - val_loss: -0.0952 - val_dice_coef: 0.0793 - val_accuracy: 0.9785\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2118 - dice_coef: 0.2133 - accuracy: 0.9626 - val_loss: -0.0969 - val_dice_coef: 0.0808 - val_accuracy: 0.9780\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2141 - dice_coef: 0.2158 - accuracy: 0.9604 - val_loss: -0.0978 - val_dice_coef: 0.0815 - val_accuracy: 0.9783\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2174 - dice_coef: 0.2071 - accuracy: 0.9611 - val_loss: -0.1001 - val_dice_coef: 0.0835 - val_accuracy: 0.9777\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2207 - dice_coef: 0.2102 - accuracy: 0.9642 - val_loss: -0.1004 - val_dice_coef: 0.0837 - val_accuracy: 0.9784\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2351 - dice_coef: 0.2344 - accuracy: 0.9657 - val_loss: -0.1014 - val_dice_coef: 0.0845 - val_accuracy: 0.9789\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2238 - dice_coef: 0.2324 - accuracy: 0.9602 - val_loss: -0.1028 - val_dice_coef: 0.0857 - val_accuracy: 0.9784\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2242 - dice_coef: 0.2252 - accuracy: 0.9618 - val_loss: -0.1043 - val_dice_coef: 0.0869 - val_accuracy: 0.9781\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2258 - dice_coef: 0.2279 - accuracy: 0.9628 - val_loss: -0.1063 - val_dice_coef: 0.0886 - val_accuracy: 0.9779\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2348 - dice_coef: 0.2373 - accuracy: 0.9629 - val_loss: -0.1079 - val_dice_coef: 0.0899 - val_accuracy: 0.9776\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2393 - dice_coef: 0.2280 - accuracy: 0.9640 - val_loss: -0.1102 - val_dice_coef: 0.0919 - val_accuracy: 0.9768\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2338 - dice_coef: 0.2355 - accuracy: 0.9610 - val_loss: -0.1117 - val_dice_coef: 0.0931 - val_accuracy: 0.9764\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2426 - dice_coef: 0.2311 - accuracy: 0.9632 - val_loss: -0.1145 - val_dice_coef: 0.0955 - val_accuracy: 0.9756\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2566 - dice_coef: 0.2444 - accuracy: 0.9667 - val_loss: -0.1162 - val_dice_coef: 0.0969 - val_accuracy: 0.9752\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2562 - dice_coef: 0.2621 - accuracy: 0.9633 - val_loss: -0.1173 - val_dice_coef: 0.0978 - val_accuracy: 0.9751\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2516 - dice_coef: 0.2396 - accuracy: 0.9641 - val_loss: -0.1179 - val_dice_coef: 0.0983 - val_accuracy: 0.9760\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2570 - dice_coef: 0.2448 - accuracy: 0.9651 - val_loss: -0.1191 - val_dice_coef: 0.0993 - val_accuracy: 0.9764\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 1s 35ms/step - loss: -0.2591 - dice_coef: 0.2619 - accuracy: 0.9654 - val_loss: -0.1217 - val_dice_coef: 0.1014 - val_accuracy: 0.9753\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2600 - dice_coef: 0.2654 - accuracy: 0.9633 - val_loss: -0.1236 - val_dice_coef: 0.1031 - val_accuracy: 0.9751\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 1s 34ms/step - loss: -0.2690 - dice_coef: 0.2779 - accuracy: 0.9668 - val_loss: -0.1236 - val_dice_coef: 0.1030 - val_accuracy: 0.9754\n"
     ]
    }
   ],
   "source": [
    "ltranfer_learning_results = transfered_model.fit(X_train_new, Y_train, validation_data=(X_Validation_new,Y_Validation), batch_size=3, epochs=maxepoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "root_path = './training_results/Without_NAIP/'\n",
    "# save the trained model\n",
    "model_yaml = transfered_model.to_yaml()\n",
    "with open(root_path+\"model_transfer_learning_no_NAIP_First4_50_samples_50_epochs_\"+timestr+\".yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# save the weights\n",
    "transfered_model.save(root_path+\"model_transfere_learning_no_NAIP_First4_50_samples_50_epochs_\"+timestr+\".h5\")\n",
    "# save the intermdediate results and training statistics\n",
    "with open(root_path+\"history_transfer_learning_no_NAIP_First4_50_samples_50_epochs_\"+timestr+\".pickle\", 'wb') as file_pi:\n",
    "    pickle.dump(ltranfer_learning_results.history, file_pi, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will wait for the whole area data to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c574e7fc8f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the predicted labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/prediction_data.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds_test_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds_test\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ModelJun14/preds_test_total_attention2.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds_test_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the predicted labels.\n",
    "X_test = np.load(root_path+'ModelJun14/prediction_data.npy')\n",
    "preds_test = model.predict(X_test)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "np.save(root_path+'ModelJun14/preds_test_total_attention2.npy',preds_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progreess 10/12/2020\n",
    "\n",
    "Training from scratch   \n",
    "- Total params: 53,508,217  \n",
    "- Trainable params: 53,490,169  \n",
    "- Non-trainable params: 18,048  \n",
    "\n",
    "1. Traing the model from scratch without NAIP   \n",
    "        \n",
    "**Without NAIP**  \n",
    "The training takes **17 seconds** for each epoch  \n",
    "- First training: the training stop at Epoch 105 (history_train_from_scratch_NoNAIP_20201012-111316)\n",
    "- We continue for 33 epochs more (history_train_from_scratch_NoNAIP_20201012-112416)\n",
    "    - Training set accu: 99.92%\n",
    "    - Validation set accu: 98.52%     \n",
    "\n",
    "**last line of log**   \n",
    "Epoch 33/400  \n",
    "50/50 [==============================] - 16s 313ms/step - loss: -0.9859 - dice_coef: 0.9859 - accuracy: 0.9992 - val_loss: -0.5574 - val_dice_coef: 0.5574 - val_accuracy: 0.9852\n",
    "\n",
    "1. Traing the model from scratch with NAIP   \n",
    "\n",
    "**With NAIP**   \n",
    "The training takes **17 seconds** for each epoch \n",
    "- First training: the training stop at Epoch 141 (history_train_from_scratch_NAIP_20201012-121601)\n",
    "    - Training set accu: 99.91%\n",
    "    - Validation set accu: 98.87%   \n",
    "\n",
    "**last line of log**     \n",
    "Epoch 141/400   \n",
    "50/50 [==============================] - 16s 321ms/step - loss: -0.9849 - dice_coef: 0.9849 - accuracy: 0.9991 - val_loss: -0.6443 - val_dice_coef: 0.6443 - val_accuracy: 0.9887   \n",
    "  \n",
    "  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "  \n",
    "---- \n",
    "\n",
    "# Progress 28/09/2020    \n",
    "\n",
    "Established the baseline for **400 epochs**  \n",
    "                                                 \n",
    "Base line Model (Transfer learnign with NAIP data) can achieve validation acc. **92.89%**\n",
    "\n",
    "1. Added SpatialDropout2D layer    \n",
    "    **Result:** The dropout doesn't help in this case.     \n",
    "    with 0.3 drop rate and 400 epochs we can achieve validation acc. 92.63%   \n",
    "    with 0.5 drop rate and 400 epochs we can achieve validation acc. 92.32%  \n",
    "    with 0.7 drop rate and 400 epochs we can achieve validation acc. 92.06%   \n",
    "    \n",
    "    Compare to Dropout layer   \n",
    "    with 0.3 drop rate and 400 epochs we can achieve validation acc. 92.56%  \n",
    "    with 0.5 drop rate and 400 epochs we can achieve validation acc. 92.34%  \n",
    "    with 0.7 drop rate and 400 epochs we can achieve validation acc. 92.22%%  \n",
    "    \n",
    "2. Fine-tuning doesn't help much  \n",
    "    first pass learning rate 0.0001   \n",
    "    second pass learning rate 0.00001   \n",
    "    **Result:** we can achieve validation acc. 92.48%   \n",
    "   \n",
    "3. Woking on classifier after the convolutional network\n",
    "\n",
    "# Plan work\n",
    "1. Create colab notebook for RIF meeting \n",
    "2. Continue writing\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 28/09/2020\n",
    "1. Added Dropout layer    \n",
    "    **Result:** The dropout doesn't help in this case.   \n",
    "    with 0.3 drop rate and 400 epochs we can achive 92.56%  \n",
    "    with 0.5 drop rate and 1000 epochs we can achive 94.1%  \n",
    "    with 0.7 drop rate and 400 epochs we can achive 92.2%  \n",
    "    \n",
    "2. Working on Fine-tuning process \n",
    "3. Working on Literature review\n",
    "\n",
    "\n",
    "# Plan work\n",
    "\n",
    "1. Finsihing the Literature review \n",
    "2. Try adding classifier after the convolutional network\n",
    "3. Begin the intro and abstract\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 21/09/2020\n",
    "1. Genreating the result for transfer learnign without NAIP again \n",
    "2. Created the [plan until Mid Oct 2020](\"https://docs.google.com/document/d/1Kqz18zgB-DSkDarr-m8Y-__0ZCNzXAkTZw7Xg7kIy08/edit#\")\n",
    "    - The goal is to finish the first draft by Mid Oct. \n",
    "    \n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020[.]('https://analyticsindiamag.com/top-10-papers-on-transfer-learning-one-must-read-in-2020/')  \n",
    "\n",
    "--- \n",
    "\n",
    "# Progress 14/09/2020\n",
    "1. Read and summarize more  [transfer learning paper]('https://openreview.net/pdf?id=ryxyCeHtPB')  \n",
    "    - propose \"attentive feature distillation and selection (AFDS)\"   \n",
    "    - AFDS dynamically learns not only the features to transfer, but also the unimportant neurons to skip    \n",
    "    \n",
    "\n",
    "# Plan work\n",
    "1. Start writing the paper\n",
    "2. Try training the model with more weight of stream class.\n",
    "3. Weekly plan until Mid October 2020\n",
    "\n",
    "**Qual Exam beginning of next semester**\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 07/09/2020  \n",
    "1. Presented the progress in CEGIS  \n",
    "  \n",
    "2. Generated total dataset for Covingtoin area (without NAIP imagery)\n",
    "    \n",
    "3. Run prediction of the Convington area with the dataset without NAIP and using the original model that is trained on Rowan creek area  \n",
    "\n",
    "\n",
    "# Plan work\n",
    "1. Try training the model with more weight of stream class.\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 31/08/2020\n",
    "1. Corrected the data (removing None class (-9999) from test dataset)\n",
    "    - will generate the new test results  \n",
    "  \n",
    "  \n",
    "2. Preparing for CEGIS presentation\n",
    "    - Added prelim results  \n",
    "    - Will add the base scenario which is the U-net model predict the dataset without NAIP in Covinton river  \n",
    "      \n",
    "        \n",
    "    \n",
    "3. preparing the script for the presentation  \n",
    "    \n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "\n",
    "----\n",
    "\n",
    "# Progress 24/08/2020\n",
    "\n",
    "**Comments:** Try to get the why and what it hold true and how to make or to apply to other places.  \n",
    "\n",
    "1. Generate the whole area and do testing\n",
    "    - Generated the dataset\n",
    "    - Evaluated the testing data and generated the prelim results\n",
    "**Problem:** the data has more than 2 classes as shown in evaluation.   \n",
    "      \n",
    "    \n",
    "2. Created the outline of the presentation for CEGIS \n",
    "    - Still need more details:   \n",
    "    https://docs.google.com/presentation/d/1PWrlgGEMCCJLXsAHeiTe40xdA22RtISE6gUpRbbplRs/edit?usp=sharing\n",
    "\n",
    "# Plan for this week\n",
    "1. Finish the presentation for CEGIS\n",
    "2. Read and summarize more paper\n",
    "3. Try training the model with more weight of stream class.\n",
    "4. Correct the data (remove the None class)\n",
    "\n",
    "---\n",
    "\n",
    "# Progress 17/08/2020\n",
    "1. Finished generating the new dataset\n",
    "    - Cleaned the NAIP data and all raw data of Covington River\n",
    "    - Included NAIP imagery into the dataset\n",
    "    - Edited the data preprocessing script to make it easier to add or remove data \n",
    "    - Added script documents and comments  \n",
    "      \n",
    "2. Generating the whole area dataset the included NAIP imagery\n",
    "    - Using High memory node on Keeling   \n",
    "    - **Problem:** The VPN disconnected after 2 hours in!!! T_T I have to start over.  \n",
    "  \n",
    "3. Trained the model with new dataset  \n",
    "    - The performance is significatly higher than the dataset without NAIP  \n",
    "  \n",
    "4. Read more papers and added summary of the read paper\n",
    "    -https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit  \n",
    "  \n",
    "# Plan for this week\n",
    "1. Generate the whole area and do testing\n",
    "2. Start preparing the presentation for CEGIS \n",
    "3. Read and summarize more papers\n",
    "    - Focus more on machine learning in hydro, remote sensing classification.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Prgress 10/08/2020\n",
    "\n",
    "1. Successfully trained the model on my own PC.  \n",
    "    - Fixed cuCNN and CUDA version problems \n",
    "    - Trained with 4 trainable layers  \n",
    "      **Problem:** The model just disrtegards the stream class.  \n",
    "      **Root cause:** Unbalanced sample of stream and non-stream classes   \n",
    "\n",
    "2. In progress: Adding NAIP image to the dataset. \n",
    "    - Extracted the NAIP for Covinton and put it on Keeling \n",
    "    - modifying the preprocessing code\n",
    "    \n",
    "3. Outline the Introduction of the paper and reviewed some papers\n",
    "    - https://docs.google.com/document/d/1BApPn0aWTwstEpbnKC9g0p5KSOhi74_rF7nzRYM9CtE/edit\n",
    "    \n",
    "# Plan for this week\n",
    "1. Finished adding the NAIP and train the model again\n",
    "2. Start the first draft of the introduction \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
